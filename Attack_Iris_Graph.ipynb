{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jskaf/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import ipysigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G_plot = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3000, 2.0000, 1.0000, 0.1000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "data = np.hstack((iris['data'],[[f'Gerard {i + 1}'] for i in range(len(iris['data']))]))\n",
    "y_true = iris['target']\n",
    "y_true_tensor = torch.tensor(y_true, dtype=torch.long, requires_grad=False)\n",
    "columns_mins = torch.tensor(np.min(iris['data'], axis=0), requires_grad=False, dtype=torch.float32)\n",
    "columns_maxs = torch.tensor(np.max(iris['data'], axis=0), requires_grad=False, dtype=torch.float32)\n",
    "columns_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(iris['data'],iris['data'])\n",
    "minimum_similarity = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8083221476510067\n",
      "0.8083221476510067\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(similarity_matrix)):\n",
    "    if \"Gerard \" + str(i + 1) not in G_plot.nodes:\n",
    "        G_plot.add_node(\"Gerard \" + str(i + 1), sepal_length=iris['data'][i][0], sepal_width=iris['data'][i][1],\n",
    "                   petal_length=iris['data'][i][2], petal_width=iris['data'][i][3])\n",
    "        G.add_node(i, sepal_length=iris['data'][i][0], sepal_width=iris['data'][i][1],\n",
    "                   petal_length=iris['data'][i][2], petal_width=iris['data'][i][3])\n",
    "    for j in range(i):\n",
    "        if \"Gerard \" + str(j + 1) not in G.nodes:\n",
    "            G_plot.add_node(\"Gerard \" + str(j + 1), sepal_length=iris['data'][j][0], sepal_width=iris['data'][j][1],\n",
    "                       petal_length=iris['data'][j][2], petal_width=iris['data'][j][3])\n",
    "            G.add_node(j, sepal_length=iris['data'][j][0], sepal_width=iris['data'][j][1],\n",
    "                       petal_length=iris['data'][j][2], petal_width=iris['data'][j][3])\n",
    "        if similarity_matrix[i][j] >= minimum_similarity:\n",
    "            G_plot.add_edge(\"Gerard \" + str(i + 1), \"Gerard \" + str(j + 1), weight=similarity_matrix[i][j])\n",
    "            G.add_edge(i, j, weight=similarity_matrix[i][j])\n",
    "\n",
    "print(nx.density(G))\n",
    "print(nx.density(G_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(iris['data'], dtype=torch.float)\n",
    "edges = list(G.edges)\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "data_target_model = Data(x=x, edge_index=edge_index)\n",
    "data_target_model.y = y_true_tensor\n",
    "data_target_model.validate(raise_on_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually split nodes into train, validation, and test sets using PyTorch\n",
    "num_nodes = len(data_target_model.x)\n",
    "train_ratio, test_ratio = 0.8, 0.2\n",
    "\n",
    "num_train = int(train_ratio * num_nodes)\n",
    "num_test = num_nodes - num_train\n",
    "\n",
    "# Create masks for train, validation, and test nodes\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_mask = perm[:num_train]\n",
    "test_mask = perm[num_train:]\n",
    "\n",
    "# Apply masks to the data\n",
    "data_target_model.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data_target_model.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "data_target_model.train_mask[train_mask] = 1\n",
    "data_target_model.test_mask[test_mask] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv3 = SAGEConv(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.conv1(data.x, data.edge_index)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        x = self.conv3(x, data.edge_index)\n",
    "        x = F.elu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = GraphSAGE(data_target_model.num_features, hidden_dim=16, out_dim=3)\n",
    "optimizer = torch.optim.Adam(target_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 1.335\n",
      "Epoch: 010, Train Loss: 0.765\n",
      "Epoch: 020, Train Loss: 0.312\n",
      "Epoch: 030, Train Loss: 0.126\n",
      "Epoch: 040, Train Loss: 0.056\n",
      "Epoch: 050, Train Loss: 0.030\n",
      "Epoch: 060, Train Loss: 0.020\n",
      "Epoch: 070, Train Loss: 0.016\n",
      "Epoch: 080, Train Loss: 0.013\n",
      "Epoch: 090, Train Loss: 0.011\n",
      "Epoch: 100, Train Loss: 0.010\n",
      "Epoch: 110, Train Loss: 0.009\n",
      "Epoch: 120, Train Loss: 0.008\n",
      "Epoch: 130, Train Loss: 0.007\n",
      "Epoch: 140, Train Loss: 0.006\n",
      "Epoch: 150, Train Loss: 0.006\n",
      "Epoch: 160, Train Loss: 0.005\n",
      "Epoch: 170, Train Loss: 0.005\n",
      "Epoch: 180, Train Loss: 0.004\n",
      "Epoch: 190, Train Loss: 0.004\n",
      "Epoch: 200, Train Loss: 0.004\n",
      "Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "target_model.train()\n",
    "for epoch in range(201):\n",
    "    optimizer.zero_grad()\n",
    "    out = target_model(data_target_model)\n",
    "    loss = F.cross_entropy(out[data_target_model.train_mask], y_true_tensor[data_target_model.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}')\n",
    "\n",
    "# Evaluation\n",
    "target_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = target_model(data_target_model)\n",
    "    pred = logits.argmax(dim=1)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = (pred[data_target_model.test_mask] == y_true_tensor[data_target_model.test_mask]).sum().item() / data_target_model.test_mask.sum().item()\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = torch.argmax(torch.nn.functional.softmax(model.forward(data)), axis=1).detach().numpy()\n",
    "ipysigma.Sigma(G, node_color=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(k_max, c, target_model,columns_mins,columns_maxs, iterations=1000, conf_min=0.99, rej_max=1000, k_min = 1, old_x_k=None):\n",
    "    j = 0\n",
    "    if old_x_k is not None:\n",
    "        x = old_x_k + torch.rand(1)\n",
    "    else:\n",
    "        x = torch.tensor(torch.rand(1, len(columns_mins)) * (columns_maxs.detach() - columns_mins.detach()) + columns_mins.detach(), requires_grad=False, dtype=torch.float)\n",
    "    edges = [(0,0)]\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    y_c = 0\n",
    "    k = k_max\n",
    "    for i in range(iterations):\n",
    "        y_class = torch.nn.functional.softmax(target_model.forward(data)).detach()\n",
    "        if y_class[0][c].item() > y_c:\n",
    "            if y_class[0][c].item() > conf_min and c == torch.argmax(y_class[0]).item():\n",
    "                if np.random.uniform(0, 1) <= y_class[0][c].item():\n",
    "                   return x\n",
    "            x_temp = x\n",
    "            y_c = y_class[0][c].item()\n",
    "            j = 0\n",
    "        else:\n",
    "            j += 1\n",
    "            if j>=rej_max:\n",
    "                k = max(k_min, k//2)\n",
    "                j = 0\n",
    "        indice = np.random.randint(0, 4, size=(1, k))\n",
    "        for i in indice:\n",
    "            x[0, i] = torch.rand(1) * (columns_maxs[i] - columns_mins[i]) + columns_mins[i]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shadows_datasets(k_max, c, target_model, columns_mins, columns_maxs, mutliple_of_cs, iterations=100, conf_min=0.99, rej_max=100000, k_min = 1, n=10000, apriori = False):\n",
    "    shadow_dataset = []\n",
    "    old_x_k = None\n",
    "    nb_used_a_priori = 0\n",
    "    print(f'Generating {c} label shadow...')\n",
    "    for j in range(mutliple_of_cs):\n",
    "        for i in tqdm(range(n)):\n",
    "            x_k = generate_synthetic_data(k_max, c, target_model, columns_mins, columns_maxs, iterations, conf_min, rej_max, k_min, old_x_k)\n",
    "            while x_k is None:\n",
    "                x_k = generate_synthetic_data(k_max, c, target_model, columns_mins, columns_maxs, iterations, conf_min, rej_max, k_min, old_x_k)\n",
    "            shadow_dataset.append(x_k)\n",
    "            if apriori and nb_used_a_priori < 50:\n",
    "                old_x_k = x_k\n",
    "                nb_used_a_priori += 1\n",
    "            if nb_used_a_priori >= 50:\n",
    "                for i in range(len(old_x_k[0])):\n",
    "                    if x[0][i] > 0.80 * columns_maxs[i]:\n",
    "                        x[0][i] = torch.rand(1) * (columns_maxs[i] - columns_mins[i]) + columns_mins[i]\n",
    "                    if x[0][i] < 1.20 * columns_mins[i]:\n",
    "                        x[0][i] = torch.rand(1) * (columns_maxs[i] - columns_mins[i]) + columns_mins[i]\n",
    "                        nb_used_a_priori = 0\n",
    "    print(f'{c} label shadow dataset generated\\n')\n",
    "    return shadow_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s = [0, 1, 2]\n",
    "mutliple_of_cs = 1\n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 0 label shadow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_88484/2410329687.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.rand(1, len(columns_mins)) * (columns_maxs.detach() - columns_mins.detach()) + columns_mins.detach(), requires_grad=False, dtype=torch.float)\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_88484/2410329687.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_class = torch.nn.functional.softmax(target_model.forward(data)).detach()\n",
      "100%|██████████| 10000/10000 [00:58<00:00, 170.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 label shadow dataset generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "shadow_dataset_0 = generate_shadows_datasets(4, 0, target_model, columns_mins, columns_maxs, mutliple_of_cs=mutliple_of_cs, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 label shadow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_88484/2410329687.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.rand(1, len(columns_mins)) * (columns_maxs.detach() - columns_mins.detach()) + columns_mins.detach(), requires_grad=False, dtype=torch.float)\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_88484/2410329687.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_class = torch.nn.functional.softmax(target_model.forward(data)).detach()\n",
      "100%|██████████| 10000/10000 [29:26<00:00,  5.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 label shadow dataset generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "shadow_dataset_1 = generate_shadows_datasets(4, 1, target_model, columns_mins, columns_maxs, mutliple_of_cs=mutliple_of_cs, n=n, apriori=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[7.4407, 4.0938, 4.1817, 0.3805]]),\n",
       " tensor([[7.7382, 2.9787, 3.4059, 0.1346]]),\n",
       " tensor([[8.0005, 3.2410, 3.6682, 0.3969]]),\n",
       " tensor([[8.0035, 3.2440, 3.6712, 0.3999]]),\n",
       " tensor([[6.8349, 3.6899, 4.1251, 0.1441]]),\n",
       " tensor([[6.8694, 3.7244, 4.1596, 0.1786]]),\n",
       " tensor([[7.5295, 2.1907, 2.5414, 0.2907]]),\n",
       " tensor([[7.5588, 2.2200, 2.5707, 0.3200]]),\n",
       " tensor([[7.5674, 2.2287, 2.5793, 0.3287]]),\n",
       " tensor([[7.5702, 2.2314, 2.5821, 0.3314]]),\n",
       " tensor([[7.6107, 3.1238, 3.7628, 0.2083]]),\n",
       " tensor([[7.6195, 3.1326, 3.7715, 0.2171]]),\n",
       " tensor([[7.6400, 3.1531, 3.7920, 0.2376]]),\n",
       " tensor([[7.6417, 3.1548, 3.7937, 0.2392]]),\n",
       " tensor([[7.8357, 2.8715, 3.1423, 0.4333]]),\n",
       " tensor([[7.8061, 4.3374, 4.2801, 0.5236]]),\n",
       " tensor([[7.6447, 2.1040, 2.4796, 0.2040]]),\n",
       " tensor([[7.6559, 2.1152, 2.4908, 0.2152]]),\n",
       " tensor([[7.7924, 2.2517, 2.6272, 0.3517]]),\n",
       " tensor([[7.8166, 2.2759, 2.6515, 0.3759]]),\n",
       " tensor([[6.9838, 3.7892, 3.9241, 0.2448]]),\n",
       " tensor([[7.0670, 3.8724, 4.0074, 0.3280]]),\n",
       " tensor([[6.8506, 3.7004, 4.0642, 0.1383]]),\n",
       " tensor([[6.8660, 3.7158, 4.0796, 0.1537]]),\n",
       " tensor([[6.9165, 3.7663, 4.1301, 0.2042]]),\n",
       " tensor([[6.9292, 3.7790, 4.1428, 0.2169]]),\n",
       " tensor([[7.4921, 4.1280, 4.3415, 0.3414]]),\n",
       " tensor([[7.4977, 4.1336, 4.3470, 0.3470]]),\n",
       " tensor([[7.5176, 4.1536, 4.3670, 0.3670]]),\n",
       " tensor([[6.8046, 2.0410, 2.6033, 0.1410]]),\n",
       " tensor([[7.3103, 3.0426, 3.5632, 0.1464]]),\n",
       " tensor([[7.4006, 3.1330, 3.6535, 0.2368]]),\n",
       " tensor([[7.7832, 2.8917, 3.1922, 0.2757]]),\n",
       " tensor([[7.8459, 2.9545, 3.2550, 0.3385]]),\n",
       " tensor([[7.9073, 3.0159, 3.3164, 0.3999]]),\n",
       " tensor([[7.9191, 3.0277, 3.3281, 0.4117]]),\n",
       " tensor([[7.9266, 3.0352, 3.3356, 0.4192]]),\n",
       " tensor([[7.5502, 3.0019, 3.4631, 0.2108]]),\n",
       " tensor([[7.5854, 3.0371, 3.4983, 0.2460]]),\n",
       " tensor([[7.6575, 3.1092, 3.5704, 0.3181]]),\n",
       " tensor([[7.8212, 2.8820, 3.1683, 0.4409]]),\n",
       " tensor([[7.3542, 2.0420, 2.7463, 0.1420]]),\n",
       " tensor([[7.3648, 2.0526, 2.7569, 0.1526]]),\n",
       " tensor([[7.4043, 2.9202, 3.2623, 0.1921]]),\n",
       " tensor([[7.5217, 3.0377, 3.3797, 0.3096]]),\n",
       " tensor([[7.5396, 3.0556, 3.3976, 0.3275]]),\n",
       " tensor([[7.5556, 3.0716, 3.4136, 0.3435]]),\n",
       " tensor([[7.6067, 3.1226, 3.4647, 0.3945]]),\n",
       " tensor([[7.6835, 4.2557, 4.5968, 0.1232]]),\n",
       " tensor([[7.8101, 4.3823, 4.7234, 0.2498]]),\n",
       " tensor([[7.8673, 4.4394, 4.7806, 0.3070]]),\n",
       " tensor([[7.8302, 4.4024, 4.7435, 0.2699]]),\n",
       " tensor([[7.8923, 4.4645, 4.8056, 0.3320]]),\n",
       " tensor([[7.8351, 4.4072, 4.7484, 0.2748]]),\n",
       " tensor([[6.4240, 2.9471, 3.3284, 0.1088]]),\n",
       " tensor([[7.8700, 4.4422, 4.7833, 0.3097]]),\n",
       " tensor([[7.8576, 4.4298, 4.7709, 0.2973]]),\n",
       " tensor([[7.8926, 4.4648, 4.8059, 0.3323]]),\n",
       " tensor([[7.8913, 4.4635, 4.8046, 0.3310]]),\n",
       " tensor([[7.8878, 4.4600, 4.8011, 0.3275]]),\n",
       " tensor([[7.8389, 4.4111, 4.7522, 0.2786]]),\n",
       " tensor([[7.6424, 2.8922, 3.1932, 0.1277]]),\n",
       " tensor([[7.8604, 4.4326, 4.7737, 0.3001]]),\n",
       " tensor([[6.8688, 3.7125, 3.9963, 0.2505]]),\n",
       " tensor([[7.8112, 4.3833, 4.7245, 0.2509]]),\n",
       " tensor([[7.8540, 4.4262, 4.7673, 0.2937]]),\n",
       " tensor([[7.8324, 4.4045, 4.7457, 0.2721]]),\n",
       " tensor([[6.6935, 2.0213, 2.6184, 0.1213]]),\n",
       " tensor([[7.8110, 4.3831, 4.7243, 0.2506]]),\n",
       " tensor([[7.8562, 4.4284, 4.7695, 0.2959]]),\n",
       " tensor([[7.8500, 4.4222, 4.7633, 0.2897]]),\n",
       " tensor([[7.2712, 2.8752, 3.1516, 0.1207]]),\n",
       " tensor([[7.3788, 4.0525, 4.2639, 0.1011]]),\n",
       " tensor([[7.8704, 4.4426, 4.7837, 0.3101]]),\n",
       " tensor([[7.4360, 4.0906, 4.2780, 0.1013]]),\n",
       " tensor([[7.8791, 4.4512, 4.7924, 0.3188]]),\n",
       " tensor([[7.8817, 4.4538, 4.7950, 0.3214]]),\n",
       " tensor([[7.2853, 2.8560, 3.1043, 0.1756]]),\n",
       " tensor([[7.8646, 4.4368, 4.7779, 0.3043]]),\n",
       " tensor([[7.8508, 4.4230, 4.7641, 0.2905]]),\n",
       " tensor([[7.8882, 4.4603, 4.8015, 0.3279]]),\n",
       " tensor([[7.8289, 4.4011, 4.7422, 0.2686]]),\n",
       " tensor([[7.8650, 4.4371, 4.7783, 0.3047]]),\n",
       " tensor([[7.4683, 4.1122, 4.2324, 0.3137]]),\n",
       " tensor([[7.8592, 4.4314, 4.7725, 0.2989]]),\n",
       " tensor([[7.8517, 4.4239, 4.7650, 0.2914]]),\n",
       " tensor([[7.2496, 3.4477, 3.6280, 0.3155]]),\n",
       " tensor([[7.8424, 4.4146, 4.7557, 0.2821]]),\n",
       " tensor([[7.8599, 2.0340, 2.8427, 0.1340]]),\n",
       " tensor([[7.8410, 4.4132, 4.7544, 0.2807]]),\n",
       " tensor([[7.3385, 2.9056, 3.2262, 0.1233]]),\n",
       " tensor([[7.5404, 2.0065, 2.6625, 0.1065]]),\n",
       " tensor([[7.6957, 3.0862, 3.6703, 0.2797]]),\n",
       " tensor([[7.8296, 4.4018, 4.7429, 0.2693]]),\n",
       " tensor([[7.8388, 4.4110, 4.7521, 0.2785]]),\n",
       " tensor([[7.8818, 4.4540, 4.7951, 0.3215]]),\n",
       " tensor([[7.8625, 4.4347, 4.7758, 0.3022]]),\n",
       " tensor([[7.8160, 4.3882, 4.7293, 0.2557]]),\n",
       " tensor([[7.8227, 4.3949, 4.7360, 0.2624]]),\n",
       " tensor([[7.3729, 3.0031, 3.4660, 0.2018]]),\n",
       " tensor([[7.8123, 4.3845, 4.7256, 0.2520]]),\n",
       " tensor([[7.8304, 4.4026, 4.7437, 0.2701]]),\n",
       " tensor([[7.8569, 4.4291, 4.7702, 0.2966]]),\n",
       " tensor([[7.8418, 4.4140, 4.7551, 0.2815]]),\n",
       " tensor([[7.6819, 4.2546, 4.8177, 0.1492]]),\n",
       " tensor([[7.7154, 2.8670, 3.1313, 0.2622]]),\n",
       " tensor([[7.6996, 2.9567, 3.3518, 0.3284]]),\n",
       " tensor([[7.0248, 3.8165, 4.1178, 0.2731]]),\n",
       " tensor([[7.8401, 4.4123, 4.7534, 0.2798]]),\n",
       " tensor([[7.8723, 4.4444, 4.7856, 0.3120]]),\n",
       " tensor([[7.6129, 4.2086, 4.2716, 0.1718]]),\n",
       " tensor([[7.8633, 4.4354, 4.7766, 0.3030]]),\n",
       " tensor([[7.8478, 4.4200, 4.7611, 0.2875]]),\n",
       " tensor([[6.9784, 2.9955, 3.4474, 0.1250]]),\n",
       " tensor([[7.8837, 4.4559, 4.7970, 0.3234]]),\n",
       " tensor([[7.8855, 4.4577, 4.7988, 0.3252]]),\n",
       " tensor([[7.8764, 4.4486, 4.7897, 0.3161]]),\n",
       " tensor([[7.8271, 4.3993, 4.7404, 0.2668]]),\n",
       " tensor([[7.8505, 4.4226, 4.7638, 0.2902]]),\n",
       " tensor([[7.3484, 2.9650, 3.3723, 0.2433]]),\n",
       " tensor([[7.8910, 4.4631, 4.8043, 0.3307]]),\n",
       " tensor([[7.0403, 2.0405, 2.4610, 0.1405]]),\n",
       " tensor([[7.8945, 2.9159, 3.2515, 0.3712]]),\n",
       " tensor([[7.8817, 4.4539, 4.7951, 0.3214]]),\n",
       " tensor([[7.8875, 4.4597, 4.8008, 0.3272]]),\n",
       " tensor([[7.8581, 4.4303, 4.7714, 0.2978]]),\n",
       " tensor([[7.8751, 4.4473, 4.7884, 0.3148]]),\n",
       " tensor([[7.8578, 4.4300, 4.7711, 0.2975]]),\n",
       " tensor([[7.8527, 4.4249, 4.7660, 0.2924]]),\n",
       " tensor([[7.8379, 4.4100, 4.7512, 0.2776]]),\n",
       " tensor([[7.9393, 2.9511, 3.3381, 0.3790]]),\n",
       " tensor([[7.8374, 4.4095, 4.7507, 0.2771]]),\n",
       " tensor([[7.8627, 4.4348, 4.7760, 0.3023]]),\n",
       " tensor([[6.9301, 3.7534, 4.1469, 0.1712]]),\n",
       " tensor([[7.8397, 4.4118, 4.7530, 0.2794]]),\n",
       " tensor([[7.8384, 4.4105, 4.7517, 0.2781]]),\n",
       " tensor([[7.8881, 4.4602, 4.8014, 0.3278]]),\n",
       " tensor([[7.8613, 4.4335, 4.7746, 0.3010]]),\n",
       " tensor([[7.8536, 4.4258, 4.7669, 0.2933]]),\n",
       " tensor([[7.8664, 4.4386, 4.7797, 0.3061]]),\n",
       " tensor([[7.6942, 2.8807, 3.1649, 0.1555]]),\n",
       " tensor([[7.8174, 4.3896, 4.7307, 0.2571]]),\n",
       " tensor([[7.7486, 3.1134, 3.7371, 0.1578]]),\n",
       " tensor([[7.8630, 2.7896, 2.9410, 0.4379]]),\n",
       " tensor([[7.8936, 4.4657, 4.8069, 0.3332]]),\n",
       " tensor([[7.8329, 4.4050, 4.7462, 0.2725]]),\n",
       " tensor([[7.8599, 4.4321, 4.7732, 0.2996]]),\n",
       " tensor([[6.6555, 2.9131, 3.2447, 0.2037]]),\n",
       " tensor([[7.8329, 4.4051, 4.7462, 0.2726]]),\n",
       " tensor([[7.8651, 4.4372, 4.7784, 0.3048]]),\n",
       " tensor([[7.8713, 4.4435, 4.7846, 0.3110]]),\n",
       " tensor([[7.8939, 4.4661, 4.8072, 0.3336]]),\n",
       " tensor([[7.8133, 4.3855, 4.7266, 0.2530]]),\n",
       " tensor([[7.8517, 4.4239, 4.7650, 0.2914]]),\n",
       " tensor([[7.8662, 4.4384, 4.7795, 0.3059]]),\n",
       " tensor([[7.8934, 4.4655, 4.8067, 0.3331]]),\n",
       " tensor([[7.8694, 4.4416, 4.7827, 0.3091]]),\n",
       " tensor([[7.8216, 4.3938, 4.7349, 0.2613]]),\n",
       " tensor([[7.8294, 4.4016, 4.7428, 0.2691]]),\n",
       " tensor([[7.8613, 4.4335, 4.7747, 0.3010]]),\n",
       " tensor([[7.0212, 3.8141, 4.1886, 0.2274]]),\n",
       " tensor([[7.1252, 3.8834, 4.1752, 0.1019]]),\n",
       " tensor([[7.8029, 2.7745, 2.9040, 0.4310]]),\n",
       " tensor([[7.8733, 4.4455, 4.7867, 0.3130]]),\n",
       " tensor([[7.8425, 4.4146, 4.7558, 0.2822]]),\n",
       " tensor([[7.8943, 4.4665, 4.8076, 0.3340]]),\n",
       " tensor([[7.8279, 4.4000, 4.7412, 0.2676]]),\n",
       " tensor([[7.3195, 4.0130, 4.1758, 0.2820]]),\n",
       " tensor([[7.8561, 4.4283, 4.7694, 0.2958]]),\n",
       " tensor([[7.8919, 4.4641, 4.8052, 0.3316]]),\n",
       " tensor([[7.6925, 4.2616, 4.5435, 0.1356]]),\n",
       " tensor([[7.4068, 2.9041, 3.2225, 0.2046]]),\n",
       " tensor([[7.3586, 4.0391, 4.1967, 0.1236]]),\n",
       " tensor([[7.8785, 4.4506, 4.7918, 0.3182]]),\n",
       " tensor([[7.8844, 4.4566, 4.7977, 0.3241]]),\n",
       " tensor([[7.8111, 4.3832, 4.7244, 0.2507]]),\n",
       " tensor([[7.8889, 4.3926, 4.6851, 0.2987]]),\n",
       " tensor([[7.8787, 4.4509, 4.7920, 0.3184]]),\n",
       " tensor([[7.8424, 4.4146, 4.7557, 0.2821]]),\n",
       " tensor([[7.8763, 4.4484, 4.7896, 0.3160]]),\n",
       " tensor([[7.8120, 4.3842, 4.7253, 0.2517]]),\n",
       " tensor([[7.6339, 4.2226, 4.8199, 0.1323]]),\n",
       " tensor([[7.8162, 4.3884, 4.7295, 0.2559]]),\n",
       " tensor([[7.8655, 4.4376, 4.7788, 0.3052]]),\n",
       " tensor([[7.8507, 4.4228, 4.7640, 0.2904]]),\n",
       " tensor([[7.8112, 4.3834, 4.7245, 0.2509]]),\n",
       " tensor([[7.8913, 4.4635, 4.8046, 0.3310]]),\n",
       " tensor([[7.8534, 4.3689, 4.9539, 0.1681]]),\n",
       " tensor([[7.8802, 4.4524, 4.7935, 0.3199]]),\n",
       " tensor([[7.8508, 4.4230, 4.7641, 0.2905]]),\n",
       " tensor([[7.8690, 4.4412, 4.7823, 0.3087]]),\n",
       " tensor([[7.8114, 4.3835, 4.7247, 0.2511]]),\n",
       " tensor([[7.7200, 2.8526, 3.0960, 0.2440]]),\n",
       " tensor([[7.8377, 4.4099, 4.7510, 0.2774]]),\n",
       " tensor([[7.8220, 4.3941, 4.7353, 0.2616]]),\n",
       " tensor([[7.8912, 4.4634, 4.8045, 0.3309]]),\n",
       " tensor([[7.8540, 4.4262, 4.7673, 0.2937]]),\n",
       " tensor([[7.8159, 4.3881, 4.7293, 0.2556]]),\n",
       " tensor([[7.8623, 4.4345, 4.7756, 0.3020]]),\n",
       " tensor([[7.8215, 4.3937, 4.7348, 0.2612]]),\n",
       " tensor([[7.3579, 2.0257, 2.5451, 0.1257]]),\n",
       " tensor([[7.8416, 4.4137, 4.7549, 0.2813]]),\n",
       " tensor([[7.3555, 4.0370, 4.3151, 0.2895]]),\n",
       " tensor([[7.8646, 4.4368, 4.7779, 0.3043]]),\n",
       " tensor([[7.8148, 4.3869, 4.7281, 0.2545]]),\n",
       " tensor([[7.8852, 4.4574, 4.7985, 0.3249]]),\n",
       " tensor([[7.8481, 4.4202, 4.7614, 0.2878]]),\n",
       " tensor([[7.8708, 4.4429, 4.7841, 0.3105]]),\n",
       " tensor([[8.3642, 4.9364, 5.2775, 0.3232]]),\n",
       " tensor([[7.8853, 4.4574, 4.7986, 0.3250]]),\n",
       " tensor([[7.8708, 4.4430, 4.7841, 0.3105]]),\n",
       " tensor([[7.8919, 4.4641, 4.8052, 0.3316]]),\n",
       " tensor([[7.8906, 4.4627, 4.8039, 0.3303]]),\n",
       " tensor([[7.9190, 2.9231, 3.2693, 0.3587]]),\n",
       " tensor([[7.8663, 4.4384, 4.7796, 0.3060]]),\n",
       " tensor([[7.8879, 4.4600, 4.8012, 0.3276]]),\n",
       " tensor([[7.6858, 2.1266, 2.7714, 0.2266]]),\n",
       " tensor([[7.8505, 4.4227, 4.7638, 0.2902]]),\n",
       " tensor([[7.8670, 4.4392, 4.7803, 0.3067]]),\n",
       " tensor([[7.8497, 4.4219, 4.7630, 0.2894]]),\n",
       " tensor([[7.4123, 4.0749, 4.5706, 0.1625]]),\n",
       " tensor([[7.8693, 4.4415, 4.7826, 0.3090]]),\n",
       " tensor([[7.8908, 4.4630, 4.8041, 0.3305]]),\n",
       " tensor([[6.9505, 2.9106, 3.2386, 0.2825]]),\n",
       " tensor([[7.8761, 4.4483, 4.7894, 0.3158]]),\n",
       " tensor([[7.8179, 4.3901, 4.7312, 0.2576]]),\n",
       " tensor([[7.8848, 4.4570, 4.7981, 0.3245]]),\n",
       " tensor([[7.8563, 4.4285, 4.7696, 0.2960]]),\n",
       " tensor([[7.8236, 4.3957, 4.7369, 0.2633]]),\n",
       " tensor([[7.0687, 3.8458, 4.0210, 0.2391]]),\n",
       " tensor([[7.8114, 4.3836, 4.7247, 0.2511]]),\n",
       " tensor([[7.8558, 4.4279, 4.7691, 0.2955]]),\n",
       " tensor([[7.8932, 4.4654, 4.8065, 0.3329]]),\n",
       " tensor([[7.8879, 2.9245, 3.2728, 0.3506]]),\n",
       " tensor([[7.6419, 4.2279, 4.3794, 0.4090]]),\n",
       " tensor([[7.8411, 4.4133, 4.7544, 0.2808]]),\n",
       " tensor([[7.8903, 4.4625, 4.8036, 0.3300]]),\n",
       " tensor([[7.8486, 4.4208, 4.7619, 0.2883]]),\n",
       " tensor([[7.8533, 4.4255, 4.7666, 0.2930]]),\n",
       " tensor([[7.8438, 4.4160, 4.7571, 0.2835]]),\n",
       " tensor([[7.8847, 4.3898, 4.6958, 0.3442]]),\n",
       " tensor([[7.8156, 4.3877, 4.7289, 0.2553]]),\n",
       " tensor([[7.8447, 4.4168, 4.7580, 0.2844]]),\n",
       " tensor([[7.8504, 4.4225, 4.7637, 0.2901]]),\n",
       " tensor([[7.8330, 4.4052, 4.7463, 0.2727]]),\n",
       " tensor([[7.8128, 4.3850, 4.7261, 0.2525]]),\n",
       " tensor([[7.8120, 4.3841, 4.7253, 0.2517]]),\n",
       " tensor([[7.8883, 4.4604, 4.8016, 0.3280]]),\n",
       " tensor([[7.5037, 3.0598, 3.6052, 0.1238]]),\n",
       " tensor([[7.4168, 4.0779, 4.2980, 0.1283]]),\n",
       " tensor([[7.7734, 2.9737, 3.3937, 0.2407]]),\n",
       " tensor([[7.8166, 4.3888, 4.7299, 0.2563]]),\n",
       " tensor([[7.8241, 3.1387, 3.7992, 0.1543]]),\n",
       " tensor([[7.8572, 4.4294, 4.7705, 0.2969]]),\n",
       " tensor([[7.8312, 4.4034, 4.7446, 0.2709]]),\n",
       " tensor([[7.8741, 4.4463, 4.7875, 0.3138]]),\n",
       " tensor([[7.8268, 4.3990, 4.7402, 0.2665]]),\n",
       " tensor([[7.8599, 4.4321, 4.7732, 0.2996]]),\n",
       " tensor([[7.7597, 2.9665, 3.3759, 0.2307]]),\n",
       " tensor([[7.8709, 4.4430, 4.7842, 0.3106]]),\n",
       " tensor([[7.8476, 4.4198, 4.7609, 0.2873]]),\n",
       " tensor([[7.8660, 4.4382, 4.7793, 0.3057]]),\n",
       " tensor([[7.8424, 4.4146, 4.7557, 0.2821]]),\n",
       " tensor([[7.8438, 4.4159, 4.7571, 0.2834]]),\n",
       " tensor([[7.8556, 4.4277, 4.7689, 0.2953]]),\n",
       " tensor([[7.8652, 4.4374, 4.7785, 0.3049]]),\n",
       " tensor([[6.3593, 2.9652, 3.3728, 0.1291]]),\n",
       " tensor([[7.1641, 3.9094, 4.3542, 0.1091]]),\n",
       " tensor([[7.8370, 4.4092, 4.7503, 0.2767]]),\n",
       " tensor([[7.8281, 4.4003, 4.7414, 0.2678]]),\n",
       " tensor([[7.8330, 4.4052, 4.7463, 0.2727]]),\n",
       " tensor([[7.8173, 4.3895, 4.7306, 0.2570]]),\n",
       " tensor([[7.7833, 2.9404, 3.3119, 0.2828]]),\n",
       " tensor([[7.8432, 4.4154, 4.7565, 0.2829]]),\n",
       " tensor([[7.5364, 2.9017, 3.2168, 0.3727]]),\n",
       " tensor([[7.8495, 4.4217, 4.7628, 0.2892]]),\n",
       " tensor([[7.8597, 4.4319, 4.7730, 0.2994]]),\n",
       " tensor([[7.8710, 4.4432, 4.7843, 0.3107]]),\n",
       " tensor([[7.8588, 4.4310, 4.7721, 0.2985]]),\n",
       " tensor([[7.8536, 4.4257, 4.7669, 0.2933]]),\n",
       " tensor([[7.7820, 4.3213, 4.3604, 0.4110]]),\n",
       " tensor([[7.8708, 2.1296, 2.7198, 0.2296]]),\n",
       " tensor([[7.8142, 4.3864, 4.7275, 0.2539]]),\n",
       " tensor([[7.8927, 4.4649, 4.8061, 0.3324]]),\n",
       " tensor([[7.8965, 3.0334, 3.5404, 0.1356]]),\n",
       " tensor([[7.9764, 2.8785, 3.1595, 0.4161]]),\n",
       " tensor([[7.8140, 4.3862, 4.7274, 0.2537]]),\n",
       " tensor([[7.2138, 2.9785, 3.4055, 0.1750]]),\n",
       " tensor([[7.8604, 4.4325, 4.7737, 0.3001]]),\n",
       " tensor([[7.7738, 2.0020, 2.7617, 0.1020]]),\n",
       " tensor([[7.8565, 4.4287, 4.7698, 0.2962]]),\n",
       " tensor([[7.8934, 4.4656, 4.8068, 0.3331]]),\n",
       " tensor([[7.8124, 4.3846, 4.7257, 0.2521]]),\n",
       " tensor([[7.8222, 4.3944, 4.7355, 0.2619]]),\n",
       " tensor([[7.8528, 4.4250, 4.7661, 0.2925]]),\n",
       " tensor([[7.8894, 4.4616, 4.8027, 0.3291]]),\n",
       " tensor([[7.8617, 4.4338, 4.7750, 0.3013]]),\n",
       " tensor([[7.8187, 4.3909, 4.7320, 0.2584]]),\n",
       " tensor([[7.7793, 4.3195, 4.5645, 0.1890]]),\n",
       " tensor([[7.8752, 4.4474, 4.7885, 0.3149]]),\n",
       " tensor([[7.8541, 4.4263, 4.7674, 0.2938]]),\n",
       " tensor([[7.8875, 4.4597, 4.8008, 0.3272]]),\n",
       " tensor([[7.8272, 4.3994, 4.7405, 0.2669]]),\n",
       " tensor([[7.8713, 4.4434, 4.7846, 0.3110]]),\n",
       " tensor([[7.8631, 4.4353, 4.7764, 0.3028]]),\n",
       " tensor([[7.1225, 3.8817, 4.3262, 0.1241]]),\n",
       " tensor([[7.8188, 4.3910, 4.7321, 0.2585]]),\n",
       " tensor([[7.5094, 2.9531, 3.3430, 0.2761]]),\n",
       " tensor([[7.4560, 2.8698, 3.1383, 0.1799]]),\n",
       " tensor([[7.8544, 4.4266, 4.7677, 0.2941]]),\n",
       " tensor([[7.8778, 4.4500, 4.7911, 0.3175]]),\n",
       " tensor([[7.8569, 4.4291, 4.7702, 0.2966]]),\n",
       " tensor([[7.4943, 4.1295, 4.3729, 0.3543]]),\n",
       " tensor([[7.8659, 4.4380, 4.7792, 0.3056]]),\n",
       " tensor([[7.1720, 2.9758, 3.3988, 0.2749]]),\n",
       " tensor([[7.8187, 4.3909, 4.7320, 0.2584]]),\n",
       " tensor([[7.8620, 4.4342, 4.7753, 0.3017]]),\n",
       " tensor([[7.8766, 4.4487, 4.7899, 0.3163]]),\n",
       " tensor([[7.8521, 4.4242, 4.7654, 0.2918]]),\n",
       " tensor([[7.8319, 4.4041, 4.7452, 0.2716]]),\n",
       " tensor([[7.7638, 3.0845, 3.6660, 0.1533]]),\n",
       " tensor([[7.8532, 4.4253, 4.7665, 0.2929]]),\n",
       " tensor([[7.8383, 4.4105, 4.7516, 0.2780]]),\n",
       " tensor([[7.8161, 4.3883, 4.7294, 0.2558]]),\n",
       " tensor([[7.8482, 4.4204, 4.7615, 0.2879]]),\n",
       " tensor([[7.8708, 4.4430, 4.7842, 0.3105]]),\n",
       " tensor([[7.8124, 4.3846, 4.7257, 0.2521]]),\n",
       " tensor([[7.8708, 4.4430, 4.7841, 0.3105]]),\n",
       " tensor([[7.8335, 4.4057, 4.7468, 0.2732]]),\n",
       " tensor([[6.5329, 2.9905, 3.4350, 0.1236]]),\n",
       " tensor([[7.8405, 4.4127, 4.7538, 0.2802]]),\n",
       " tensor([[7.7738, 4.3159, 4.4084, 0.1608]]),\n",
       " tensor([[7.8831, 4.4553, 4.7964, 0.3228]]),\n",
       " tensor([[7.8521, 4.4243, 4.7654, 0.2918]]),\n",
       " tensor([[7.8281, 4.4003, 4.7414, 0.2678]]),\n",
       " tensor([[7.8341, 4.4062, 4.7474, 0.2738]]),\n",
       " tensor([[7.2401, 3.0325, 3.5383, 0.2140]]),\n",
       " tensor([[7.8264, 4.3986, 4.7397, 0.2661]]),\n",
       " tensor([[7.8203, 4.3925, 4.7336, 0.2600]]),\n",
       " tensor([[7.8543, 4.4265, 4.7676, 0.2940]]),\n",
       " tensor([[7.3788, 3.0572, 3.5990, 0.2389]]),\n",
       " tensor([[7.4289, 4.0859, 4.4395, 0.2510]]),\n",
       " tensor([[7.8305, 4.4027, 4.7438, 0.2702]]),\n",
       " tensor([[6.9425, 3.7617, 4.0890, 0.1101]]),\n",
       " tensor([[7.8381, 4.3588, 4.4864, 0.2363]]),\n",
       " tensor([[7.8318, 4.4040, 4.7452, 0.2715]]),\n",
       " tensor([[7.8695, 4.4417, 4.7828, 0.3092]]),\n",
       " tensor([[7.8424, 4.4146, 4.7557, 0.2821]]),\n",
       " tensor([[7.8590, 4.4311, 4.7723, 0.2987]]),\n",
       " tensor([[7.7196, 4.2797, 4.7654, 0.1022]]),\n",
       " tensor([[7.7688, 4.3125, 4.2442, 0.4219]]),\n",
       " tensor([[7.8104, 4.3826, 4.7237, 0.2501]]),\n",
       " tensor([[7.8260, 4.3982, 4.7394, 0.2657]]),\n",
       " tensor([[7.6764, 4.2509, 4.8631, 0.1140]]),\n",
       " tensor([[7.8521, 4.4242, 4.7654, 0.2918]]),\n",
       " tensor([[6.7228, 2.9029, 3.2196, 0.2042]]),\n",
       " tensor([[7.8669, 4.4391, 4.7802, 0.3066]]),\n",
       " tensor([[7.8516, 4.4238, 4.7649, 0.2913]]),\n",
       " tensor([[7.8886, 3.1186, 3.7498, 0.2049]]),\n",
       " tensor([[7.8229, 4.3951, 4.7362, 0.2626]]),\n",
       " tensor([[7.8802, 4.4524, 4.7935, 0.3199]]),\n",
       " tensor([[7.8401, 4.4123, 4.7534, 0.2798]]),\n",
       " tensor([[7.8893, 4.3929, 4.5177, 0.3097]]),\n",
       " tensor([[7.8743, 4.4464, 4.7876, 0.3140]]),\n",
       " tensor([[7.8534, 4.4256, 4.7667, 0.2931]]),\n",
       " tensor([[7.8446, 4.4167, 4.7579, 0.2843]]),\n",
       " tensor([[7.8617, 4.4339, 4.7750, 0.3014]]),\n",
       " tensor([[7.8653, 4.4375, 4.7786, 0.3050]]),\n",
       " tensor([[7.1760, 3.0955, 3.6931, 0.1720]]),\n",
       " tensor([[7.8321, 4.4043, 4.7454, 0.2718]]),\n",
       " tensor([[7.8690, 4.4412, 4.7823, 0.3087]]),\n",
       " tensor([[7.8307, 4.4029, 4.7440, 0.2704]]),\n",
       " tensor([[7.8707, 4.4429, 4.7840, 0.3104]]),\n",
       " tensor([[7.8270, 4.3991, 4.7403, 0.2666]]),\n",
       " tensor([[7.8288, 4.4009, 4.7421, 0.2684]]),\n",
       " tensor([[7.8829, 4.4550, 4.7962, 0.3226]]),\n",
       " tensor([[7.8979, 2.0767, 2.5026, 0.1767]]),\n",
       " tensor([[7.8575, 4.4297, 4.7708, 0.2972]]),\n",
       " tensor([[7.8520, 4.4241, 4.7653, 0.2917]]),\n",
       " tensor([[7.8587, 4.4309, 4.7720, 0.2984]]),\n",
       " tensor([[6.8449, 2.0229, 2.5254, 0.1229]]),\n",
       " tensor([[7.8432, 4.4154, 4.7565, 0.2829]]),\n",
       " tensor([[7.8342, 4.4064, 4.7475, 0.2739]]),\n",
       " tensor([[7.8888, 4.4609, 4.8021, 0.3285]]),\n",
       " tensor([[7.8919, 4.4641, 4.8052, 0.3316]]),\n",
       " tensor([[7.8436, 4.4157, 4.7569, 0.2833]]),\n",
       " tensor([[7.8493, 4.4214, 4.7626, 0.2890]]),\n",
       " tensor([[6.7109, 3.0125, 3.4891, 0.1139]]),\n",
       " tensor([[7.8789, 4.4510, 4.7922, 0.3186]]),\n",
       " tensor([[7.8126, 4.3848, 4.7259, 0.2523]]),\n",
       " tensor([[7.4174, 4.0782, 4.1421, 0.2246]]),\n",
       " tensor([[7.8705, 4.4427, 4.7838, 0.3102]]),\n",
       " tensor([[7.8174, 4.3896, 4.7307, 0.2571]]),\n",
       " tensor([[7.8919, 4.4641, 4.8052, 0.3316]]),\n",
       " tensor([[7.8758, 4.4480, 4.7891, 0.3155]]),\n",
       " tensor([[7.8495, 4.4217, 4.7628, 0.2892]]),\n",
       " tensor([[7.7802, 2.9513, 3.3385, 0.1862]]),\n",
       " tensor([[7.8155, 4.3876, 4.7288, 0.2552]]),\n",
       " tensor([[7.8615, 2.9182, 3.2572, 0.1855]]),\n",
       " tensor([[7.8568, 4.4290, 4.7701, 0.2965]]),\n",
       " tensor([[7.8848, 4.4570, 4.7981, 0.3245]]),\n",
       " tensor([[7.8695, 4.4416, 4.7828, 0.3092]]),\n",
       " tensor([[7.8657, 4.4379, 4.7790, 0.3054]]),\n",
       " tensor([[7.8703, 4.4424, 4.7836, 0.3100]]),\n",
       " tensor([[7.8450, 4.4171, 4.7583, 0.2847]]),\n",
       " tensor([[7.8892, 4.4614, 4.8025, 0.3289]]),\n",
       " tensor([[7.8448, 4.4169, 4.7581, 0.2844]]),\n",
       " tensor([[7.8942, 4.4664, 4.8075, 0.3339]]),\n",
       " tensor([[8.4678, 5.0399, 5.3811, 0.1067]]),\n",
       " tensor([[7.8889, 4.4611, 4.8022, 0.3286]]),\n",
       " tensor([[7.8424, 4.4146, 4.7557, 0.2821]]),\n",
       " tensor([[7.8135, 4.3857, 4.7268, 0.2532]]),\n",
       " tensor([[7.0996, 2.8594, 3.1127, 0.2188]]),\n",
       " tensor([[7.8895, 4.4617, 4.8028, 0.3292]]),\n",
       " tensor([[7.5065, 2.9629, 3.3260, 0.1837]]),\n",
       " tensor([[7.8747, 4.4468, 4.7880, 0.3144]]),\n",
       " tensor([[7.8758, 4.4480, 4.7891, 0.3155]]),\n",
       " tensor([[7.8839, 4.4561, 4.7972, 0.3236]]),\n",
       " tensor([[7.7809, 2.8401, 3.0651, 0.2519]]),\n",
       " tensor([[7.6948, 2.8162, 3.0064, 0.2960]]),\n",
       " tensor([[7.8266, 4.3988, 4.7399, 0.2663]]),\n",
       " tensor([[7.8881, 4.4603, 4.8014, 0.3278]]),\n",
       " tensor([[7.8931, 4.4652, 4.8064, 0.3327]]),\n",
       " tensor([[7.8424, 4.4146, 4.7557, 0.2821]]),\n",
       " tensor([[7.8199, 4.3921, 4.7332, 0.2596]]),\n",
       " tensor([[7.8638, 4.4360, 4.7771, 0.3035]]),\n",
       " tensor([[7.8695, 4.4417, 4.7828, 0.3092]]),\n",
       " tensor([[7.6394, 4.2263, 4.5392, 0.2833]]),\n",
       " tensor([[7.8132, 4.3853, 4.7265, 0.2529]]),\n",
       " tensor([[7.4022, 4.0681, 4.4623, 0.1064]]),\n",
       " tensor([[7.8769, 4.4491, 4.7902, 0.3166]]),\n",
       " tensor([[7.8586, 4.4308, 4.7719, 0.2983]]),\n",
       " tensor([[7.8533, 4.4255, 4.7666, 0.2930]]),\n",
       " tensor([[7.9783, 2.8278, 3.0351, 0.4180]]),\n",
       " tensor([[7.8458, 4.4179, 4.7591, 0.2855]]),\n",
       " tensor([[7.8268, 4.3990, 4.7401, 0.2665]]),\n",
       " tensor([[7.8941, 4.4663, 4.8074, 0.3338]]),\n",
       " tensor([[7.5873, 4.1916, 4.4569, 0.3079]]),\n",
       " tensor([[7.8553, 4.4275, 4.7686, 0.2950]]),\n",
       " tensor([[7.8426, 4.4148, 4.7559, 0.2823]]),\n",
       " tensor([[7.8516, 4.4237, 4.7649, 0.2913]]),\n",
       " tensor([[7.8914, 4.4636, 4.8047, 0.3311]]),\n",
       " tensor([[7.8110, 4.3832, 4.7243, 0.2507]]),\n",
       " tensor([[7.8543, 4.4265, 4.7676, 0.2940]]),\n",
       " tensor([[7.8913, 4.4634, 4.8046, 0.3310]]),\n",
       " tensor([[7.8458, 4.4179, 4.7591, 0.2855]]),\n",
       " tensor([[7.8545, 4.4267, 4.7678, 0.2942]]),\n",
       " tensor([[7.8175, 4.3897, 4.7308, 0.2572]]),\n",
       " tensor([[7.8734, 4.4456, 4.7867, 0.3131]]),\n",
       " tensor([[7.8158, 4.3880, 4.7291, 0.2555]]),\n",
       " tensor([[7.6986, 2.8220, 3.0207, 0.3106]]),\n",
       " tensor([[7.8761, 4.4483, 4.7894, 0.3158]]),\n",
       " tensor([[7.2245, 3.1808, 3.9028, 0.1065]]),\n",
       " tensor([[7.8881, 4.4603, 4.8014, 0.3278]]),\n",
       " tensor([[8.2303, 4.8025, 5.1436, 0.1123]]),\n",
       " tensor([[7.8457, 4.4179, 4.7590, 0.2854]]),\n",
       " tensor([[7.8473, 2.8201, 3.0162, 0.4200]]),\n",
       " tensor([[7.8622, 4.4344, 4.7755, 0.3019]]),\n",
       " tensor([[7.8934, 4.4655, 4.8067, 0.3331]]),\n",
       " tensor([[7.8885, 4.4606, 4.8018, 0.3281]]),\n",
       " tensor([[7.8786, 4.4508, 4.7919, 0.3183]]),\n",
       " tensor([[7.8788, 4.4509, 4.7921, 0.3185]]),\n",
       " tensor([[7.8351, 4.4072, 4.7484, 0.2748]]),\n",
       " tensor([[7.8720, 4.4442, 4.7853, 0.3117]]),\n",
       " tensor([[7.6326, 2.0547, 2.5999, 0.1547]]),\n",
       " tensor([[7.8426, 4.4148, 4.7560, 0.2823]]),\n",
       " tensor([[7.8940, 4.4662, 4.8073, 0.3337]]),\n",
       " tensor([[7.8243, 4.3965, 4.7376, 0.2640]]),\n",
       " tensor([[7.8568, 4.4290, 4.7701, 0.2965]]),\n",
       " tensor([[7.8416, 4.4138, 4.7549, 0.2813]]),\n",
       " tensor([[7.8123, 4.3845, 4.7256, 0.2520]]),\n",
       " tensor([[7.8589, 4.4311, 4.7723, 0.2986]]),\n",
       " tensor([[7.8122, 4.3844, 4.7255, 0.2519]]),\n",
       " tensor([[7.8753, 4.4474, 4.7886, 0.3150]]),\n",
       " tensor([[7.8521, 4.4243, 4.7654, 0.2918]]),\n",
       " tensor([[7.8322, 4.4043, 4.7455, 0.2719]]),\n",
       " tensor([[7.8718, 4.4440, 4.7851, 0.3115]]),\n",
       " tensor([[7.8881, 4.4603, 4.8014, 0.3278]]),\n",
       " tensor([[7.8525, 4.4247, 4.7658, 0.2922]]),\n",
       " tensor([[7.8774, 4.4495, 4.7907, 0.3171]]),\n",
       " tensor([[7.5574, 2.8545, 3.1006, 0.1375]]),\n",
       " tensor([[7.8732, 4.4454, 4.7865, 0.3129]]),\n",
       " tensor([[7.8316, 4.4038, 4.7449, 0.2713]]),\n",
       " tensor([[7.8821, 4.4542, 4.7954, 0.3218]]),\n",
       " tensor([[7.7056, 2.9846, 3.4205, 0.3532]]),\n",
       " tensor([[6.6730, 2.9994, 3.4569, 0.1879]]),\n",
       " tensor([[7.8361, 4.4083, 4.7494, 0.2758]]),\n",
       " tensor([[7.5710, 3.1479, 3.8219, 0.1703]]),\n",
       " tensor([[7.8138, 4.3859, 4.7271, 0.2535]]),\n",
       " tensor([[7.8262, 4.3983, 4.7395, 0.2659]]),\n",
       " tensor([[7.8472, 4.4194, 4.7605, 0.2869]]),\n",
       " tensor([[7.7217, 2.2127, 2.6723, 0.3127]]),\n",
       " tensor([[6.6032, 3.0103, 3.4837, 0.1272]]),\n",
       " tensor([[7.8177, 4.3899, 4.7310, 0.2574]]),\n",
       " tensor([[7.8344, 4.4066, 4.7477, 0.2741]]),\n",
       " tensor([[7.8580, 4.4302, 4.7713, 0.2977]]),\n",
       " tensor([[7.8104, 4.3826, 4.7238, 0.2501]]),\n",
       " tensor([[7.8726, 4.4447, 4.7859, 0.3123]]),\n",
       " tensor([[7.8911, 4.4633, 4.8044, 0.3308]]),\n",
       " tensor([[7.8467, 4.4189, 4.7600, 0.2864]]),\n",
       " tensor([[7.8628, 4.4349, 4.7761, 0.3024]]),\n",
       " tensor([[7.8651, 4.4373, 4.7784, 0.3048]]),\n",
       " tensor([[7.8348, 2.1466, 2.7803, 0.2466]]),\n",
       " tensor([[7.8437, 4.4159, 4.7570, 0.2834]]),\n",
       " tensor([[7.5876, 4.1918, 4.2867, 0.3895]]),\n",
       " tensor([[6.7212, 2.8914, 3.1914, 0.1823]]),\n",
       " tensor([[7.8248, 4.3970, 4.7381, 0.2645]]),\n",
       " tensor([[7.8352, 4.4073, 4.7485, 0.2749]]),\n",
       " tensor([[7.8565, 4.4286, 4.7698, 0.2962]]),\n",
       " tensor([[7.8704, 4.4426, 4.7837, 0.3101]]),\n",
       " tensor([[7.8836, 4.4558, 4.7969, 0.3233]]),\n",
       " tensor([[7.8160, 4.3882, 4.7293, 0.2557]]),\n",
       " tensor([[7.5603, 4.1735, 4.3050, 0.3712]]),\n",
       " tensor([[7.8820, 4.4541, 4.7953, 0.3217]]),\n",
       " tensor([[7.8489, 4.4210, 4.7622, 0.2886]]),\n",
       " tensor([[7.8776, 4.4497, 4.7909, 0.3173]]),\n",
       " tensor([[7.8394, 4.4116, 4.7527, 0.2791]]),\n",
       " tensor([[7.3631, 2.9189, 3.2591, 0.2008]]),\n",
       " tensor([[7.8483, 4.4204, 4.7616, 0.2880]]),\n",
       " tensor([[7.6127, 2.0711, 2.4890, 0.1711]]),\n",
       " tensor([[7.8612, 4.4334, 4.7745, 0.3009]]),\n",
       " tensor([[7.2942, 3.9961, 4.3221, 0.1906]]),\n",
       " tensor([[7.2423, 3.0560, 3.5960, 0.1404]]),\n",
       " tensor([[7.8184, 4.3906, 4.7317, 0.2581]]),\n",
       " tensor([[7.8858, 4.4579, 4.7991, 0.3254]]),\n",
       " tensor([[7.8932, 4.4654, 4.8065, 0.3329]]),\n",
       " tensor([[7.8228, 4.3950, 4.7361, 0.2625]]),\n",
       " tensor([[7.8227, 4.3949, 4.7360, 0.2624]]),\n",
       " tensor([[7.8837, 4.4558, 4.7970, 0.3234]]),\n",
       " tensor([[6.3550, 2.9490, 3.3329, 0.1244]]),\n",
       " tensor([[7.8743, 4.4464, 4.7876, 0.3139]]),\n",
       " tensor([[7.8130, 4.3852, 4.7263, 0.2527]]),\n",
       " tensor([[7.8164, 4.3886, 4.7298, 0.2561]]),\n",
       " tensor([[7.3490, 4.0326, 4.3180, 0.1456]]),\n",
       " tensor([[7.8717, 4.4438, 4.7850, 0.3114]]),\n",
       " tensor([[7.8740, 4.4462, 4.7873, 0.3137]]),\n",
       " tensor([[7.8579, 4.4300, 4.7712, 0.2976]]),\n",
       " tensor([[7.8527, 4.4249, 4.7660, 0.2924]]),\n",
       " tensor([[7.8833, 4.4555, 4.7967, 0.3230]]),\n",
       " tensor([[7.8855, 2.8885, 3.1842, 0.4470]]),\n",
       " tensor([[7.8442, 4.4164, 4.7575, 0.2839]]),\n",
       " tensor([[7.8422, 2.9912, 3.4367, 0.1920]]),\n",
       " tensor([[7.8635, 4.4357, 4.7768, 0.3032]]),\n",
       " tensor([[7.8166, 4.3887, 4.7299, 0.2563]]),\n",
       " tensor([[7.8737, 4.4459, 4.7870, 0.3134]]),\n",
       " tensor([[7.8482, 4.4204, 4.7615, 0.2879]]),\n",
       " tensor([[7.8142, 4.3864, 4.7275, 0.2539]]),\n",
       " tensor([[7.8371, 4.4092, 4.7504, 0.2768]]),\n",
       " tensor([[7.8773, 4.4494, 4.7906, 0.3170]]),\n",
       " tensor([[7.8552, 4.4274, 4.7685, 0.2949]]),\n",
       " tensor([[7.8243, 4.3965, 4.7376, 0.2640]]),\n",
       " tensor([[7.3708, 4.0472, 4.6810, 0.1101]]),\n",
       " tensor([[7.8505, 4.4227, 4.7639, 0.2902]]),\n",
       " tensor([[7.8867, 4.4589, 4.8000, 0.3264]]),\n",
       " tensor([[7.7681, 2.0855, 2.4525, 0.1855]]),\n",
       " tensor([[7.8220, 4.3942, 4.7353, 0.2617]]),\n",
       " tensor([[7.8396, 4.4118, 4.7529, 0.2793]]),\n",
       " tensor([[7.6023, 2.9490, 3.3329, 0.1401]]),\n",
       " tensor([[7.8897, 4.4619, 4.8031, 0.3294]]),\n",
       " tensor([[7.8252, 4.3973, 4.7385, 0.2648]]),\n",
       " tensor([[7.8245, 4.3966, 4.7378, 0.2642]]),\n",
       " tensor([[7.8791, 4.4512, 4.7924, 0.3188]]),\n",
       " tensor([[7.8289, 4.4011, 4.7422, 0.2686]]),\n",
       " tensor([[7.8682, 4.4404, 4.7815, 0.3079]]),\n",
       " tensor([[7.3908, 4.0605, 4.2818, 0.3154]]),\n",
       " tensor([[7.8359, 4.4080, 4.7492, 0.2756]]),\n",
       " tensor([[7.8367, 4.4088, 4.7500, 0.2764]]),\n",
       " tensor([[7.9450, 4.5172, 4.4770, 0.3847]]),\n",
       " tensor([[7.8156, 4.3878, 4.7290, 0.2553]]),\n",
       " tensor([[7.8914, 4.4636, 4.8047, 0.3311]]),\n",
       " tensor([[7.8191, 4.3913, 4.7324, 0.2588]]),\n",
       " tensor([[7.8425, 4.4147, 4.7558, 0.2822]]),\n",
       " tensor([[7.8200, 4.3921, 4.7333, 0.2597]]),\n",
       " tensor([[7.8154, 4.3876, 4.7287, 0.2551]]),\n",
       " tensor([[7.8274, 4.3996, 4.7407, 0.2671]]),\n",
       " tensor([[7.8943, 4.4665, 4.8076, 0.3340]]),\n",
       " tensor([[7.8797, 4.4518, 4.7930, 0.3194]]),\n",
       " tensor([[7.7597, 4.3065, 4.3319, 0.4434]]),\n",
       " tensor([[7.3832, 2.9299, 3.2859, 0.2955]]),\n",
       " tensor([[7.8622, 4.4344, 4.7756, 0.3019]]),\n",
       " tensor([[7.6344, 2.9834, 3.4175, 0.1535]]),\n",
       " tensor([[7.8610, 4.4332, 4.7743, 0.3007]]),\n",
       " tensor([[7.8345, 4.4067, 4.7478, 0.2742]]),\n",
       " tensor([[7.8360, 4.4082, 4.7493, 0.2757]]),\n",
       " tensor([[7.8682, 4.4403, 4.7815, 0.3079]]),\n",
       " tensor([[7.8389, 4.4111, 4.7522, 0.2786]]),\n",
       " tensor([[7.8617, 4.4339, 4.7751, 0.3014]]),\n",
       " tensor([[7.8485, 4.4207, 4.7618, 0.2882]]),\n",
       " tensor([[7.8342, 4.4064, 4.7475, 0.2739]]),\n",
       " tensor([[7.8934, 4.4655, 4.8067, 0.3331]]),\n",
       " tensor([[7.8900, 4.4622, 4.8033, 0.3297]]),\n",
       " tensor([[7.8926, 4.4647, 4.8059, 0.3323]]),\n",
       " tensor([[7.8398, 4.4120, 4.7531, 0.2795]]),\n",
       " tensor([[6.8715, 3.7143, 4.0838, 0.1750]]),\n",
       " tensor([[7.8128, 4.3850, 4.7261, 0.2525]]),\n",
       " tensor([[7.8886, 2.3152, 2.5922, 0.4152]]),\n",
       " tensor([[7.6136, 4.2090, 4.3642, 0.2951]]),\n",
       " tensor([[7.8521, 4.4243, 4.7654, 0.2918]]),\n",
       " tensor([[7.8583, 4.4304, 4.7716, 0.2980]]),\n",
       " tensor([[7.8570, 4.4292, 4.7703, 0.2967]]),\n",
       " tensor([[6.7945, 2.9330, 3.2936, 0.1784]]),\n",
       " tensor([[7.8937, 4.4659, 4.8070, 0.3334]]),\n",
       " tensor([[7.4014, 2.8708, 3.1407, 0.1124]]),\n",
       " tensor([[7.8231, 4.3952, 4.7364, 0.2627]]),\n",
       " tensor([[7.8545, 4.4267, 4.7678, 0.2942]]),\n",
       " tensor([[7.8598, 4.4319, 4.7731, 0.2995]]),\n",
       " tensor([[7.7936, 2.8974, 3.2061, 0.3938]]),\n",
       " tensor([[7.8793, 4.4515, 4.7926, 0.3190]]),\n",
       " tensor([[7.8239, 4.3961, 4.7372, 0.2636]]),\n",
       " tensor([[7.8152, 4.3874, 4.7285, 0.2549]]),\n",
       " tensor([[7.8110, 4.3832, 4.7243, 0.2507]]),\n",
       " tensor([[7.7927, 4.3284, 4.5782, 0.2678]]),\n",
       " tensor([[7.8564, 4.4286, 4.7697, 0.2961]]),\n",
       " tensor([[7.8796, 4.4517, 4.7929, 0.3193]]),\n",
       " tensor([[7.8806, 4.4528, 4.7939, 0.3203]]),\n",
       " tensor([[7.8535, 4.4256, 4.7668, 0.2932]]),\n",
       " tensor([[7.8235, 4.3957, 4.7368, 0.2632]]),\n",
       " tensor([[7.8834, 4.4556, 4.7967, 0.3231]]),\n",
       " tensor([[7.8735, 4.4457, 4.7868, 0.3132]]),\n",
       " tensor([[7.8772, 4.4494, 4.7905, 0.3169]]),\n",
       " tensor([[7.8546, 4.4268, 4.7680, 0.2943]]),\n",
       " tensor([[7.8384, 4.4106, 4.7517, 0.2781]]),\n",
       " tensor([[7.8548, 4.4270, 4.7681, 0.2945]]),\n",
       " tensor([[7.8356, 4.4078, 4.7489, 0.2753]]),\n",
       " tensor([[7.8440, 4.4162, 4.7573, 0.2837]]),\n",
       " tensor([[7.8811, 4.4532, 4.7944, 0.3208]]),\n",
       " tensor([[7.6790, 2.0765, 2.6005, 0.1765]]),\n",
       " tensor([[7.8883, 4.4604, 4.8016, 0.3280]]),\n",
       " tensor([[7.8646, 4.4368, 4.7779, 0.3043]]),\n",
       " tensor([[7.8107, 4.3828, 4.7240, 0.2504]]),\n",
       " tensor([[6.9539, 3.1400, 3.8025, 0.1006]]),\n",
       " tensor([[7.8325, 4.4047, 4.7458, 0.2722]]),\n",
       " tensor([[7.8682, 4.4403, 4.7815, 0.3079]]),\n",
       " tensor([[7.8849, 4.4571, 4.7982, 0.3246]]),\n",
       " tensor([[7.8252, 4.3973, 4.7385, 0.2649]]),\n",
       " tensor([[7.8667, 4.4389, 4.7800, 0.3064]]),\n",
       " tensor([[7.8904, 4.4626, 4.8037, 0.3301]]),\n",
       " tensor([[7.9816, 2.9151, 3.2495, 0.4213]]),\n",
       " tensor([[7.8623, 4.4345, 4.7756, 0.3020]]),\n",
       " tensor([[7.6198, 2.1409, 2.7109, 0.2409]]),\n",
       " tensor([[7.8429, 4.4151, 4.7562, 0.2826]]),\n",
       " tensor([[7.8939, 4.4660, 4.8072, 0.3335]]),\n",
       " tensor([[7.8360, 4.4082, 4.7493, 0.2757]]),\n",
       " tensor([[7.8233, 4.3954, 4.7366, 0.2629]]),\n",
       " tensor([[7.8498, 4.4220, 4.7631, 0.2895]]),\n",
       " tensor([[8.0522, 2.8307, 3.0421, 0.4919]]),\n",
       " tensor([[7.8866, 4.4588, 4.7999, 0.3263]]),\n",
       " tensor([[7.6761, 2.8703, 3.1396, 0.2823]]),\n",
       " tensor([[7.8344, 4.4066, 4.7477, 0.2741]]),\n",
       " tensor([[7.8853, 4.4574, 4.7986, 0.3250]]),\n",
       " tensor([[7.8306, 4.4028, 4.7439, 0.2703]]),\n",
       " tensor([[7.8273, 4.3994, 4.7406, 0.2670]]),\n",
       " tensor([[7.8283, 4.4005, 4.7416, 0.2680]]),\n",
       " tensor([[6.7702, 3.0034, 3.4668, 0.1321]]),\n",
       " tensor([[7.8417, 4.4138, 4.7550, 0.2814]]),\n",
       " tensor([[7.8751, 2.8409, 3.0672, 0.2455]]),\n",
       " tensor([[7.6267, 2.8400, 3.0650, 0.2131]]),\n",
       " tensor([[7.8171, 4.3893, 4.7304, 0.2568]]),\n",
       " tensor([[7.8131, 4.3853, 4.7264, 0.2528]]),\n",
       " tensor([[7.8725, 4.4446, 4.7858, 0.3122]]),\n",
       " tensor([[7.8243, 4.3965, 4.7376, 0.2640]]),\n",
       " tensor([[7.0434, 2.9126, 3.2435, 0.2961]]),\n",
       " tensor([[7.8238, 4.3960, 4.7372, 0.2635]]),\n",
       " tensor([[7.8383, 4.4105, 4.7516, 0.2780]]),\n",
       " tensor([[7.8484, 4.4206, 4.7617, 0.2881]]),\n",
       " tensor([[7.5950, 2.0998, 2.6870, 0.1998]]),\n",
       " tensor([[7.8282, 4.4003, 4.7415, 0.2679]]),\n",
       " tensor([[7.8255, 4.3977, 4.7388, 0.2652]]),\n",
       " tensor([[7.8936, 4.4658, 4.8069, 0.3333]]),\n",
       " tensor([[7.6509, 2.9445, 3.3218, 0.2983]]),\n",
       " tensor([[6.2558, 2.9663, 3.3755, 0.1109]]),\n",
       " tensor([[7.8117, 4.3838, 4.7250, 0.2514]]),\n",
       " tensor([[7.6210, 2.8643, 3.1246, 0.4153]]),\n",
       " tensor([[7.8554, 4.4276, 4.7688, 0.2951]]),\n",
       " tensor([[7.8443, 4.4165, 4.7576, 0.2840]]),\n",
       " tensor([[7.8288, 4.4009, 4.7421, 0.2685]]),\n",
       " tensor([[7.8110, 4.3832, 4.7243, 0.2507]]),\n",
       " tensor([[7.8214, 4.3936, 4.7347, 0.2611]]),\n",
       " tensor([[7.8435, 4.4157, 4.7568, 0.2832]]),\n",
       " tensor([[7.8718, 2.1009, 2.7000, 0.2009]]),\n",
       " tensor([[7.8411, 4.4132, 4.7544, 0.2808]]),\n",
       " tensor([[7.8815, 4.4537, 4.7948, 0.3212]]),\n",
       " tensor([[7.8780, 4.4502, 4.7913, 0.3177]]),\n",
       " tensor([[7.8128, 4.3850, 4.7261, 0.2525]]),\n",
       " tensor([[7.8134, 4.3856, 4.7267, 0.2531]]),\n",
       " tensor([[7.8499, 4.4221, 4.7632, 0.2896]]),\n",
       " tensor([[7.8726, 4.4447, 4.7859, 0.3123]]),\n",
       " tensor([[7.8157, 4.3879, 4.7290, 0.2554]]),\n",
       " tensor([[7.8331, 4.4053, 4.7464, 0.2728]]),\n",
       " tensor([[7.9496, 3.2382, 4.0440, 0.1164]]),\n",
       " tensor([[7.8131, 4.3852, 4.7264, 0.2528]]),\n",
       " tensor([[7.8643, 4.4365, 4.7776, 0.3040]]),\n",
       " tensor([[7.8645, 4.4367, 4.7778, 0.3042]]),\n",
       " tensor([[7.8366, 4.4087, 4.7499, 0.2763]]),\n",
       " tensor([[7.8176, 4.3897, 4.7309, 0.2573]]),\n",
       " tensor([[7.8595, 4.4317, 4.7728, 0.2992]]),\n",
       " tensor([[7.6491, 2.9203, 3.2624, 0.2917]]),\n",
       " tensor([[7.8849, 4.4570, 4.7982, 0.3246]]),\n",
       " tensor([[7.8414, 4.4135, 4.7547, 0.2811]]),\n",
       " tensor([[7.8583, 4.4304, 4.7716, 0.2980]]),\n",
       " tensor([[7.7473, 3.0424, 3.5625, 0.3009]]),\n",
       " tensor([[7.8586, 4.4308, 4.7719, 0.2983]]),\n",
       " tensor([[7.8913, 4.4634, 4.8046, 0.3309]]),\n",
       " tensor([[7.8912, 4.4634, 4.8045, 0.3309]]),\n",
       " tensor([[7.8277, 4.3999, 4.7410, 0.2674]]),\n",
       " tensor([[7.8665, 4.4386, 4.7798, 0.3061]]),\n",
       " tensor([[7.8306, 4.4027, 4.7439, 0.2703]]),\n",
       " tensor([[7.8630, 4.4352, 4.7763, 0.3027]]),\n",
       " tensor([[7.8196, 4.3918, 4.7329, 0.2593]]),\n",
       " tensor([[7.5945, 3.0080, 3.4780, 0.2866]]),\n",
       " tensor([[7.8592, 4.4314, 4.7725, 0.2989]]),\n",
       " tensor([[7.8573, 4.4295, 4.7706, 0.2970]]),\n",
       " tensor([[7.8150, 4.3872, 4.7283, 0.2547]]),\n",
       " tensor([[7.7527, 2.0659, 2.5044, 0.1659]]),\n",
       " tensor([[7.8939, 4.4661, 4.8072, 0.3336]]),\n",
       " tensor([[7.4945, 2.0228, 2.5855, 0.1228]]),\n",
       " tensor([[7.8907, 4.4629, 4.8040, 0.3304]]),\n",
       " tensor([[7.8141, 4.3863, 4.7274, 0.2538]]),\n",
       " tensor([[7.8899, 4.4621, 4.8032, 0.3296]]),\n",
       " tensor([[7.8918, 4.4640, 4.8051, 0.3315]]),\n",
       " tensor([[7.8568, 4.4290, 4.7701, 0.2965]]),\n",
       " tensor([[7.8145, 4.3867, 4.7278, 0.2542]]),\n",
       " tensor([[7.8920, 4.4641, 4.8053, 0.3317]]),\n",
       " tensor([[7.6665, 4.2444, 4.2970, 0.1674]]),\n",
       " tensor([[7.8804, 4.4525, 4.7937, 0.3200]]),\n",
       " tensor([[7.8777, 4.4499, 4.7910, 0.3174]]),\n",
       " tensor([[7.8943, 4.4665, 4.8076, 0.3340]]),\n",
       " tensor([[7.8384, 4.4106, 4.7517, 0.2781]]),\n",
       " tensor([[7.8186, 4.3907, 4.7319, 0.2583]]),\n",
       " tensor([[7.8780, 4.4502, 4.7913, 0.3177]]),\n",
       " tensor([[7.8567, 4.4289, 4.7700, 0.2964]]),\n",
       " tensor([[7.8843, 4.4564, 4.7976, 0.3240]]),\n",
       " tensor([[7.8637, 2.9184, 3.2578, 0.3930]]),\n",
       " tensor([[7.8133, 4.3854, 4.7266, 0.2530]]),\n",
       " tensor([[7.8146, 4.3868, 4.7279, 0.2543]]),\n",
       " tensor([[7.8577, 4.4299, 4.7710, 0.2974]]),\n",
       " tensor([[7.8475, 4.4197, 4.7608, 0.2872]]),\n",
       " tensor([[7.8121, 4.3843, 4.7254, 0.2518]]),\n",
       " tensor([[7.8840, 4.3893, 4.8841, 0.1960]]),\n",
       " tensor([[7.8170, 4.3892, 4.7303, 0.2567]]),\n",
       " tensor([[7.5558, 4.1706, 4.1667, 0.4630]]),\n",
       " tensor([[7.5590, 4.1727, 4.4854, 0.2436]]),\n",
       " tensor([[7.8121, 4.3843, 4.7254, 0.2518]]),\n",
       " tensor([[7.8826, 4.4548, 4.7959, 0.3223]]),\n",
       " tensor([[7.8890, 4.4612, 4.8023, 0.3287]]),\n",
       " tensor([[7.8571, 4.4293, 4.7704, 0.2968]]),\n",
       " tensor([[7.8202, 4.3923, 4.7335, 0.2599]]),\n",
       " tensor([[7.8935, 4.4656, 4.8068, 0.3332]]),\n",
       " tensor([[7.8335, 4.4056, 4.7468, 0.2732]]),\n",
       " tensor([[7.8331, 4.4053, 4.7464, 0.2728]]),\n",
       " tensor([[7.8677, 4.4399, 4.7810, 0.3074]]),\n",
       " tensor([[7.8425, 4.4147, 4.7558, 0.2822]]),\n",
       " tensor([[7.8819, 4.4540, 4.7952, 0.3216]]),\n",
       " tensor([[7.8691, 4.4413, 4.7824, 0.3088]]),\n",
       " tensor([[7.8390, 4.4112, 4.7523, 0.2787]]),\n",
       " tensor([[7.8833, 4.4555, 4.7966, 0.3230]]),\n",
       " tensor([[7.3309, 4.0206, 4.2258, 0.1100]]),\n",
       " tensor([[7.4777, 2.8600, 3.1141, 0.3671]]),\n",
       " tensor([[7.7222, 3.1012, 3.7072, 0.1869]]),\n",
       " tensor([[7.8685, 4.4406, 4.7818, 0.3081]]),\n",
       " tensor([[7.6610, 2.0234, 2.8225, 0.1234]]),\n",
       " tensor([[7.8859, 4.4580, 4.7992, 0.3256]]),\n",
       " tensor([[7.8106, 4.3828, 4.7239, 0.2503]]),\n",
       " tensor([[7.8689, 2.8555, 3.1031, 0.2002]]),\n",
       " tensor([[7.8748, 4.4470, 4.7881, 0.3145]]),\n",
       " tensor([[7.8677, 4.4398, 4.7810, 0.3074]]),\n",
       " tensor([[7.8899, 4.4621, 4.8032, 0.3296]]),\n",
       " tensor([[7.8558, 4.4279, 4.7691, 0.2955]]),\n",
       " tensor([[7.8700, 4.4422, 4.7833, 0.3097]]),\n",
       " tensor([[7.8346, 4.4067, 4.7479, 0.2743]]),\n",
       " tensor([[7.8240, 4.3962, 4.7373, 0.2637]]),\n",
       " tensor([[7.8839, 4.4560, 4.7972, 0.3236]]),\n",
       " tensor([[7.8696, 4.4418, 4.7829, 0.3093]]),\n",
       " tensor([[7.8766, 4.4488, 4.7899, 0.3163]]),\n",
       " tensor([[7.6503, 2.9302, 3.2868, 0.1663]]),\n",
       " tensor([[7.8902, 4.4624, 4.8035, 0.3299]]),\n",
       " tensor([[7.8688, 4.4410, 4.7821, 0.3085]]),\n",
       " tensor([[7.8416, 4.4137, 4.7549, 0.2813]]),\n",
       " tensor([[7.8723, 4.4444, 4.7856, 0.3120]]),\n",
       " tensor([[7.8272, 4.3994, 4.7405, 0.2669]]),\n",
       " tensor([[7.8368, 4.4090, 4.7501, 0.2765]]),\n",
       " tensor([[7.8664, 4.4385, 4.7797, 0.3061]]),\n",
       " tensor([[7.8734, 4.4456, 4.7867, 0.3131]]),\n",
       " tensor([[7.8432, 4.4153, 4.7565, 0.2829]]),\n",
       " tensor([[7.8008, 4.3339, 4.6000, 0.1886]]),\n",
       " tensor([[7.8904, 4.4626, 4.8037, 0.3301]]),\n",
       " tensor([[7.8117, 4.3839, 4.7251, 0.2514]]),\n",
       " tensor([[7.8788, 4.4509, 4.7921, 0.3184]]),\n",
       " tensor([[7.8444, 4.4165, 4.7577, 0.2841]]),\n",
       " tensor([[7.8348, 4.4069, 4.7481, 0.2745]]),\n",
       " tensor([[7.8879, 4.4601, 4.8012, 0.3276]]),\n",
       " tensor([[7.8517, 4.4238, 4.7650, 0.2913]]),\n",
       " tensor([[7.8511, 4.4232, 4.7644, 0.2908]]),\n",
       " tensor([[7.8149, 4.3870, 4.7282, 0.2546]]),\n",
       " tensor([[7.8300, 4.4022, 4.7433, 0.2697]]),\n",
       " tensor([[7.8402, 4.4124, 4.7535, 0.2799]]),\n",
       " tensor([[7.8915, 4.4636, 4.8048, 0.3312]]),\n",
       " tensor([[7.8877, 4.4598, 4.8010, 0.3274]]),\n",
       " tensor([[7.2373, 3.9582, 4.3332, 0.2093]]),\n",
       " tensor([[7.8424, 4.4145, 4.7557, 0.2820]]),\n",
       " tensor([[7.8373, 4.4095, 4.7506, 0.2770]]),\n",
       " tensor([[7.8712, 4.4433, 4.7845, 0.3109]]),\n",
       " tensor([[7.8363, 4.4085, 4.7496, 0.2760]]),\n",
       " tensor([[7.8638, 4.4360, 4.7771, 0.3035]]),\n",
       " tensor([[7.5082, 2.9353, 3.2992, 0.1326]]),\n",
       " tensor([[7.8286, 4.4008, 4.7419, 0.2683]]),\n",
       " tensor([[7.8415, 4.4137, 4.7548, 0.2812]]),\n",
       " tensor([[7.8869, 4.4591, 4.8002, 0.3266]]),\n",
       " tensor([[8.0588, 2.7814, 2.9210, 0.4985]]),\n",
       " tensor([[7.8886, 4.4608, 4.8019, 0.3283]]),\n",
       " tensor([[7.8647, 4.4369, 4.7780, 0.3044]]),\n",
       " tensor([[7.8184, 4.3906, 4.7317, 0.2581]]),\n",
       " tensor([[7.8123, 4.3845, 4.7256, 0.2520]]),\n",
       " tensor([[7.8434, 4.4156, 4.7567, 0.2831]]),\n",
       " tensor([[7.8691, 4.4412, 4.7824, 0.3088]]),\n",
       " tensor([[7.8296, 4.4018, 4.7429, 0.2693]]),\n",
       " tensor([[7.8535, 4.4256, 4.7668, 0.2932]]),\n",
       " tensor([[6.9821, 2.0723, 2.4823, 0.1723]]),\n",
       " tensor([[7.8157, 4.3878, 4.7290, 0.2554]]),\n",
       " tensor([[7.8124, 4.3846, 4.7257, 0.2521]]),\n",
       " tensor([[6.8885, 2.9618, 3.3644, 0.2456]]),\n",
       " tensor([[6.7074, 2.9371, 3.3037, 0.1241]]),\n",
       " tensor([[7.8139, 4.3860, 4.7272, 0.2536]]),\n",
       " tensor([[7.8158, 4.3880, 4.7291, 0.2555]]),\n",
       " tensor([[7.8932, 4.4653, 4.8065, 0.3329]]),\n",
       " tensor([[7.8377, 4.4098, 4.7510, 0.2774]]),\n",
       " tensor([[7.8672, 4.4393, 4.7805, 0.3069]]),\n",
       " tensor([[7.4199, 3.0343, 3.5427, 0.1988]]),\n",
       " tensor([[7.8734, 4.4456, 4.7867, 0.3131]]),\n",
       " tensor([[7.8872, 4.4593, 4.8005, 0.3269]]),\n",
       " tensor([[7.8508, 4.4230, 4.7641, 0.2905]]),\n",
       " tensor([[7.8122, 4.3843, 4.7255, 0.2518]]),\n",
       " tensor([[7.8587, 4.4309, 4.7721, 0.2984]]),\n",
       " tensor([[7.8916, 4.4638, 4.8049, 0.3313]]),\n",
       " tensor([[7.8735, 4.4456, 4.7868, 0.3131]]),\n",
       " tensor([[7.8734, 4.4456, 4.7867, 0.3131]]),\n",
       " tensor([[7.8379, 4.4100, 4.7512, 0.2776]]),\n",
       " tensor([[7.8737, 4.4459, 4.7870, 0.3134]]),\n",
       " tensor([[7.8214, 4.3935, 4.7347, 0.2611]]),\n",
       " tensor([[7.8267, 4.3989, 4.7400, 0.2664]]),\n",
       " tensor([[7.8385, 4.4107, 4.7518, 0.2782]]),\n",
       " tensor([[7.8350, 4.4072, 4.7483, 0.2747]]),\n",
       " tensor([[7.8240, 4.3962, 4.7373, 0.2637]]),\n",
       " tensor([[7.8212, 4.3934, 4.7345, 0.2609]]),\n",
       " tensor([[7.8716, 4.4438, 4.7849, 0.3113]]),\n",
       " tensor([[7.8467, 4.4189, 4.7600, 0.2864]]),\n",
       " tensor([[7.8807, 4.4529, 4.7940, 0.3204]]),\n",
       " tensor([[7.6353, 2.9868, 3.4259, 0.2086]]),\n",
       " tensor([[7.3721, 2.9516, 3.3393, 0.1527]]),\n",
       " tensor([[7.8752, 4.4474, 4.7885, 0.3149]]),\n",
       " tensor([[7.8634, 4.4356, 4.7767, 0.3031]]),\n",
       " tensor([[7.8283, 4.4005, 4.7416, 0.2680]]),\n",
       " tensor([[7.8771, 4.4493, 4.7905, 0.3168]]),\n",
       " tensor([[7.8124, 4.3846, 4.7257, 0.2521]]),\n",
       " tensor([[7.7766, 3.0644, 3.6167, 0.3051]]),\n",
       " tensor([[7.7515, 4.3010, 4.7139, 0.2504]]),\n",
       " tensor([[7.8659, 4.4381, 4.7792, 0.3056]]),\n",
       " tensor([[7.6380, 3.1805, 3.9021, 0.1451]]),\n",
       " tensor([[7.8448, 4.4170, 4.7581, 0.2845]]),\n",
       " tensor([[7.8269, 4.3991, 4.7402, 0.2666]]),\n",
       " tensor([[7.8117, 4.3838, 4.7250, 0.2514]]),\n",
       " tensor([[7.8647, 4.4369, 4.7781, 0.3044]]),\n",
       " tensor([[7.6874, 2.8189, 3.0132, 0.2952]]),\n",
       " tensor([[7.8105, 4.3827, 4.7239, 0.2502]]),\n",
       " tensor([[7.8443, 4.4165, 4.7576, 0.2840]]),\n",
       " tensor([[7.8606, 4.4327, 4.7739, 0.3003]]),\n",
       " tensor([[7.6716, 2.9386, 3.3074, 0.3222]]),\n",
       " tensor([[7.8328, 4.4049, 4.7461, 0.2725]]),\n",
       " tensor([[8.7372, 2.0922, 2.5734, 0.1922]]),\n",
       " tensor([[7.8852, 4.4574, 4.7985, 0.3249]]),\n",
       " tensor([[7.8188, 4.3910, 4.7321, 0.2585]]),\n",
       " tensor([[7.8303, 4.4025, 4.7437, 0.2700]]),\n",
       " tensor([[7.8347, 4.4069, 4.7480, 0.2744]]),\n",
       " tensor([[7.6224, 2.0770, 2.7385, 0.1770]]),\n",
       " tensor([[7.3359, 2.8848, 3.1752, 0.2815]]),\n",
       " tensor([[7.6331, 2.8656, 3.1280, 0.3233]]),\n",
       " tensor([[7.8558, 4.4280, 4.7691, 0.2955]]),\n",
       " tensor([[7.8458, 4.4180, 4.7591, 0.2855]]),\n",
       " tensor([[7.8121, 4.3843, 4.7254, 0.2518]]),\n",
       " tensor([[7.8855, 4.4577, 4.7988, 0.3252]]),\n",
       " tensor([[7.3987, 4.0658, 4.3617, 0.2467]]),\n",
       " tensor([[7.8668, 4.4389, 4.7801, 0.3065]]),\n",
       " tensor([[7.8770, 4.4492, 4.7903, 0.3167]]),\n",
       " tensor([[7.8810, 4.4532, 4.7943, 0.3207]]),\n",
       " tensor([[7.8260, 4.3982, 4.7393, 0.2657]]),\n",
       " tensor([[7.8352, 4.4074, 4.7485, 0.2749]]),\n",
       " tensor([[7.8123, 4.3845, 4.7256, 0.2520]]),\n",
       " tensor([[7.8910, 4.4631, 4.8043, 0.3307]]),\n",
       " tensor([[7.8168, 4.3445, 4.7320, 0.2729]]),\n",
       " tensor([[7.8572, 4.4294, 4.7705, 0.2969]]),\n",
       " tensor([[7.8905, 4.4627, 4.8038, 0.3302]]),\n",
       " tensor([[7.0299, 3.8200, 4.0260, 0.2146]]),\n",
       " tensor([[7.8403, 4.4124, 4.7536, 0.2800]]),\n",
       " tensor([[7.8153, 4.3875, 4.7286, 0.2550]]),\n",
       " tensor([[7.8193, 4.3915, 4.7326, 0.2590]]),\n",
       " tensor([[7.9920, 2.8244, 3.0267, 0.4317]]),\n",
       " tensor([[7.8248, 4.3970, 4.7381, 0.2645]]),\n",
       " tensor([[7.8631, 4.4353, 4.7764, 0.3028]]),\n",
       " tensor([[7.7020, 3.1804, 3.9019, 0.1459]]),\n",
       " tensor([[7.8222, 2.0037, 2.4680, 0.1037]]),\n",
       " tensor([[7.8179, 4.3901, 4.7312, 0.2576]]),\n",
       " tensor([[7.8699, 4.4421, 4.7833, 0.3096]]),\n",
       " tensor([[7.1863, 2.9140, 3.2469, 0.1371]]),\n",
       " tensor([[7.8414, 4.4135, 4.7547, 0.2811]]),\n",
       " tensor([[7.8144, 4.3866, 4.7277, 0.2541]]),\n",
       " tensor([[7.6968, 2.8511, 3.0923, 0.1211]]),\n",
       " tensor([[6.7102, 3.0513, 3.5844, 0.1678]]),\n",
       " tensor([[7.8793, 4.4514, 4.7926, 0.3190]]),\n",
       " tensor([[7.8367, 4.4089, 4.7500, 0.2764]]),\n",
       " tensor([[7.8258, 4.3980, 4.7391, 0.2655]]),\n",
       " tensor([[7.8879, 4.4601, 4.8012, 0.3276]]),\n",
       " tensor([[7.8183, 4.3904, 4.7316, 0.2579]]),\n",
       " tensor([[7.8709, 4.4431, 4.7842, 0.3106]]),\n",
       " tensor([[7.8638, 4.4359, 4.7771, 0.3035]]),\n",
       " tensor([[7.8224, 4.3945, 4.7357, 0.2621]]),\n",
       " tensor([[7.1002, 3.0294, 3.5307, 0.1102]]),\n",
       " tensor([[7.8912, 4.4633, 4.8045, 0.3309]]),\n",
       " tensor([[7.5982, 3.0351, 3.5446, 0.3018]]),\n",
       " tensor([[7.8286, 4.4008, 4.7419, 0.2683]]),\n",
       " tensor([[7.8266, 4.3988, 4.7399, 0.2663]]),\n",
       " tensor([[7.8615, 4.4337, 4.7748, 0.3012]]),\n",
       " tensor([[7.8209, 4.3931, 4.7342, 0.2606]]),\n",
       " tensor([[7.8578, 4.4300, 4.7711, 0.2975]]),\n",
       " tensor([[7.8356, 4.4078, 4.7489, 0.2753]]),\n",
       " tensor([[7.8706, 4.4428, 4.7839, 0.3103]]),\n",
       " tensor([[7.8637, 4.4359, 4.7770, 0.3034]]),\n",
       " tensor([[7.8259, 4.3981, 4.7392, 0.2656]]),\n",
       " tensor([[7.8469, 4.4190, 4.7602, 0.2866]]),\n",
       " tensor([[7.8788, 4.4510, 4.7921, 0.3185]]),\n",
       " tensor([[7.8347, 4.4068, 4.7480, 0.2744]]),\n",
       " tensor([[7.8847, 4.4568, 4.7980, 0.3244]]),\n",
       " tensor([[7.8546, 4.4268, 4.7679, 0.2943]]),\n",
       " tensor([[7.8117, 4.3839, 4.7250, 0.2514]]),\n",
       " tensor([[7.8128, 4.3850, 4.7261, 0.2525]]),\n",
       " tensor([[7.8153, 4.3874, 4.7286, 0.2550]]),\n",
       " tensor([[7.8475, 4.4197, 4.7608, 0.2872]]),\n",
       " tensor([[7.8214, 4.3936, 4.7347, 0.2611]]),\n",
       " tensor([[7.8441, 4.4163, 4.7574, 0.2838]]),\n",
       " tensor([[7.8733, 4.4455, 4.7866, 0.3130]]),\n",
       " tensor([[6.7018, 2.0053, 2.4799, 0.1053]]),\n",
       " tensor([[7.8560, 4.4282, 4.7693, 0.2957]]),\n",
       " tensor([[7.8601, 4.4322, 4.7734, 0.2998]]),\n",
       " tensor([[7.8459, 4.4180, 4.7592, 0.2856]]),\n",
       " tensor([[7.8723, 4.4445, 4.7856, 0.3120]]),\n",
       " tensor([[6.4797, 3.0758, 3.6448, 0.1106]]),\n",
       " tensor([[7.8042, 2.9672, 3.3778, 0.3455]]),\n",
       " tensor([[7.8588, 4.4310, 4.7721, 0.2985]]),\n",
       " tensor([[7.8438, 4.4160, 4.7571, 0.2835]]),\n",
       " tensor([[7.8360, 4.4082, 4.7493, 0.2757]]),\n",
       " tensor([[7.8753, 4.4475, 4.7887, 0.3150]]),\n",
       " tensor([[7.8935, 4.4657, 4.8068, 0.3332]]),\n",
       " tensor([[8.5318, 2.8763, 3.1542, 0.3160]]),\n",
       " tensor([[7.8352, 2.2399, 2.5934, 0.1223]]),\n",
       " tensor([[7.8536, 3.1069, 3.7211, 0.1085]]),\n",
       " tensor([[7.2455, 3.9637, 4.0474, 0.3406]]),\n",
       " tensor([[7.8559, 4.4281, 4.7692, 0.2956]]),\n",
       " tensor([[7.8679, 4.4401, 4.7812, 0.3076]]),\n",
       " tensor([[7.8348, 4.4069, 4.7481, 0.2745]]),\n",
       " tensor([[7.8695, 4.4417, 4.7828, 0.3092]]),\n",
       " tensor([[7.8714, 4.4436, 4.7848, 0.3111]]),\n",
       " tensor([[7.7616, 2.8440, 3.0749, 0.2165]]),\n",
       " tensor([[7.8394, 4.4116, 4.7527, 0.2791]]),\n",
       " tensor([[7.8915, 4.4637, 4.8048, 0.3312]]),\n",
       " tensor([[7.8448, 4.4170, 4.7582, 0.2845]]),\n",
       " tensor([[7.8804, 4.4526, 4.7937, 0.3201]]),\n",
       " tensor([[7.2009, 2.9791, 3.4069, 0.1046]]),\n",
       " tensor([[7.8865, 4.4587, 4.7998, 0.3262]]),\n",
       " tensor([[7.4697, 2.8704, 3.1397, 0.2216]]),\n",
       " tensor([[7.8321, 4.4042, 4.7454, 0.2718]]),\n",
       " tensor([[7.8184, 4.3906, 4.7318, 0.2581]]),\n",
       " tensor([[7.8574, 4.4296, 4.7707, 0.2971]]),\n",
       " tensor([[7.8230, 4.3952, 4.7363, 0.2627]]),\n",
       " tensor([[7.3610, 2.9081, 3.2325, 0.2126]]),\n",
       " tensor([[7.8291, 4.4012, 4.7424, 0.2688]]),\n",
       " tensor([[7.8198, 4.3919, 4.7331, 0.2595]]),\n",
       " tensor([[7.8533, 4.4255, 4.7666, 0.2930]]),\n",
       " tensor([[7.8532, 4.4254, 4.7665, 0.2929]]),\n",
       " tensor([[7.7233, 2.0954, 2.8045, 0.1954]]),\n",
       " tensor([[7.8452, 4.4174, 4.7585, 0.2849]]),\n",
       " tensor([[7.8801, 4.4523, 4.7934, 0.3198]]),\n",
       " tensor([[7.8801, 4.4523, 4.7934, 0.3198]]),\n",
       " tensor([[7.8795, 4.4517, 4.7928, 0.3192]]),\n",
       " tensor([[7.8410, 4.4132, 4.7544, 0.2807]]),\n",
       " tensor([[7.8711, 4.4432, 4.7844, 0.3108]]),\n",
       " tensor([[7.8782, 4.4503, 4.7915, 0.3179]]),\n",
       " tensor([[8.3687, 2.8826, 3.1697, 0.3465]]),\n",
       " tensor([[7.8388, 4.4110, 4.7521, 0.2785]]),\n",
       " tensor([[7.8301, 4.4023, 4.7434, 0.2698]]),\n",
       " tensor([[7.8559, 4.4281, 4.7692, 0.2956]]),\n",
       " tensor([[7.8452, 4.4174, 4.7585, 0.2849]]),\n",
       " tensor([[7.8284, 4.4006, 4.7417, 0.2681]]),\n",
       " tensor([[7.8861, 4.4583, 4.7994, 0.3258]]),\n",
       " tensor([[7.4612, 4.1075, 4.2865, 0.2550]]),\n",
       " tensor([[7.8603, 4.4325, 4.7736, 0.3000]]),\n",
       " tensor([[7.8664, 4.4386, 4.7797, 0.3061]]),\n",
       " tensor([[7.7065, 2.9934, 3.4420, 0.3426]]),\n",
       " tensor([[7.8883, 4.4605, 4.8016, 0.3280]]),\n",
       " tensor([[7.8460, 4.4182, 4.7593, 0.2857]]),\n",
       " tensor([[7.8843, 4.4564, 4.7976, 0.3240]]),\n",
       " tensor([[7.8489, 4.4211, 4.7622, 0.2886]]),\n",
       " ...]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2 label shadow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_88484/2410329687.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.rand(1, len(columns_mins)) * (columns_maxs.detach() - columns_mins.detach()) + columns_mins.detach(), requires_grad=False, dtype=torch.float)\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_88484/2410329687.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_class = torch.nn.functional.softmax(target_model.forward(data)).detach()\n",
      "100%|██████████| 10000/10000 [00:04<00:00, 2499.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 label shadow dataset generated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shadow_dataset_2 = generate_shadows_datasets(4, 2, target_model, columns_mins, columns_maxs, mutliple_of_cs=mutliple_of_cs, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[4.7182, 2.6255, 6.2058, 1.2701]]),\n",
       " tensor([[6.6992, 2.9685, 5.1157, 1.8997]]),\n",
       " tensor([[5.3722, 2.7418, 4.9675, 0.2015]]),\n",
       " tensor([[4.5514, 3.6863, 4.7075, 0.4862]]),\n",
       " tensor([[7.6488, 3.3724, 2.8565, 2.4919]]),\n",
       " tensor([[6.7497, 3.5584, 6.8083, 1.2461]]),\n",
       " tensor([[6.4513, 3.8199, 4.5257, 1.5342]]),\n",
       " tensor([[7.0234, 3.0461, 5.4633, 1.1461]]),\n",
       " tensor([[7.5320, 3.3989, 4.2305, 2.4105]]),\n",
       " tensor([[7.3912, 2.0126, 5.4744, 1.8869]]),\n",
       " tensor([[4.9614, 4.0071, 6.0164, 0.7743]]),\n",
       " tensor([[6.4755, 3.6673, 5.4055, 2.0498]]),\n",
       " tensor([[4.8933, 2.0819, 3.3170, 2.0508]]),\n",
       " tensor([[5.9814, 3.4564, 6.6045, 1.6933]]),\n",
       " tensor([[6.4662, 3.3526, 5.0271, 0.6604]]),\n",
       " tensor([[5.8761, 4.3411, 6.2562, 1.7244]]),\n",
       " tensor([[7.8528, 2.9303, 6.7533, 1.3216]]),\n",
       " tensor([[5.3262, 4.2759, 5.6267, 2.0646]]),\n",
       " tensor([[7.0043, 4.0061, 3.9252, 1.5321]]),\n",
       " tensor([[5.6339, 2.0574, 5.9909, 2.4181]]),\n",
       " tensor([[5.4104, 3.1220, 3.6479, 1.1419]]),\n",
       " tensor([[7.3341, 2.2283, 5.1489, 1.0267]]),\n",
       " tensor([[5.4176, 3.0014, 4.7177, 0.4252]]),\n",
       " tensor([[6.7385, 3.9250, 5.7323, 1.7236]]),\n",
       " tensor([[6.4984, 3.8831, 4.7208, 1.3809]]),\n",
       " tensor([[5.5331, 4.3657, 5.0340, 2.2387]]),\n",
       " tensor([[5.8342, 2.9167, 6.1596, 0.2223]]),\n",
       " tensor([[7.8773, 3.0466, 5.9111, 2.0977]]),\n",
       " tensor([[7.3610, 2.4696, 1.4590, 2.3217]]),\n",
       " tensor([[4.5095, 3.6683, 3.0741, 1.9698]]),\n",
       " tensor([[7.4892, 4.1261, 6.2267, 0.6924]]),\n",
       " tensor([[6.7588, 3.6392, 4.5071, 1.7392]]),\n",
       " tensor([[7.1470, 4.0221, 3.9158, 2.1708]]),\n",
       " tensor([[7.5767, 4.1845, 3.1158, 2.2845]]),\n",
       " tensor([[6.1194, 4.1487, 4.4816, 2.1024]]),\n",
       " tensor([[5.8892, 2.7751, 3.6046, 1.1595]]),\n",
       " tensor([[6.9831, 3.6622, 5.9351, 0.5388]]),\n",
       " tensor([[5.6842, 2.3978, 6.3293, 1.9591]]),\n",
       " tensor([[6.4260, 2.8756, 3.0294, 1.9343]]),\n",
       " tensor([[7.1072, 3.4625, 5.3580, 1.2273]]),\n",
       " tensor([[7.1474, 3.8983, 5.6666, 1.9983]]),\n",
       " tensor([[6.0665, 3.0289, 4.4881, 0.5271]]),\n",
       " tensor([[6.6749, 4.3486, 4.8922, 1.6833]]),\n",
       " tensor([[4.4120, 3.9996, 5.9156, 2.0996]]),\n",
       " tensor([[7.2698, 2.8084, 5.1868, 2.2042]]),\n",
       " tensor([[6.0710, 2.8489, 1.8637, 2.1080]]),\n",
       " tensor([[5.6582, 2.3531, 4.7482, 1.4260]]),\n",
       " tensor([[6.5802, 4.0212, 3.8116, 2.3128]]),\n",
       " tensor([[6.6748, 3.7267, 3.6916, 1.8260]]),\n",
       " tensor([[6.7448, 2.5262, 6.8078, 0.2077]]),\n",
       " tensor([[6.7544, 4.0772, 4.3364, 1.4701]]),\n",
       " tensor([[6.7822, 3.6548, 5.0680, 0.9853]]),\n",
       " tensor([[6.4291, 4.3888, 6.6533, 2.3997]]),\n",
       " tensor([[7.8927, 3.7798, 2.8504, 2.4881]]),\n",
       " tensor([[6.3002, 3.3335, 4.2781, 0.7633]]),\n",
       " tensor([[5.5132, 2.3705, 5.9371, 0.7318]]),\n",
       " tensor([[6.8495, 2.3905, 5.1783, 1.5699]]),\n",
       " tensor([[5.7686, 2.9791, 3.4069, 1.0791]]),\n",
       " tensor([[4.8822, 3.2486, 4.0694, 1.3486]]),\n",
       " tensor([[6.3787, 3.9296, 3.3231, 2.3124]]),\n",
       " tensor([[4.4458, 3.7137, 5.2170, 1.8154]]),\n",
       " tensor([[6.5111, 2.1884, 4.2971, 0.4486]]),\n",
       " tensor([[5.2740, 3.1871, 5.6485, 0.5038]]),\n",
       " tensor([[5.0396, 3.5154, 4.8056, 2.0513]]),\n",
       " tensor([[5.3674, 2.7665, 2.1849, 1.8157]]),\n",
       " tensor([[7.0440, 3.8293, 5.4971, 1.0551]]),\n",
       " tensor([[5.5737, 3.6554, 5.6594, 1.9953]]),\n",
       " tensor([[6.0251, 4.2638, 6.6026, 2.1713]]),\n",
       " tensor([[4.5755, 4.3949, 4.9381, 2.4918]]),\n",
       " tensor([[5.8472, 3.0314, 3.5356, 1.1314]]),\n",
       " tensor([[4.5488, 2.5431, 4.6178, 0.7002]]),\n",
       " tensor([[6.2952, 2.4242, 2.6203, 1.8513]]),\n",
       " tensor([[7.2773, 3.7690, 6.2824, 1.0165]]),\n",
       " tensor([[6.0618, 2.4116, 3.8874, 1.2746]]),\n",
       " tensor([[6.7053, 3.4338, 4.7090, 0.7604]]),\n",
       " tensor([[5.9325, 2.6904, 5.1439, 0.7061]]),\n",
       " tensor([[6.1076, 2.9272, 5.7823, 0.9272]]),\n",
       " tensor([[6.4422, 2.1292, 4.7230, 2.4966]]),\n",
       " tensor([[4.4551, 3.2443, 4.0589, 1.3443]]),\n",
       " tensor([[6.5643, 3.5206, 6.6789, 1.5835]]),\n",
       " tensor([[6.2331, 2.1658, 5.1304, 0.2796]]),\n",
       " tensor([[7.4544, 3.3889, 2.8022, 2.2315]]),\n",
       " tensor([[6.4958, 2.6274, 2.5527, 2.0051]]),\n",
       " tensor([[5.8166, 3.0658, 5.8458, 1.8678]]),\n",
       " tensor([[5.6132, 2.5145, 3.4972, 1.4633]]),\n",
       " tensor([[7.1686, 4.3300, 5.7014, 0.7745]]),\n",
       " tensor([[4.8841, 2.6022, 4.4721, 1.0367]]),\n",
       " tensor([[5.4182, 2.1745, 2.5093, 1.5885]]),\n",
       " tensor([[4.4686, 3.8053, 6.3734, 0.2198]]),\n",
       " tensor([[7.7923, 3.1917, 6.0018, 2.3199]]),\n",
       " tensor([[5.7405, 2.2769, 3.3608, 1.0603]]),\n",
       " tensor([[7.3334, 2.7295, 4.5562, 0.9504]]),\n",
       " tensor([[6.5438, 3.9139, 5.7049, 2.1006]]),\n",
       " tensor([[7.2592, 3.9728, 5.8498, 1.2413]]),\n",
       " tensor([[5.9027, 2.0347, 3.8376, 0.7778]]),\n",
       " tensor([[5.8396, 3.8802, 5.6221, 1.9802]]),\n",
       " tensor([[5.5293, 3.8865, 6.3859, 0.5169]]),\n",
       " tensor([[7.1922, 3.9282, 5.7400, 0.8986]]),\n",
       " tensor([[6.7291, 2.7119, 5.5916, 2.1126]]),\n",
       " tensor([[5.1111, 2.1739, 6.5745, 2.0868]]),\n",
       " tensor([[7.3504, 3.3208, 4.2722, 1.0237]]),\n",
       " tensor([[7.6853, 4.3970, 6.8927, 2.4970]]),\n",
       " tensor([[5.9342, 3.8414, 6.3458, 2.2746]]),\n",
       " tensor([[4.8105, 2.0074, 6.1759, 2.3055]]),\n",
       " tensor([[6.9132, 3.7109, 5.2060, 1.6998]]),\n",
       " tensor([[4.8119, 2.9769, 6.0297, 0.6482]]),\n",
       " tensor([[4.6686, 4.1239, 4.4169, 1.7768]]),\n",
       " tensor([[6.0716, 2.7750, 5.6110, 0.2770]]),\n",
       " tensor([[5.5015, 2.1248, 1.7257, 1.6087]]),\n",
       " tensor([[6.2367, 3.2912, 3.7530, 1.3912]]),\n",
       " tensor([[6.7131, 3.4149, 2.6645, 1.9369]]),\n",
       " tensor([[7.6460, 4.2307, 6.4838, 0.3262]]),\n",
       " tensor([[5.8915, 2.5566, 4.8698, 0.1213]]),\n",
       " tensor([[5.2302, 4.0295, 3.1488, 2.1295]]),\n",
       " tensor([[7.0289, 3.8193, 5.1293, 1.9193]]),\n",
       " tensor([[6.9612, 3.5807, 5.3614, 1.8741]]),\n",
       " tensor([[6.0666, 3.7105, 5.3431, 1.6263]]),\n",
       " tensor([[5.2336, 3.2696, 6.5613, 1.7944]]),\n",
       " tensor([[6.9980, 2.1243, 2.7556, 2.4825]]),\n",
       " tensor([[7.4048, 3.5486, 6.0885, 1.0536]]),\n",
       " tensor([[5.7834, 4.0417, 5.1682, 2.0332]]),\n",
       " tensor([[5.4935, 3.8391, 5.5210, 0.1146]]),\n",
       " tensor([[5.9890, 3.9894, 4.7627, 0.9632]]),\n",
       " tensor([[7.1036, 4.1950, 6.3960, 0.3240]]),\n",
       " tensor([[7.3586, 4.0390, 6.0127, 2.1390]]),\n",
       " tensor([[5.7374, 2.4862, 5.3105, 1.9724]]),\n",
       " tensor([[5.5717, 3.6748, 5.2260, 0.7417]]),\n",
       " tensor([[4.7536, 3.0977, 5.6734, 1.9463]]),\n",
       " tensor([[4.5907, 3.8081, 5.4449, 1.9081]]),\n",
       " tensor([[4.3100, 2.4140, 4.0223, 0.3526]]),\n",
       " tensor([[5.7177, 2.9451, 3.3235, 1.0451]]),\n",
       " tensor([[7.6284, 4.3030, 6.4548, 0.1686]]),\n",
       " tensor([[5.2233, 4.0079, 6.0353, 1.0698]]),\n",
       " tensor([[6.6101, 4.1279, 6.2694, 2.3202]]),\n",
       " tensor([[5.6507, 2.2407, 5.7411, 0.3507]]),\n",
       " tensor([[5.8652, 2.3763, 4.5566, 0.9946]]),\n",
       " tensor([[6.1594, 3.3947, 4.0473, 1.3396]]),\n",
       " tensor([[4.5700, 3.2864, 6.8617, 2.3440]]),\n",
       " tensor([[7.0138, 4.3111, 6.8632, 1.6150]]),\n",
       " tensor([[6.4404, 2.5085, 6.7323, 2.4318]]),\n",
       " tensor([[5.8663, 2.9061, 4.8354, 0.4718]]),\n",
       " tensor([[6.0020, 3.4714, 6.3099, 0.8377]]),\n",
       " tensor([[7.3823, 2.7112, 4.5568, 1.0540]]),\n",
       " tensor([[7.0382, 3.8255, 5.4876, 1.9255]]),\n",
       " tensor([[6.8060, 3.5519, 4.4974, 2.1422]]),\n",
       " tensor([[7.2367, 3.9578, 5.8129, 2.0578]]),\n",
       " tensor([[7.1427, 3.3021, 5.9332, 2.4935]]),\n",
       " tensor([[7.1841, 2.5009, 6.3455, 1.7368]]),\n",
       " tensor([[7.7947, 4.3298, 6.7275, 2.4298]]),\n",
       " tensor([[6.3395, 2.2931, 4.3426, 1.5781]]),\n",
       " tensor([[6.0238, 2.4409, 4.5458, 1.7282]]),\n",
       " tensor([[6.2408, 3.6941, 5.0357, 1.2711]]),\n",
       " tensor([[6.3789, 2.7578, 4.4071, 1.4859]]),\n",
       " tensor([[4.5103, 2.2113, 5.9100, 0.3678]]),\n",
       " tensor([[6.0094, 3.1396, 3.8016, 1.2396]]),\n",
       " tensor([[6.7273, 3.0225, 5.6372, 0.5565]]),\n",
       " tensor([[6.2572, 2.2149, 5.6689, 0.8253]]),\n",
       " tensor([[6.2680, 2.2196, 2.2054, 2.1337]]),\n",
       " tensor([[4.4014, 3.2604, 3.1015, 1.7246]]),\n",
       " tensor([[5.3364, 2.4441, 6.5428, 2.3547]]),\n",
       " tensor([[7.0056, 3.8037, 5.4342, 0.6982]]),\n",
       " tensor([[4.6512, 2.2341, 2.7571, 0.9977]]),\n",
       " tensor([[7.0894, 2.1730, 6.0294, 1.1420]]),\n",
       " tensor([[5.0486, 2.6278, 4.6292, 0.1746]]),\n",
       " tensor([[7.8404, 3.8227, 6.6440, 0.4310]]),\n",
       " tensor([[5.9717, 2.8562, 1.6877, 2.4519]]),\n",
       " tensor([[7.0936, 2.2893, 3.9482, 1.2294]]),\n",
       " tensor([[7.4521, 4.0085, 6.7925, 0.7730]]),\n",
       " tensor([[6.9884, 4.1936, 5.4060, 1.8923]]),\n",
       " tensor([[6.3909, 2.1494, 1.3609, 2.1254]]),\n",
       " tensor([[4.3700, 3.3787, 6.4939, 2.3348]]),\n",
       " tensor([[7.4710, 2.1410, 6.1969, 2.2140]]),\n",
       " tensor([[6.8372, 3.0619, 5.3789, 0.9676]]),\n",
       " tensor([[7.0983, 3.8322, 6.8873, 1.7533]]),\n",
       " tensor([[7.0287, 3.5352, 6.7912, 1.4541]]),\n",
       " tensor([[6.9352, 2.8760, 4.9495, 0.6250]]),\n",
       " tensor([[6.9585, 4.1699, 6.8041, 0.2272]]),\n",
       " tensor([[7.7099, 3.8956, 4.3811, 1.4754]]),\n",
       " tensor([[6.6369, 4.0979, 3.6896, 1.6316]]),\n",
       " tensor([[4.8267, 3.4041, 4.7909, 0.4272]]),\n",
       " tensor([[7.7598, 4.2460, 5.7468, 0.8116]]),\n",
       " tensor([[7.0244, 2.2603, 5.3022, 2.3446]]),\n",
       " tensor([[7.5614, 3.2390, 5.2902, 0.5155]]),\n",
       " tensor([[5.6736, 2.6079, 5.2238, 1.2827]]),\n",
       " tensor([[4.5787, 2.4496, 4.6460, 1.8905]]),\n",
       " tensor([[6.5374, 3.8758, 5.6680, 0.6812]]),\n",
       " tensor([[5.4232, 4.3931, 5.0289, 1.9798]]),\n",
       " tensor([[6.3293, 2.2528, 6.8961, 2.1559]]),\n",
       " tensor([[5.0062, 2.4708, 3.4453, 0.8225]]),\n",
       " tensor([[4.4300, 3.3277, 2.2918, 2.4434]]),\n",
       " tensor([[6.2600, 3.2342, 3.6661, 1.5123]]),\n",
       " tensor([[7.1579, 4.1348, 3.6065, 2.0836]]),\n",
       " tensor([[7.8346, 3.9656, 5.8321, 2.0656]]),\n",
       " tensor([[6.6106, 2.5764, 3.8713, 0.6764]]),\n",
       " tensor([[6.7600, 2.6059, 4.8073, 2.1402]]),\n",
       " tensor([[7.5260, 2.4920, 1.9602, 2.2507]]),\n",
       " tensor([[7.2524, 3.9682, 5.8386, 2.0682]]),\n",
       " tensor([[4.3093, 3.7829, 4.5407, 1.6379]]),\n",
       " tensor([[6.9330, 4.0452, 6.0279, 0.8521]]),\n",
       " tensor([[5.2435, 2.6638, 5.4799, 1.1587]]),\n",
       " tensor([[6.1038, 2.4956, 6.0504, 2.0621]]),\n",
       " tensor([[5.8029, 4.3718, 6.7947, 2.3528]]),\n",
       " tensor([[4.9597, 3.6521, 5.3742, 2.2672]]),\n",
       " tensor([[5.9256, 3.8081, 4.9468, 0.7744]]),\n",
       " tensor([[6.6463, 3.5642, 4.8453, 1.6642]]),\n",
       " tensor([[4.6797, 3.6592, 5.7231, 1.9313]]),\n",
       " tensor([[7.0255, 2.8858, 3.9022, 1.6125]]),\n",
       " tensor([[7.0285, 2.1423, 6.7132, 1.2743]]),\n",
       " tensor([[7.0292, 3.8194, 5.4728, 1.9194]]),\n",
       " tensor([[5.3466, 3.1417, 4.4931, 2.0432]]),\n",
       " tensor([[6.7739, 3.5961, 5.9053, 0.1512]]),\n",
       " tensor([[4.5105, 2.2144, 3.7694, 2.4224]]),\n",
       " tensor([[5.6906, 4.2954, 4.2960, 1.3699]]),\n",
       " tensor([[4.8925, 3.6454, 5.7733, 2.4925]]),\n",
       " tensor([[6.8751, 3.7167, 5.2203, 2.1998]]),\n",
       " tensor([[4.4992, 4.3274, 6.7216, 2.4274]]),\n",
       " tensor([[7.8079, 4.3386, 6.7491, 2.4386]]),\n",
       " tensor([[5.6394, 3.3429, 4.3012, 1.4429]]),\n",
       " tensor([[7.5797, 3.7154, 3.9346, 2.0939]]),\n",
       " tensor([[7.3173, 2.2061, 6.7279, 2.3068]]),\n",
       " tensor([[4.5296, 2.4255, 3.7354, 1.2127]]),\n",
       " tensor([[4.3521, 2.2102, 6.0490, 2.2508]]),\n",
       " tensor([[6.2976, 3.3317, 4.2738, 1.4317]]),\n",
       " tensor([[4.4669, 2.6742, 6.0355, 0.7598]]),\n",
       " tensor([[7.5537, 4.1691, 6.3324, 2.2691]]),\n",
       " tensor([[4.7198, 3.2881, 5.5339, 0.9276]]),\n",
       " tensor([[6.4431, 2.6855, 4.1285, 1.1452]]),\n",
       " tensor([[6.8556, 4.2094, 4.6334, 2.3725]]),\n",
       " tensor([[4.5405, 3.0703, 5.1478, 1.8736]]),\n",
       " tensor([[4.8870, 3.4533, 6.8501, 1.1945]]),\n",
       " tensor([[5.8270, 3.3560, 5.7903, 2.2185]]),\n",
       " tensor([[6.3571, 3.8141, 6.7999, 0.4577]]),\n",
       " tensor([[4.8877, 2.1763, 3.8723, 2.2864]]),\n",
       " tensor([[4.5224, 2.0243, 2.8773, 1.7220]]),\n",
       " tensor([[6.1012, 2.7036, 6.8807, 1.2667]]),\n",
       " tensor([[7.0867, 2.4520, 5.9199, 2.2826]]),\n",
       " tensor([[7.2652, 3.6894, 5.6288, 1.4443]]),\n",
       " tensor([[6.8959, 3.3138, 4.6462, 2.2598]]),\n",
       " tensor([[6.1688, 3.5716, 6.4117, 2.2560]]),\n",
       " tensor([[7.7286, 3.7444, 6.5202, 1.7219]]),\n",
       " tensor([[6.1851, 2.1583, 4.8808, 0.8227]]),\n",
       " tensor([[5.6937, 4.0559, 6.1275, 0.3337]]),\n",
       " tensor([[4.8191, 2.2764, 6.6544, 0.6901]]),\n",
       " tensor([[6.4800, 3.4534, 5.1752, 1.5534]]),\n",
       " tensor([[5.7865, 4.3152, 6.6915, 1.2720]]),\n",
       " tensor([[5.6303, 3.4761, 4.9263, 1.3151]]),\n",
       " tensor([[6.5968, 3.5312, 4.7641, 1.9508]]),\n",
       " tensor([[4.6214, 4.2849, 6.6171, 2.3849]]),\n",
       " tensor([[4.9195, 2.0935, 4.4108, 1.8406]]),\n",
       " tensor([[6.5481, 2.0265, 4.4657, 0.9589]]),\n",
       " tensor([[6.9006, 2.3223, 6.8884, 2.4336]]),\n",
       " tensor([[7.3438, 2.6797, 4.8190, 1.5284]]),\n",
       " tensor([[7.1849, 3.9233, 4.1643, 2.0233]]),\n",
       " tensor([[6.1748, 3.2155, 6.0833, 0.1761]]),\n",
       " tensor([[6.7187, 3.1067, 4.9640, 1.7125]]),\n",
       " tensor([[5.0183, 2.4620, 4.5985, 1.3717]]),\n",
       " tensor([[5.6346, 3.9726, 5.8492, 2.0726]]),\n",
       " tensor([[4.9222, 4.0254, 5.3898, 2.4343]]),\n",
       " tensor([[4.6312, 2.9791, 4.8728, 1.0945]]),\n",
       " tensor([[5.6183, 3.2264, 4.0149, 1.1040]]),\n",
       " tensor([[5.3237, 2.6449, 6.5223, 1.9450]]),\n",
       " tensor([[7.1986, 3.9324, 3.4142, 2.0324]]),\n",
       " tensor([[7.1473, 3.0413, 2.3924, 2.1167]]),\n",
       " tensor([[7.5014, 4.2225, 3.7718, 2.2343]]),\n",
       " tensor([[6.8240, 2.1789, 4.2920, 0.6429]]),\n",
       " tensor([[6.5117, 3.4744, 4.6247, 0.6107]]),\n",
       " tensor([[7.8367, 2.9738, 3.7207, 1.3133]]),\n",
       " tensor([[7.6665, 4.2635, 6.5174, 2.3444]]),\n",
       " tensor([[6.1072, 3.2048, 3.9617, 1.3048]]),\n",
       " tensor([[4.8823, 2.1728, 4.9092, 1.2239]]),\n",
       " tensor([[5.3408, 2.7334, 5.1187, 0.3261]]),\n",
       " tensor([[5.3758, 3.0203, 2.6146, 1.6054]]),\n",
       " tensor([[4.5105, 2.8633, 3.5471, 2.2775]]),\n",
       " tensor([[5.8368, 4.1901, 4.0592, 1.3444]]),\n",
       " tensor([[4.5746, 3.4296, 5.8988, 0.7419]]),\n",
       " tensor([[4.9552, 2.7715, 2.3742, 2.4366]]),\n",
       " tensor([[4.4211, 2.6532, 4.8798, 2.4580]]),\n",
       " tensor([[5.0945, 2.0625, 6.8702, 0.2286]]),\n",
       " tensor([[5.9267, 4.2998, 5.6108, 1.9756]]),\n",
       " tensor([[4.5829, 3.6108, 3.1008, 1.9720]]),\n",
       " tensor([[7.5876, 3.5041, 5.8265, 0.6201]]),\n",
       " tensor([[7.2884, 3.2210, 4.8953, 2.2502]]),\n",
       " tensor([[7.6760, 2.6879, 5.3872, 0.6407]]),\n",
       " tensor([[4.9288, 3.2344, 6.2956, 1.6221]]),\n",
       " tensor([[6.7478, 2.5592, 5.7297, 1.2197]]),\n",
       " tensor([[5.9717, 3.4799, 5.2152, 1.5892]]),\n",
       " tensor([[5.9921, 3.1280, 3.7731, 1.9557]]),\n",
       " tensor([[6.9588, 2.7004, 2.6904, 2.0790]]),\n",
       " tensor([[5.8841, 2.1926, 2.8774, 1.3981]]),\n",
       " tensor([[6.9730, 2.3765, 2.7072, 2.0005]]),\n",
       " tensor([[7.0773, 2.0963, 5.8512, 0.6444]]),\n",
       " tensor([[4.3281, 3.0714, 5.7656, 0.6031]]),\n",
       " tensor([[6.6309, 2.1769, 6.8414, 2.3282]]),\n",
       " tensor([[5.8134, 2.1921, 4.0030, 0.6055]]),\n",
       " tensor([[7.7993, 3.9181, 3.0054, 2.4328]]),\n",
       " tensor([[5.9113, 4.3316, 6.7319, 2.4316]]),\n",
       " tensor([[4.4321, 3.3761, 4.3828, 1.4761]]),\n",
       " tensor([[7.5396, 3.3377, 3.5404, 2.4902]]),\n",
       " tensor([[6.4599, 3.4399, 4.5398, 1.2462]]),\n",
       " tensor([[4.3743, 3.1559, 6.1359, 1.9145]]),\n",
       " tensor([[5.0190, 2.9095, 6.1524, 0.8985]]),\n",
       " tensor([[7.8843, 2.1078, 6.8743, 2.4895]]),\n",
       " tensor([[7.5430, 2.6463, 6.4661, 1.4418]]),\n",
       " tensor([[7.4916, 4.3489, 3.0983, 2.3585]]),\n",
       " tensor([[7.5401, 3.9876, 4.8218, 1.6094]]),\n",
       " tensor([[7.3418, 3.3694, 3.4724, 2.3599]]),\n",
       " tensor([[4.9662, 2.0487, 6.7150, 2.0150]]),\n",
       " tensor([[7.2671, 3.9781, 5.8627, 0.3911]]),\n",
       " tensor([[5.9021, 3.3236, 3.6256, 1.1681]]),\n",
       " tensor([[7.1360, 3.0505, 3.1721, 2.2212]]),\n",
       " tensor([[4.3385, 4.0681, 5.2824, 1.7918]]),\n",
       " tensor([[7.5972, 4.1982, 6.4038, 0.4364]]),\n",
       " tensor([[5.8158, 3.1080, 5.7449, 1.7212]]),\n",
       " tensor([[6.2750, 2.7544, 2.3427, 1.7599]]),\n",
       " tensor([[6.6740, 2.8482, 3.5893, 2.4980]]),\n",
       " tensor([[4.8130, 3.2440, 4.0581, 1.3440]]),\n",
       " tensor([[4.6096, 3.0775, 3.2420, 2.0925]]),\n",
       " tensor([[4.5793, 3.4397, 3.9274, 1.9033]]),\n",
       " tensor([[5.8430, 3.0895, 3.6534, 2.0915]]),\n",
       " tensor([[7.0569, 2.3088, 6.0339, 0.3782]]),\n",
       " tensor([[5.8542, 2.3745, 1.8315, 2.0680]]),\n",
       " tensor([[4.5214, 2.8584, 2.3248, 1.4659]]),\n",
       " tensor([[6.6500, 3.5667, 4.8514, 1.1846]]),\n",
       " tensor([[4.6318, 2.2346, 4.5616, 1.5057]]),\n",
       " tensor([[7.8006, 3.0708, 6.4871, 0.2085]]),\n",
       " tensor([[6.3844, 4.0085, 6.3057, 0.8996]]),\n",
       " tensor([[7.7393, 2.4298, 6.6367, 2.3929]]),\n",
       " tensor([[4.7128, 4.1178, 3.3948, 2.2642]]),\n",
       " tensor([[7.1115, 2.5350, 4.0305, 1.4296]]),\n",
       " tensor([[5.6513, 2.8293, 3.2146, 1.5151]]),\n",
       " tensor([[7.1385, 2.7064, 5.8769, 1.9733]]),\n",
       " tensor([[4.9980, 4.0549, 5.7949, 2.0030]]),\n",
       " tensor([[5.5139, 2.8497, 3.3519, 1.6337]]),\n",
       " tensor([[6.7653, 2.4925, 5.4161, 0.6379]]),\n",
       " tensor([[4.6987, 3.7983, 3.1945, 1.5351]]),\n",
       " tensor([[6.7398, 2.0551, 5.8118, 0.6341]]),\n",
       " tensor([[5.9454, 2.3666, 6.0024, 2.3684]]),\n",
       " tensor([[7.7870, 3.2629, 3.7071, 1.7079]]),\n",
       " tensor([[5.2059, 2.7306, 3.1820, 1.5934]]),\n",
       " tensor([[4.5927, 3.4641, 4.5993, 1.3936]]),\n",
       " tensor([[4.4300, 2.2507, 3.6805, 1.3130]]),\n",
       " tensor([[7.1716, 2.4374, 1.7873, 2.2863]]),\n",
       " tensor([[7.6621, 4.2414, 6.5101, 2.3414]]),\n",
       " tensor([[5.7586, 2.4021, 2.1473, 2.1172]]),\n",
       " tensor([[6.1093, 2.3591, 6.8250, 0.1778]]),\n",
       " tensor([[5.3633, 4.1950, 5.3984, 1.8892]]),\n",
       " tensor([[6.1227, 3.2151, 3.9872, 1.6935]]),\n",
       " tensor([[7.1357, 4.0334, 5.8022, 0.6072]]),\n",
       " tensor([[6.4823, 4.0768, 4.1923, 2.0629]]),\n",
       " tensor([[6.5715, 3.5143, 4.7228, 1.6143]]),\n",
       " tensor([[7.0387, 3.8258, 5.4884, 0.4729]]),\n",
       " tensor([[4.3347, 2.0843, 4.2057, 0.1135]]),\n",
       " tensor([[5.7926, 2.0559, 6.3178, 1.8303]]),\n",
       " tensor([[6.0178, 3.6733, 5.7318, 0.6696]]),\n",
       " tensor([[6.5679, 3.0363, 3.5475, 1.1363]]),\n",
       " tensor([[6.2779, 3.1036, 2.1725, 2.1967]]),\n",
       " tensor([[4.9270, 2.9795, 3.4078, 1.0795]]),\n",
       " tensor([[4.7386, 4.2630, 2.8895, 2.1091]]),\n",
       " tensor([[5.7771, 2.6729, 6.6305, 0.2873]]),\n",
       " tensor([[4.9119, 3.2025, 6.0205, 2.1141]]),\n",
       " tensor([[6.0081, 2.2146, 4.8960, 1.4746]]),\n",
       " tensor([[5.1679, 2.5786, 3.2431, 1.0125]]),\n",
       " tensor([[6.9175, 3.5460, 6.2919, 1.5194]]),\n",
       " tensor([[6.1319, 2.7938, 4.0023, 0.7744]]),\n",
       " tensor([[5.2421, 4.2180, 5.9796, 2.1885]]),\n",
       " tensor([[5.3051, 2.9187, 5.3450, 1.0814]]),\n",
       " tensor([[7.4731, 2.4692, 1.9258, 2.0228]]),\n",
       " tensor([[7.2462, 3.4646, 5.8285, 2.0641]]),\n",
       " tensor([[6.1729, 4.0797, 4.0695, 1.3486]]),\n",
       " tensor([[7.2098, 3.5990, 3.1296, 1.9348]]),\n",
       " tensor([[6.3893, 2.5833, 4.2225, 1.6852]]),\n",
       " tensor([[5.4188, 2.2295, 4.8804, 0.1066]]),\n",
       " tensor([[6.0502, 3.5981, 4.9265, 1.3316]]),\n",
       " tensor([[6.9394, 4.3345, 6.7389, 2.4345]]),\n",
       " tensor([[6.6488, 4.0260, 5.2245, 2.0225]]),\n",
       " tensor([[4.7374, 4.2082, 6.4102, 1.7575]]),\n",
       " tensor([[5.2708, 3.4676, 4.6079, 1.5676]]),\n",
       " tensor([[7.5060, 3.2008, 6.6171, 0.6041]]),\n",
       " tensor([[5.3321, 2.6772, 6.0317, 0.6644]]),\n",
       " tensor([[7.6149, 2.6986, 5.7288, 1.1939]]),\n",
       " tensor([[5.7731, 3.3188, 4.2420, 1.4188]]),\n",
       " tensor([[6.0016, 3.1344, 3.7887, 1.0847]]),\n",
       " tensor([[4.7034, 3.0840, 5.7091, 2.0346]]),\n",
       " tensor([[7.1319, 2.6327, 3.1123, 1.3342]]),\n",
       " tensor([[6.6378, 3.5586, 4.8315, 0.7660]]),\n",
       " tensor([[6.1900, 3.2600, 3.5099, 1.3600]]),\n",
       " tensor([[4.5205, 3.5450, 4.7981, 0.2470]]),\n",
       " tensor([[6.6176, 2.0112, 4.1564, 2.1634]]),\n",
       " tensor([[5.8041, 3.0028, 3.4651, 2.0417]]),\n",
       " tensor([[6.0566, 4.1084, 4.9470, 0.9904]]),\n",
       " tensor([[7.1812, 4.1506, 3.4377, 2.2385]]),\n",
       " tensor([[6.0148, 3.4918, 3.1342, 1.8442]]),\n",
       " tensor([[7.4842, 2.0172, 6.2185, 2.2228]]),\n",
       " tensor([[4.9097, 3.3467, 4.3106, 1.4467]]),\n",
       " tensor([[4.6692, 3.4120, 3.7782, 2.1216]]),\n",
       " tensor([[7.2925, 3.8362, 5.4506, 2.0850]]),\n",
       " tensor([[5.4283, 2.1343, 5.3965, 2.3016]]),\n",
       " tensor([[6.2793, 3.3196, 4.2439, 1.4196]]),\n",
       " tensor([[5.9096, 2.6379, 6.1964, 2.4692]]),\n",
       " tensor([[4.7870, 3.8652, 5.2362, 0.4105]]),\n",
       " tensor([[5.7292, 2.0061, 3.3423, 1.0528]]),\n",
       " tensor([[4.7293, 2.1003, 3.1664, 0.6453]]),\n",
       " tensor([[5.6009, 2.2658, 1.8179, 1.9392]]),\n",
       " tensor([[6.4517, 2.3564, 5.7464, 1.7549]]),\n",
       " tensor([[5.7916, 4.0627, 5.3712, 1.3173]]),\n",
       " tensor([[6.3327, 3.3552, 4.3314, 1.4552]]),\n",
       " tensor([[7.5946, 4.1884, 6.3799, 2.2884]]),\n",
       " tensor([[6.5049, 3.5157, 4.6135, 1.6157]]),\n",
       " tensor([[5.8832, 4.0185, 5.9622, 2.1185]]),\n",
       " tensor([[4.3809, 3.5312, 4.6817, 1.5748]]),\n",
       " tensor([[5.5556, 2.3387, 5.5081, 1.6445]]),\n",
       " tensor([[7.8649, 3.6397, 5.4659, 0.5607]]),\n",
       " tensor([[6.3742, 4.3194, 6.7018, 1.4608]]),\n",
       " tensor([[6.2126, 2.9944, 5.1721, 0.6168]]),\n",
       " tensor([[7.1891, 3.5942, 4.1246, 2.4748]]),\n",
       " tensor([[6.3715, 2.8154, 4.3950, 1.4810]]),\n",
       " tensor([[5.8787, 3.0524, 3.5872, 1.1524]]),\n",
       " tensor([[7.5062, 3.1642, 3.8619, 1.2642]]),\n",
       " tensor([[6.6046, 2.9638, 4.4538, 1.3755]]),\n",
       " tensor([[4.3238, 4.0624, 4.1202, 1.3693]]),\n",
       " tensor([[7.2947, 2.5951, 5.9080, 0.6948]]),\n",
       " tensor([[4.9851, 2.3955, 2.0768, 1.4586]]),\n",
       " tensor([[6.5564, 3.9551, 4.5181, 2.0551]]),\n",
       " tensor([[7.2872, 2.5644, 5.9413, 2.4205]]),\n",
       " tensor([[5.5146, 2.6346, 1.4208, 2.0987]]),\n",
       " tensor([[4.6990, 2.0077, 1.3267, 2.4801]]),\n",
       " tensor([[6.6204, 3.0807, 2.4104, 1.9054]]),\n",
       " tensor([[6.1933, 2.2675, 4.1530, 1.9657]]),\n",
       " tensor([[7.7308, 4.2872, 3.2985, 2.3872]]),\n",
       " tensor([[6.5123, 3.8538, 3.4763, 2.0177]]),\n",
       " tensor([[7.6435, 4.2290, 6.4796, 0.6751]]),\n",
       " tensor([[4.4335, 2.3683, 3.2012, 1.8089]]),\n",
       " tensor([[7.7314, 3.6500, 3.1262, 2.1229]]),\n",
       " tensor([[4.6741, 2.8395, 2.7833, 1.7264]]),\n",
       " tensor([[6.0631, 2.7239, 3.0510, 1.4098]]),\n",
       " tensor([[5.9364, 3.5007, 5.5702, 1.6495]]),\n",
       " tensor([[5.4444, 2.7629, 2.8755, 2.2361]]),\n",
       " tensor([[5.8017, 3.0011, 3.4611, 1.1011]]),\n",
       " tensor([[4.4089, 2.4655, 2.6136, 1.0638]]),\n",
       " tensor([[4.5893, 3.9758, 4.1700, 1.1984]]),\n",
       " tensor([[6.4755, 4.0832, 4.8950, 2.0810]]),\n",
       " tensor([[5.2094, 3.4755, 5.2606, 0.2652]]),\n",
       " tensor([[5.8669, 2.6100, 2.3422, 2.0904]]),\n",
       " tensor([[5.6313, 2.4798, 5.3238, 1.8847]]),\n",
       " tensor([[7.8350, 3.4302, 6.3618, 0.9183]]),\n",
       " tensor([[5.2296, 3.2045, 5.2787, 1.7550]]),\n",
       " tensor([[5.9083, 3.7963, 4.3406, 1.9130]]),\n",
       " tensor([[5.5283, 3.6667, 5.0972, 0.5178]]),\n",
       " tensor([[4.5729, 3.8792, 4.5892, 0.7021]]),\n",
       " tensor([[5.3777, 2.0048, 2.1889, 1.5174]]),\n",
       " tensor([[6.1335, 2.3799, 4.5078, 0.2703]]),\n",
       " tensor([[7.2517, 2.3019, 3.7755, 1.3744]]),\n",
       " tensor([[5.5106, 2.6803, 4.5865, 0.5887]]),\n",
       " tensor([[5.4365, 3.2365, 4.6333, 0.4151]]),\n",
       " tensor([[7.4262, 4.1861, 6.3742, 0.8005]]),\n",
       " tensor([[5.8495, 2.9279, 3.2444, 2.1733]]),\n",
       " tensor([[7.4073, 3.6210, 6.6538, 1.7219]]),\n",
       " tensor([[6.4100, 4.1434, 4.2341, 1.5512]]),\n",
       " tensor([[7.8793, 2.9741, 4.8528, 1.6878]]),\n",
       " tensor([[5.6625, 2.4793, 4.4876, 1.6237]]),\n",
       " tensor([[6.9697, 3.1196, 3.7524, 1.2196]]),\n",
       " tensor([[5.8349, 3.5666, 4.8512, 1.6666]]),\n",
       " tensor([[6.0821, 3.0003, 5.6884, 2.2281]]),\n",
       " tensor([[6.3675, 4.3715, 5.9659, 1.2939]]),\n",
       " tensor([[7.1546, 3.0261, 6.0408, 2.0657]]),\n",
       " tensor([[6.3669, 3.7973, 5.7613, 2.0368]]),\n",
       " tensor([[5.4746, 3.7622, 5.3321, 1.8622]]),\n",
       " tensor([[7.2630, 3.7248, 5.2401, 1.8248]]),\n",
       " tensor([[4.9788, 3.1783, 3.8966, 1.2783]]),\n",
       " tensor([[4.8762, 2.6273, 6.5039, 0.4529]]),\n",
       " tensor([[6.1998, 3.3164, 4.2360, 1.4164]]),\n",
       " tensor([[4.6801, 3.6788, 5.1750, 1.9895]]),\n",
       " tensor([[4.5807, 3.0072, 3.4761, 1.1072]]),\n",
       " tensor([[6.5156, 4.2235, 5.0074, 1.6638]]),\n",
       " tensor([[5.0259, 3.4382, 5.5869, 0.2664]]),\n",
       " tensor([[5.0946, 2.6672, 4.9542, 0.1455]]),\n",
       " tensor([[4.3988, 3.5828, 5.2708, 0.1448]]),\n",
       " tensor([[6.9072, 3.2486, 4.0694, 1.3486]]),\n",
       " tensor([[7.4228, 2.8064, 5.3011, 0.8721]]),\n",
       " tensor([[5.7122, 4.0321, 3.1567, 2.4657]]),\n",
       " tensor([[5.8783, 3.0522, 3.5867, 1.0240]]),\n",
       " tensor([[4.4319, 3.9134, 6.5794, 2.4625]]),\n",
       " tensor([[6.8249, 4.1869, 5.1380, 1.7832]]),\n",
       " tensor([[4.3282, 2.5678, 4.1001, 1.2402]]),\n",
       " tensor([[7.1478, 4.0115, 5.9449, 0.9322]]),\n",
       " tensor([[7.0497, 3.8331, 5.5065, 1.9331]]),\n",
       " tensor([[5.0917, 3.9901, 6.8282, 1.5235]]),\n",
       " tensor([[7.4019, 3.9472, 6.0836, 2.1679]]),\n",
       " tensor([[6.9112, 3.1991, 3.9479, 1.2991]]),\n",
       " tensor([[7.7426, 3.3151, 4.9536, 1.0353]]),\n",
       " tensor([[7.6068, 4.2045, 6.4194, 2.0545]]),\n",
       " tensor([[7.8109, 3.8492, 3.5479, 1.9492]]),\n",
       " tensor([[6.5536, 2.1023, 3.8779, 2.1941]]),\n",
       " tensor([[7.3466, 2.4221, 6.6268, 2.4720]]),\n",
       " tensor([[5.7754, 2.7041, 4.7656, 0.2293]]),\n",
       " tensor([[5.8101, 3.0067, 3.4748, 1.0207]]),\n",
       " tensor([[4.8605, 3.0725, 3.4219, 1.2748]]),\n",
       " tensor([[6.2351, 2.5241, 2.1648, 1.9301]]),\n",
       " tensor([[5.4182, 2.7455, 3.0529, 1.0984]]),\n",
       " tensor([[7.2210, 2.1452, 3.1771, 2.3050]]),\n",
       " tensor([[4.5584, 2.1052, 5.6592, 0.5773]]),\n",
       " tensor([[5.5277, 3.5374, 4.7349, 1.8939]]),\n",
       " tensor([[7.6914, 4.1882, 5.8777, 2.4230]]),\n",
       " tensor([[6.2455, 3.6390, 2.3819, 2.4521]]),\n",
       " tensor([[5.1211, 3.6364, 3.7551, 2.0064]]),\n",
       " tensor([[7.8480, 2.8388, 6.6116, 2.2548]]),\n",
       " tensor([[7.5242, 4.2156, 4.4752, 1.7304]]),\n",
       " tensor([[7.2639, 4.0136, 6.6835, 0.4426]]),\n",
       " tensor([[5.5577, 2.8384, 4.8371, 1.6608]]),\n",
       " tensor([[5.4603, 3.4630, 4.5966, 1.5630]]),\n",
       " tensor([[5.1693, 3.4397, 4.5393, 1.5397]]),\n",
       " tensor([[4.3946, 3.8303, 5.5602, 2.0257]]),\n",
       " tensor([[6.3000, 2.4036, 4.4552, 1.8377]]),\n",
       " tensor([[4.7035, 2.8198, 4.0683, 0.4316]]),\n",
       " tensor([[7.5471, 2.1285, 4.6661, 1.1745]]),\n",
       " tensor([[6.3894, 3.3930, 4.4243, 1.4930]]),\n",
       " tensor([[6.1187, 4.1675, 6.7368, 0.4061]]),\n",
       " tensor([[4.3563, 3.9413, 3.0181, 2.4164]]),\n",
       " tensor([[4.6161, 3.5145, 5.6283, 2.4369]]),\n",
       " tensor([[4.5678, 4.1906, 3.4967, 1.7274]]),\n",
       " tensor([[7.6434, 4.2289, 3.3786, 2.3289]]),\n",
       " tensor([[5.7474, 2.7473, 5.5387, 0.8678]]),\n",
       " tensor([[7.2474, 2.4245, 2.0435, 2.3945]]),\n",
       " tensor([[5.2091, 4.3396, 6.6021, 0.9909]]),\n",
       " tensor([[6.2948, 4.3197, 6.1966, 0.1028]]),\n",
       " tensor([[7.8437, 3.7536, 6.3388, 1.6849]]),\n",
       " tensor([[7.2372, 2.5622, 4.4415, 2.2396]]),\n",
       " tensor([[7.4038, 3.2919, 5.2063, 1.2818]]),\n",
       " tensor([[4.3649, 2.0432, 5.4730, 0.8475]]),\n",
       " tensor([[5.7897, 2.0487, 3.4414, 1.0931]]),\n",
       " tensor([[6.1911, 2.3884, 4.0993, 0.4884]]),\n",
       " tensor([[5.8661, 2.0339, 2.9774, 1.9986]]),\n",
       " tensor([[7.1741, 4.1279, 6.2312, 0.1697]]),\n",
       " tensor([[5.7320, 3.8409, 5.9347, 0.4163]]),\n",
       " tensor([[5.1421, 3.2925, 4.1773, 0.6614]]),\n",
       " tensor([[6.5297, 2.9307, 3.2881, 1.5864]]),\n",
       " tensor([[5.5353, 4.0642, 6.0744, 0.3445]]),\n",
       " tensor([[7.6678, 3.5479, 4.8052, 1.6479]]),\n",
       " tensor([[5.2729, 2.6486, 4.5872, 1.5592]]),\n",
       " tensor([[4.5843, 2.3158, 4.4602, 1.7266]]),\n",
       " tensor([[5.3471, 3.0090, 2.6932, 1.6938]]),\n",
       " tensor([[4.5883, 2.3269, 6.0616, 1.1204]]),\n",
       " tensor([[7.4160, 3.2501, 6.0384, 0.1794]]),\n",
       " tensor([[5.4933, 3.5914, 4.9122, 1.6914]]),\n",
       " tensor([[5.4698, 3.8970, 4.2032, 2.3880]]),\n",
       " tensor([[7.4531, 4.1021, 6.1676, 2.2083]]),\n",
       " tensor([[6.2721, 3.2589, 6.1996, 0.9123]]),\n",
       " tensor([[5.5845, 3.0899, 4.6968, 2.4250]]),\n",
       " tensor([[4.6144, 3.1543, 4.9286, 0.3517]]),\n",
       " tensor([[6.5936, 3.5291, 4.7589, 1.6291]]),\n",
       " tensor([[7.1523, 2.4861, 6.6603, 0.5714]]),\n",
       " tensor([[5.9417, 4.2554, 6.5446, 0.1010]]),\n",
       " tensor([[6.7388, 4.1367, 4.0022, 1.6706]]),\n",
       " tensor([[5.0354, 3.1268, 3.7700, 1.2268]]),\n",
       " tensor([[5.9577, 3.5242, 3.9789, 1.6042]]),\n",
       " tensor([[7.7270, 3.2608, 2.9886, 2.1593]]),\n",
       " tensor([[5.1789, 4.0900, 6.1379, 2.1900]]),\n",
       " tensor([[6.3016, 2.5547, 4.1741, 1.3911]]),\n",
       " tensor([[4.4124, 2.0750, 2.5733, 0.8716]]),\n",
       " tensor([[7.7084, 2.8930, 6.8337, 1.2854]]),\n",
       " tensor([[7.7945, 3.8128, 5.3532, 1.3053]]),\n",
       " tensor([[5.5187, 2.7535, 5.3510, 1.2060]]),\n",
       " tensor([[5.6550, 2.9033, 3.9146, 1.0033]]),\n",
       " tensor([[7.4342, 3.2281, 4.0190, 1.3281]]),\n",
       " tensor([[5.5025, 3.6159, 4.9724, 1.7159]]),\n",
       " tensor([[6.6507, 3.5213, 4.7398, 1.6213]]),\n",
       " tensor([[7.1906, 4.1662, 5.7374, 2.0271]]),\n",
       " tensor([[7.0420, 4.3534, 6.2381, 0.7923]]),\n",
       " tensor([[5.2746, 2.6498, 2.5973, 1.6056]]),\n",
       " tensor([[6.3662, 3.0272, 3.5253, 1.6272]]),\n",
       " tensor([[6.2067, 3.2353, 6.8596, 2.3649]]),\n",
       " tensor([[4.6773, 3.1502, 4.5458, 0.5894]]),\n",
       " tensor([[7.0246, 3.2177, 3.4564, 2.3860]]),\n",
       " tensor([[6.5651, 3.2242, 4.7122, 1.6101]]),\n",
       " tensor([[4.7393, 2.8666, 6.6812, 1.1272]]),\n",
       " tensor([[5.9535, 3.4003, 5.8045, 1.6925]]),\n",
       " tensor([[7.8578, 2.2061, 4.2114, 0.9076]]),\n",
       " tensor([[7.5721, 3.2973, 6.3627, 2.2814]]),\n",
       " tensor([[6.6979, 4.3909, 4.9299, 1.6986]]),\n",
       " tensor([[5.6054, 2.2280, 3.1770, 1.3820]]),\n",
       " tensor([[7.6564, 3.9436, 5.4693, 0.7461]]),\n",
       " tensor([[5.6990, 3.3535, 4.5496, 0.5388]]),\n",
       " tensor([[6.5934, 3.5289, 4.7586, 1.6289]]),\n",
       " tensor([[4.5944, 3.7849, 4.4487, 1.7010]]),\n",
       " tensor([[5.2372, 3.1612, 5.5085, 1.3228]]),\n",
       " tensor([[5.5713, 2.4665, 5.0269, 1.6577]]),\n",
       " tensor([[5.1844, 2.3708, 3.1651, 1.5721]]),\n",
       " tensor([[4.6153, 2.2102, 4.3196, 0.3102]]),\n",
       " tensor([[7.6010, 2.7563, 6.3771, 0.6552]]),\n",
       " tensor([[7.0973, 4.0010, 6.8093, 0.1985]]),\n",
       " tensor([[6.8867, 2.8087, 3.1615, 1.8204]]),\n",
       " tensor([[7.8030, 3.8040, 6.3265, 1.0401]]),\n",
       " tensor([[4.4441, 2.2777, 1.9882, 1.8106]]),\n",
       " tensor([[7.1259, 3.7394, 3.4649, 1.7433]]),\n",
       " tensor([[7.3643, 4.2605, 6.5570, 2.3605]]),\n",
       " tensor([[5.9157, 3.0771, 3.6479, 1.1771]]),\n",
       " tensor([[6.2678, 4.1359, 6.2507, 2.2359]]),\n",
       " tensor([[4.5993, 2.2570, 4.5939, 1.8311]]),\n",
       " tensor([[7.3908, 3.1873, 6.0654, 2.1605]]),\n",
       " tensor([[7.7131, 3.1175, 3.8830, 1.2728]]),\n",
       " tensor([[5.7997, 3.5246, 3.8865, 2.4368]]),\n",
       " tensor([[7.5013, 2.6660, 6.2466, 2.2342]]),\n",
       " tensor([[7.0057, 2.3358, 4.0602, 0.6937]]),\n",
       " tensor([[7.1304, 3.9288, 6.8594, 1.1948]]),\n",
       " tensor([[6.5167, 2.5885, 4.8345, 0.2012]]),\n",
       " tensor([[4.7431, 2.0051, 3.1743, 1.9753]]),\n",
       " tensor([[5.7585, 3.4345, 2.2138, 2.0794]]),\n",
       " tensor([[4.4291, 3.5448, 6.0129, 0.6753]]),\n",
       " tensor([[4.6676, 2.0089, 3.2708, 0.9798]]),\n",
       " tensor([[6.3517, 3.4009, 3.8034, 1.4626]]),\n",
       " tensor([[4.6776, 2.9954, 4.2511, 1.5589]]),\n",
       " tensor([[6.6427, 2.3106, 5.8561, 0.7659]]),\n",
       " tensor([[5.9536, 4.1270, 4.6973, 1.4772]]),\n",
       " tensor([[5.7325, 2.1688, 1.5072, 2.3628]]),\n",
       " tensor([[4.5585, 3.2093, 3.9729, 1.3093]]),\n",
       " tensor([[7.2279, 4.1173, 5.8034, 2.3533]]),\n",
       " tensor([[6.4336, 4.1824, 5.9594, 0.4253]]),\n",
       " tensor([[5.9063, 3.8017, 5.4291, 1.9017]]),\n",
       " tensor([[4.6140, 4.3494, 6.8218, 0.1966]]),\n",
       " tensor([[7.7283, 3.6710, 5.1078, 1.7710]]),\n",
       " tensor([[6.4459, 3.9038, 5.6801, 2.0038]]),\n",
       " tensor([[6.3110, 3.0804, 6.3552, 2.1294]]),\n",
       " tensor([[5.8769, 4.0241, 5.9759, 2.1241]]),\n",
       " tensor([[5.7049, 3.8956, 6.3087, 0.2126]]),\n",
       " tensor([[6.2699, 3.0156, 3.4636, 2.2036]]),\n",
       " tensor([[7.8152, 2.8254, 5.8261, 2.0548]]),\n",
       " tensor([[5.1408, 2.9459, 5.2857, 1.1443]]),\n",
       " tensor([[7.2943, 3.9962, 5.9074, 2.0962]]),\n",
       " tensor([[6.9684, 2.7058, 3.7495, 2.2415]]),\n",
       " tensor([[5.7927, 3.1686, 3.4464, 1.0952]]),\n",
       " tensor([[5.8915, 3.8147, 6.7337, 1.0772]]),\n",
       " tensor([[6.3074, 3.1835, 6.5055, 1.2912]]),\n",
       " tensor([[6.5365, 3.6124, 4.7817, 1.6753]]),\n",
       " tensor([[7.7619, 2.7228, 6.6239, 0.4663]]),\n",
       " tensor([[7.4114, 4.0817, 4.1426, 1.8427]]),\n",
       " tensor([[4.5352, 2.1568, 1.7577, 2.3394]]),\n",
       " tensor([[5.6864, 2.1901, 3.2722, 1.0243]]),\n",
       " tensor([[6.6054, 3.9121, 4.7784, 1.6370]]),\n",
       " tensor([[6.2538, 2.2359, 4.7762, 1.2362]]),\n",
       " tensor([[4.9492, 3.7330, 3.3661, 1.7022]]),\n",
       " tensor([[4.5147, 4.1303, 6.2369, 2.2303]]),\n",
       " tensor([[4.8394, 2.5720, 6.0383, 1.2960]]),\n",
       " tensor([[4.7630, 3.0536, 3.5901, 1.7045]]),\n",
       " tensor([[7.1333, 2.8697, 6.6225, 1.4887]]),\n",
       " tensor([[5.1150, 3.8383, 4.6655, 1.9365]]),\n",
       " tensor([[4.7425, 3.9220, 5.7250, 2.0220]]),\n",
       " tensor([[4.4056, 2.0379, 3.6945, 1.0173]]),\n",
       " tensor([[7.7844, 3.0546, 4.1067, 1.5488]]),\n",
       " tensor([[5.5031, 2.1290, 1.3445, 1.9751]]),\n",
       " tensor([[7.6010, 4.2007, 6.4100, 2.3007]]),\n",
       " tensor([[5.1361, 2.7013, 4.9344, 1.1203]]),\n",
       " tensor([[5.6725, 2.5489, 3.8122, 1.2801]]),\n",
       " tensor([[7.0667, 4.3201, 5.7459, 0.5651]]),\n",
       " tensor([[6.9932, 2.6804, 4.7936, 1.8787]]),\n",
       " tensor([[6.7732, 2.7057, 5.7954, 0.8684]]),\n",
       " tensor([[6.0314, 3.8488, 5.8969, 0.7735]]),\n",
       " tensor([[4.9774, 2.3850, 4.7415, 0.6416]]),\n",
       " tensor([[6.0121, 3.8172, 5.4674, 0.1527]]),\n",
       " tensor([[4.9066, 2.9651, 6.8781, 2.1738]]),\n",
       " tensor([[6.5609, 4.3656, 4.3161, 2.0661]]),\n",
       " tensor([[7.1829, 2.1879, 4.9236, 0.3409]]),\n",
       " tensor([[5.0188, 2.0044, 2.4848, 1.0997]]),\n",
       " tensor([[7.7832, 2.2830, 3.4284, 2.4394]]),\n",
       " tensor([[7.0541, 3.8361, 5.5137, 1.9361]]),\n",
       " tensor([[6.8834, 4.2546, 3.0500, 2.3853]]),\n",
       " tensor([[4.5603, 3.4165, 6.6122, 2.0083]]),\n",
       " tensor([[4.5121, 3.8816, 5.4654, 0.5483]]),\n",
       " tensor([[6.3368, 3.2164, 3.8165, 1.2457]]),\n",
       " tensor([[6.6616, 2.2133, 4.1952, 1.6686]]),\n",
       " tensor([[4.3307, 3.0808, 4.3063, 1.3992]]),\n",
       " tensor([[7.3254, 4.3205, 5.7168, 1.1122]]),\n",
       " tensor([[7.6474, 3.6493, 4.3877, 2.1057]]),\n",
       " tensor([[7.6657, 3.3364, 2.9189, 2.1857]]),\n",
       " tensor([[5.5563, 2.7748, 6.6492, 1.5315]]),\n",
       " tensor([[4.7039, 2.8436, 5.9085, 1.1792]]),\n",
       " tensor([[5.8519, 2.3180, 3.5433, 1.1346]]),\n",
       " tensor([[6.2035, 2.2074, 3.0387, 1.5620]]),\n",
       " tensor([[4.5219, 4.1776, 6.3532, 2.2776]]),\n",
       " tensor([[4.6623, 3.3918, 3.9347, 2.2042]]),\n",
       " tensor([[5.1179, 2.8751, 5.5882, 1.2842]]),\n",
       " tensor([[6.5306, 3.4871, 3.7344, 1.5871]]),\n",
       " tensor([[5.9987, 3.4705, 6.3271, 1.6749]]),\n",
       " tensor([[6.4395, 2.6137, 4.9803, 0.8367]]),\n",
       " tensor([[6.4522, 3.8336, 6.5233, 0.9463]]),\n",
       " tensor([[6.3753, 3.7847, 5.3875, 1.8847]]),\n",
       " tensor([[5.8008, 3.5446, 4.7971, 1.1006]]),\n",
       " tensor([[6.4530, 3.3468, 5.3694, 1.8427]]),\n",
       " tensor([[5.0194, 3.1277, 3.7722, 1.2277]]),\n",
       " tensor([[7.6706, 3.2209, 4.7636, 1.5052]]),\n",
       " tensor([[6.9460, 4.2775, 5.3365, 1.8640]]),\n",
       " tensor([[5.9454, 2.5078, 3.7490, 1.5956]]),\n",
       " tensor([[6.0908, 2.0560, 4.0077, 0.8746]]),\n",
       " tensor([[5.9864, 2.5950, 4.0311, 1.3330]]),\n",
       " tensor([[5.8532, 2.6611, 6.0628, 0.3272]]),\n",
       " tensor([[6.3068, 3.0328, 4.2889, 1.1328]]),\n",
       " tensor([[6.5326, 3.4884, 4.6590, 0.7557]]),\n",
       " tensor([[5.6743, 2.0399, 2.1786, 1.5720]]),\n",
       " tensor([[5.4460, 2.7640, 2.8781, 1.2859]]),\n",
       " tensor([[6.6517, 3.6027, 5.0067, 0.8224]]),\n",
       " tensor([[6.4765, 2.3740, 4.5670, 1.5510]]),\n",
       " tensor([[4.3109, 2.4482, 3.2768, 2.4670]]),\n",
       " tensor([[7.4490, 2.7184, 4.1667, 0.9025]]),\n",
       " tensor([[5.2461, 2.6508, 5.7066, 1.7353]]),\n",
       " tensor([[5.0310, 2.3127, 6.4490, 1.2869]]),\n",
       " tensor([[6.5603, 3.2175, 5.7132, 1.9517]]),\n",
       " tensor([[7.2855, 4.0000, 5.9166, 0.2479]]),\n",
       " tensor([[4.6043, 4.3842, 4.5614, 1.1694]]),\n",
       " tensor([[6.1548, 2.3785, 4.0399, 1.3366]]),\n",
       " tensor([[5.7097, 2.0616, 2.0387, 2.1619]]),\n",
       " tensor([[4.4858, 2.0892, 1.5218, 1.5790]]),\n",
       " tensor([[4.4804, 3.3292, 5.2898, 1.7477]]),\n",
       " tensor([[5.0177, 3.8607, 6.3936, 1.6328]]),\n",
       " tensor([[7.5117, 2.1153, 5.0100, 0.3706]]),\n",
       " tensor([[5.1254, 3.6944, 5.8930, 2.2084]]),\n",
       " tensor([[6.7781, 2.4027, 4.1302, 1.2079]]),\n",
       " tensor([[6.0061, 3.1374, 3.7962, 1.1889]]),\n",
       " tensor([[6.0975, 2.7021, 2.9284, 1.4342]]),\n",
       " tensor([[6.0827, 3.0228, 6.2636, 2.2161]]),\n",
       " tensor([[7.5458, 3.2092, 2.9063, 2.0747]]),\n",
       " tensor([[5.5237, 3.9968, 4.8826, 0.8222]]),\n",
       " tensor([[4.5954, 3.3466, 4.3105, 1.4466]]),\n",
       " tensor([[4.6661, 3.4270, 3.2963, 1.7845]]),\n",
       " tensor([[5.0803, 2.8658, 3.9046, 1.4874]]),\n",
       " tensor([[7.7886, 4.3257, 6.7175, 2.4257]]),\n",
       " tensor([[7.0038, 3.1956, 6.4407, 1.6880]]),\n",
       " tensor([[5.0099, 3.7012, 3.0952, 2.4321]]),\n",
       " tensor([[4.3643, 2.5603, 3.6492, 0.9812]]),\n",
       " tensor([[7.0798, 2.5567, 5.5558, 0.2333]]),\n",
       " tensor([[5.3536, 2.8360, 5.1068, 1.9754]]),\n",
       " tensor([[4.9503, 3.3585, 4.3395, 0.5335]]),\n",
       " tensor([[4.4565, 2.9159, 2.2968, 2.4193]]),\n",
       " tensor([[6.1117, 2.7372, 5.5443, 1.0978]]),\n",
       " tensor([[4.4543, 3.8995, 4.9330, 1.5070]]),\n",
       " tensor([[6.6715, 2.8755, 4.8866, 1.6810]]),\n",
       " tensor([[5.3795, 2.9801, 5.1932, 2.1404]]),\n",
       " tensor([[5.0926, 2.0727, 4.9330, 0.8890]]),\n",
       " tensor([[4.6024, 2.7230, 5.2088, 1.9046]]),\n",
       " tensor([[6.9258, 3.5396, 5.3034, 1.8505]]),\n",
       " tensor([[6.9872, 2.5069, 6.0154, 1.2356]]),\n",
       " tensor([[7.8194, 2.6401, 6.7678, 2.4462]]),\n",
       " tensor([[6.9804, 2.5640, 6.6199, 0.3596]]),\n",
       " tensor([[5.3683, 2.1554, 6.6720, 2.3279]]),\n",
       " tensor([[5.8989, 4.1754, 3.2967, 2.0533]]),\n",
       " tensor([[6.4126, 2.4836, 6.1111, 1.5796]]),\n",
       " tensor([[5.5920, 3.9129, 6.6399, 1.4182]]),\n",
       " tensor([[4.9472, 2.3359, 1.7813, 1.9578]]),\n",
       " tensor([[4.7535, 2.6424, 6.3843, 0.7297]]),\n",
       " tensor([[7.7634, 4.3089, 6.6761, 0.3669]]),\n",
       " tensor([[5.4355, 3.2099, 5.2216, 0.5218]]),\n",
       " tensor([[7.2357, 2.7939, 4.0976, 2.1049]]),\n",
       " tensor([[5.4864, 3.3936, 6.3670, 0.6493]]),\n",
       " tensor([[4.7809, 3.8610, 6.4342, 1.0380]]),\n",
       " tensor([[7.6420, 4.2280, 6.4772, 2.3280]]),\n",
       " tensor([[5.1706, 2.7003, 5.6802, 0.3416]]),\n",
       " tensor([[7.3571, 2.9666, 5.7832, 1.7246]]),\n",
       " tensor([[5.8700, 3.0467, 3.5731, 1.4662]]),\n",
       " tensor([[7.0005, 3.5996, 5.4258, 1.9003]]),\n",
       " tensor([[5.9573, 2.6131, 3.4864, 2.2848]]),\n",
       " tensor([[6.0176, 2.2805, 6.8510, 2.4849]]),\n",
       " tensor([[5.8343, 3.1810, 6.7236, 0.4799]]),\n",
       " tensor([[5.1172, 3.0187, 3.5043, 0.8857]]),\n",
       " tensor([[7.4623, 4.1082, 6.1826, 2.2082]]),\n",
       " tensor([[7.6845, 3.0636, 3.3882, 1.7892]]),\n",
       " tensor([[7.7581, 4.1683, 5.3515, 2.1990]]),\n",
       " tensor([[7.1407, 3.8938, 3.1004, 1.9938]]),\n",
       " tensor([[5.9698, 2.8430, 4.9425, 2.4232]]),\n",
       " tensor([[7.1931, 2.3869, 5.7414, 2.0287]]),\n",
       " tensor([[6.2863, 2.9079, 2.3383, 1.8022]]),\n",
       " tensor([[5.8489, 2.0216, 1.5165, 2.3160]]),\n",
       " tensor([[7.6995, 4.2664, 6.5715, 2.4683]]),\n",
       " tensor([[7.7628, 3.3790, 6.6751, 2.4085]]),\n",
       " tensor([[5.7788, 2.0206, 3.8653, 1.0225]]),\n",
       " tensor([[6.6627, 3.7209, 5.2306, 1.8209]]),\n",
       " tensor([[7.7764, 3.1171, 3.7463, 1.2171]]),\n",
       " tensor([[5.9431, 2.8608, 3.6928, 0.9608]]),\n",
       " tensor([[7.0199, 3.1618, 3.6986, 2.3148]]),\n",
       " tensor([[5.8725, 3.2556, 6.8126, 0.8749]]),\n",
       " tensor([[7.0291, 3.8194, 5.4726, 1.9194]]),\n",
       " tensor([[7.7106, 4.2737, 6.5896, 1.0684]]),\n",
       " tensor([[5.9776, 3.1184, 3.7494, 1.2184]]),\n",
       " tensor([[6.6113, 3.5409, 4.7879, 1.6409]]),\n",
       " tensor([[6.4689, 2.7879, 6.7975, 2.4943]]),\n",
       " tensor([[6.0654, 2.3748, 5.4626, 0.1861]]),\n",
       " tensor([[5.4694, 2.1701, 5.4603, 0.9586]]),\n",
       " tensor([[5.1822, 2.6711, 4.9403, 1.2374]]),\n",
       " tensor([[7.1846, 3.3217, 5.8192, 0.9186]]),\n",
       " tensor([[5.8077, 3.4962, 4.0557, 1.8764]]),\n",
       " tensor([[6.0901, 3.1934, 3.9338, 1.4513]]),\n",
       " tensor([[5.0327, 3.5397, 4.5926, 1.6468]]),\n",
       " tensor([[7.3968, 2.1579, 6.0753, 2.1645]]),\n",
       " tensor([[7.4740, 4.1160, 4.1942, 2.2160]]),\n",
       " tensor([[6.8430, 3.2538, 6.4017, 0.7219]]),\n",
       " tensor([[4.6331, 3.5071, 2.1377, 2.1124]]),\n",
       " tensor([[4.8887, 2.0186, 3.8702, 2.4154]]),\n",
       " tensor([[7.6927, 4.1973, 6.1457, 1.9429]]),\n",
       " tensor([[5.9289, 3.0859, 3.6695, 1.1859]]),\n",
       " tensor([[7.1755, 3.9170, 5.7126, 2.0170]]),\n",
       " tensor([[6.6962, 3.0781, 3.3644, 1.3252]]),\n",
       " tensor([[5.9970, 2.9613, 6.2815, 1.3554]]),\n",
       " tensor([[7.5612, 3.8547, 5.4463, 1.0013]]),\n",
       " tensor([[6.0876, 3.5411, 4.4423, 1.7542]]),\n",
       " tensor([[4.4375, 2.2546, 4.8018, 1.6452]]),\n",
       " tensor([[7.4386, 4.0924, 3.1277, 2.1924]]),\n",
       " tensor([[6.7698, 2.0194, 5.0477, 0.1194]]),\n",
       " tensor([[6.6319, 2.7297, 3.9213, 1.9578]]),\n",
       " tensor([[6.3303, 3.3536, 4.3275, 1.2569]]),\n",
       " tensor([[6.1010, 2.5003, 3.5121, 1.1828]]),\n",
       " tensor([[6.8402, 3.9287, 5.7413, 2.0287]]),\n",
       " tensor([[7.6402, 4.2268, 6.4741, 2.3268]]),\n",
       " tensor([[6.4771, 3.5035, 3.3618, 1.8783]]),\n",
       " tensor([[7.1561, 2.8414, 3.2279, 2.1903]]),\n",
       " tensor([[6.3476, 2.2069, 4.6317, 1.5773]]),\n",
       " tensor([[4.5913, 3.9696, 5.2409, 2.4619]]),\n",
       " tensor([[4.5118, 2.3561, 5.1632, 0.3612]]),\n",
       " tensor([[5.5526, 2.1062, 4.7425, 2.2463]]),\n",
       " tensor([[7.4500, 2.7001, 6.2965, 1.2437]]),\n",
       " tensor([[6.1518, 2.2193, 6.3495, 1.2596]]),\n",
       " tensor([[5.7846, 4.1398, 3.7667, 2.2398]]),\n",
       " tensor([[7.5224, 3.0853, 4.6197, 2.0517]]),\n",
       " tensor([[5.9739, 2.0910, 1.7820, 2.0587]]),\n",
       " tensor([[6.4195, 2.8970, 4.9962, 2.0786]]),\n",
       " tensor([[6.0949, 2.5580, 3.9417, 0.8673]]),\n",
       " tensor([[6.6980, 2.4490, 3.2167, 1.2217]]),\n",
       " tensor([[6.9725, 3.5340, 5.3338, 2.2391]]),\n",
       " tensor([[4.9869, 2.4579, 2.1257, 2.0085]]),\n",
       " tensor([[7.7343, 4.2896, 2.9150, 2.3896]]),\n",
       " tensor([[7.0224, 4.0766, 6.2866, 2.2505]]),\n",
       " tensor([[5.6263, 2.1402, 3.1737, 0.9842]]),\n",
       " tensor([[5.5014, 3.8361, 5.9023, 1.9517]]),\n",
       " tensor([[6.3761, 3.8686, 4.5636, 1.2821]]),\n",
       " tensor([[5.7760, 3.4344, 4.2075, 1.8829]]),\n",
       " tensor([[6.2608, 2.0333, 5.1848, 1.6307]]),\n",
       " tensor([[6.3607, 2.1168, 2.3928, 2.1835]]),\n",
       " tensor([[6.6406, 3.5604, 4.8360, 2.2191]]),\n",
       " tensor([[4.9035, 3.5767, 4.8761, 1.6767]]),\n",
       " tensor([[7.5239, 2.9344, 6.3679, 1.3838]]),\n",
       " tensor([[5.4547, 2.7698, 2.8924, 1.7423]]),\n",
       " tensor([[5.4579, 2.9360, 4.3625, 2.4710]]),\n",
       " tensor([[6.3686, 2.6960, 5.0763, 2.0583]]),\n",
       " tensor([[6.6124, 2.5337, 2.3121, 1.6416]]),\n",
       " tensor([[6.4961, 3.5780, 4.2983, 1.7742]]),\n",
       " tensor([[5.1798, 2.2308, 2.9518, 2.1462]]),\n",
       " tensor([[6.3076, 4.1840, 4.4719, 2.4163]]),\n",
       " tensor([[5.9143, 2.7909, 3.6456, 1.1762]]),\n",
       " tensor([[6.3509, 3.3673, 4.3612, 1.4673]]),\n",
       " tensor([[4.4879, 2.1252, 4.4207, 1.4915]]),\n",
       " tensor([[6.5052, 3.0225, 3.0898, 1.6252]]),\n",
       " tensor([[6.3367, 3.3578, 4.3379, 0.7740]]),\n",
       " tensor([[5.3385, 2.6923, 2.7020, 1.4326]]),\n",
       " tensor([[7.4213, 2.8245, 6.1155, 0.2194]]),\n",
       " tensor([[5.4188, 2.6058, 1.7358, 2.0182]]),\n",
       " tensor([[4.3429, 4.1504, 5.1721, 2.3447]]),\n",
       " tensor([[5.3595, 3.0493, 2.0511, 2.2783]]),\n",
       " tensor([[6.3143, 3.3180, 4.3012, 1.4429]]),\n",
       " tensor([[7.0162, 3.5227, 3.9515, 2.4705]]),\n",
       " tensor([[5.8334, 3.0223, 3.5131, 1.1223]]),\n",
       " tensor([[6.6076, 2.4464, 1.3574, 2.4735]]),\n",
       " tensor([[7.4593, 2.8261, 6.1777, 2.2062]]),\n",
       " tensor([[4.5460, 3.0703, 5.6821, 0.8194]]),\n",
       " tensor([[6.2115, 4.0832, 5.4938, 1.5558]]),\n",
       " tensor([[7.3876, 4.0584, 6.0603, 0.6973]]),\n",
       " tensor([[5.8409, 2.9859, 6.3502, 1.4780]]),\n",
       " tensor([[4.6863, 3.5400, 1.7620, 2.4116]]),\n",
       " tensor([[7.0378, 3.0090, 4.7966, 1.5674]]),\n",
       " tensor([[4.9497, 3.8258, 6.2578, 2.2388]]),\n",
       " tensor([[6.8447, 4.2794, 4.6399, 1.5806]]),\n",
       " tensor([[6.4559, 2.2834, 6.2715, 0.8870]]),\n",
       " tensor([[5.6524, 2.5703, 3.8834, 1.0479]]),\n",
       " tensor([[7.5837, 3.4779, 4.6332, 1.5779]]),\n",
       " tensor([[5.0185, 2.4915, 3.7078, 2.1991]]),\n",
       " tensor([[6.7376, 2.4152, 3.5404, 1.7250]]),\n",
       " tensor([[6.4821, 4.2725, 5.9228, 1.4343]]),\n",
       " tensor([[6.0259, 2.1375, 5.7039, 0.1979]]),\n",
       " tensor([[4.9371, 3.5579, 4.8298, 1.6579]]),\n",
       " tensor([[7.4775, 4.1838, 5.1923, 0.8929]]),\n",
       " tensor([[4.3132, 3.8277, 5.4930, 0.1542]]),\n",
       " tensor([[6.9201, 3.7467, 5.2940, 0.4141]]),\n",
       " tensor([[6.2089, 3.2726, 4.1284, 1.3726]]),\n",
       " tensor([[6.4175, 3.2965, 4.3606, 1.9026]]),\n",
       " tensor([[6.2946, 3.3298, 4.2690, 0.8532]]),\n",
       " tensor([[4.3893, 2.3884, 5.9717, 1.7006]]),\n",
       " tensor([[5.9737, 3.1158, 4.1033, 1.2158]]),\n",
       " tensor([[7.6026, 3.1318, 6.2577, 0.1380]]),\n",
       " tensor([[5.6942, 2.9136, 6.3110, 0.8270]]),\n",
       " tensor([[5.7614, 3.6915, 2.5401, 2.3491]]),\n",
       " tensor([[4.3604, 3.0049, 5.3972, 0.5420]]),\n",
       " tensor([[6.7381, 2.1598, 3.7899, 1.7115]]),\n",
       " tensor([[4.3230, 2.9393, 5.9011, 1.0098]]),\n",
       " tensor([[6.0440, 2.9747, 3.8170, 1.9706]]),\n",
       " tensor([[6.5469, 4.3143, 4.9134, 1.7587]]),\n",
       " tensor([[6.7269, 3.5578, 4.9774, 1.7179]]),\n",
       " tensor([[4.9045, 3.1280, 5.0965, 0.3805]]),\n",
       " tensor([[5.2105, 3.6681, 6.4244, 1.3286]]),\n",
       " tensor([[7.5793, 2.1876, 2.0858, 2.3012]]),\n",
       " tensor([[5.5148, 2.3429, 5.5865, 2.2051]]),\n",
       " tensor([[5.8501, 2.5991, 3.4269, 1.3831]]),\n",
       " tensor([[5.2957, 3.3266, 4.8754, 1.6764]]),\n",
       " tensor([[5.7725, 3.8839, 6.4465, 0.9395]]),\n",
       " tensor([[6.7638, 3.0975, 3.8839, 1.2298]]),\n",
       " tensor([[6.9049, 2.1475, 5.5886, 2.2193]]),\n",
       " tensor([[7.0653, 2.4527, 6.5558, 2.0685]]),\n",
       " tensor([[5.7816, 2.9877, 3.4282, 1.0877]]),\n",
       " tensor([[6.2648, 4.0544, 3.1406, 2.0915]]),\n",
       " tensor([[7.2588, 2.3163, 4.5095, 1.5789]]),\n",
       " tensor([[5.9901, 2.5206, 3.7698, 1.2267]]),\n",
       " tensor([[7.7018, 2.0821, 6.5751, 2.3679]]),\n",
       " tensor([[4.6219, 3.1687, 3.2472, 1.9902]]),\n",
       " tensor([[5.9128, 3.3776, 4.4110, 2.4576]]),\n",
       " tensor([[5.8433, 2.6782, 3.5293, 1.1289]]),\n",
       " tensor([[4.3967, 2.8419, 1.7436, 2.1173]]),\n",
       " tensor([[6.7946, 3.2796, 5.5086, 2.4174]]),\n",
       " tensor([[5.2877, 2.6585, 2.6187, 1.6665]]),\n",
       " tensor([[5.1803, 3.7178, 5.3351, 2.1266]]),\n",
       " tensor([[4.5854, 2.9023, 3.9518, 0.4474]]),\n",
       " tensor([[7.3285, 4.0190, 5.9634, 0.9818]]),\n",
       " tensor([[6.6264, 3.6518, 4.0860, 1.7970]]),\n",
       " tensor([[7.8731, 3.0166, 6.8560, 2.4821]]),\n",
       " tensor([[7.1346, 4.0637, 5.3820, 2.3061]]),\n",
       " tensor([[4.9299, 2.2299, 5.2850, 0.3011]]),\n",
       " tensor([[5.0915, 2.8601, 6.6351, 1.8020]]),\n",
       " tensor([[4.8201, 2.2178, 3.2152, 0.9765]]),\n",
       " tensor([[6.3293, 2.0174, 5.4960, 2.0797]]),\n",
       " tensor([[5.4795, 2.0366, 4.9672, 1.5516]]),\n",
       " tensor([[5.0604, 2.1742, 5.0158, 1.6030]]),\n",
       " tensor([[7.1932, 2.5978, 6.1425, 2.2915]]),\n",
       " tensor([[4.8113, 3.0451, 4.1128, 2.3218]]),\n",
       " tensor([[4.9405, 3.3726, 6.4480, 0.8778]]),\n",
       " tensor([[7.0123, 3.8082, 3.1670, 1.9082]]),\n",
       " tensor([[7.4547, 3.0467, 6.7235, 1.3455]]),\n",
       " tensor([[6.3437, 2.4829, 6.2389, 0.8132]]),\n",
       " tensor([[7.3941, 4.3229, 6.8929, 2.4971]]),\n",
       " tensor([[7.3201, 3.2509, 6.4060, 1.3747]]),\n",
       " tensor([[4.9094, 4.3475, 6.7710, 2.4475]]),\n",
       " tensor([[5.6334, 3.9798, 6.0872, 0.9659]]),\n",
       " tensor([[7.6615, 3.6830, 4.9247, 1.1410]]),\n",
       " tensor([[6.9413, 3.0227, 5.2349, 2.4706]]),\n",
       " tensor([[5.3877, 2.3492, 5.8552, 2.1480]]),\n",
       " tensor([[6.4365, 3.0260, 5.6336, 1.1528]]),\n",
       " tensor([[7.2185, 3.9457, 3.6602, 2.0457]]),\n",
       " tensor([[7.6638, 3.7383, 5.2734, 1.8383]]),\n",
       " tensor([[6.8638, 4.1668, 6.3267, 0.5569]]),\n",
       " tensor([[6.7267, 2.4572, 5.4290, 1.3948]]),\n",
       " tensor([[6.2358, 4.0423, 4.1726, 1.3906]]),\n",
       " tensor([[5.2930, 3.6461, 4.4709, 1.2024]]),\n",
       " tensor([[6.7009, 4.3161, 4.9008, 1.9205]]),\n",
       " tensor([[6.8041, 3.1254, 6.1316, 0.2777]]),\n",
       " tensor([[7.0011, 2.7046, 5.0394, 0.8558]]),\n",
       " tensor([[4.4411, 2.0762, 2.5098, 2.3952]]),\n",
       " tensor([[5.9714, 4.1427, 6.6552, 0.6674]]),\n",
       " tensor([[6.4272, 3.4182, 4.4863, 0.8706]]),\n",
       " tensor([[5.2374, 2.0339, 6.4995, 1.5228]]),\n",
       " tensor([[5.6833, 3.8348, 5.5107, 1.2751]]),\n",
       " tensor([[4.4757, 2.7744, 1.8259, 1.7291]]),\n",
       " tensor([[7.4748, 2.7971, 6.2031, 0.1041]]),\n",
       " tensor([[6.2267, 3.4690, 3.3019, 1.5569]]),\n",
       " tensor([[5.8677, 3.5250, 3.7961, 1.6930]]),\n",
       " tensor([[4.5385, 2.9346, 5.8493, 1.7050]]),\n",
       " tensor([[6.7701, 2.2528, 6.5801, 0.3009]]),\n",
       " tensor([[5.7318, 3.3404, 6.3022, 1.6093]]),\n",
       " tensor([[7.4079, 3.9969, 6.6917, 1.4866]]),\n",
       " tensor([[6.0777, 4.3193, 3.9134, 2.1773]]),\n",
       " tensor([[7.8368, 3.7400, 5.1972, 0.9089]]),\n",
       " tensor([[5.7847, 2.1681, 6.8636, 2.4014]]),\n",
       " tensor([[6.9047, 2.1091, 5.1349, 1.2866]]),\n",
       " tensor([[7.0963, 2.2583, 2.6508, 1.8559]]),\n",
       " tensor([[6.8770, 4.0270, 6.4926, 2.4063]]),\n",
       " tensor([[5.2800, 2.4391, 5.1951, 1.5372]]),\n",
       " tensor([[6.3071, 3.9265, 6.1161, 0.1346]]),\n",
       " tensor([[4.7135, 3.6361, 6.0448, 1.6076]]),\n",
       " tensor([[7.1530, 3.0381, 6.6609, 2.4875]]),\n",
       " tensor([[5.5869, 3.2352, 4.0366, 1.3352]]),\n",
       " tensor([[7.1560, 3.9040, 5.6807, 0.2687]]),\n",
       " tensor([[6.6189, 3.8734, 6.5877, 2.0689]]),\n",
       " tensor([[4.8300, 3.3525, 5.2124, 1.5940]]),\n",
       " tensor([[5.3294, 2.6863, 2.6870, 1.3686]]),\n",
       " tensor([[4.5322, 3.7847, 4.9319, 0.7321]]),\n",
       " tensor([[6.6921, 3.5947, 4.9203, 1.6947]]),\n",
       " tensor([[5.5418, 3.7209, 5.7130, 2.0172]]),\n",
       " tensor([[6.0250, 3.1500, 3.8270, 1.5766]]),\n",
       " tensor([[4.3545, 4.2990, 6.5338, 1.8177]]),\n",
       " tensor([[7.2986, 2.0125, 1.6244, 2.4585]]),\n",
       " tensor([[6.6199, 2.4325, 2.7039, 1.5985]]),\n",
       " tensor([[6.5154, 3.6894, 5.1530, 1.7894]]),\n",
       " tensor([[4.9177, 3.8457, 4.6727, 2.1444]]),\n",
       " tensor([[7.8738, 4.0083, 5.9372, 2.1083]]),\n",
       " tensor([[5.8641, 2.8738, 3.5634, 1.1427]]),\n",
       " tensor([[7.2752, 3.8610, 6.6410, 1.5500]]),\n",
       " tensor([[5.0062, 4.1159, 4.0449, 1.2004]]),\n",
       " tensor([[5.9716, 3.1144, 6.0978, 2.1737]]),\n",
       " tensor([[6.1229, 4.1004, 5.5987, 1.9624]]),\n",
       " tensor([[6.2396, 3.9595, 5.4667, 1.0077]]),\n",
       " tensor([[4.7784, 4.2219, 6.4621, 2.3219]]),\n",
       " tensor([[4.8679, 2.3786, 4.4830, 0.4786]]),\n",
       " tensor([[4.8949, 2.3966, 5.8491, 2.0725]]),\n",
       " tensor([[6.6790, 2.0044, 5.6181, 1.1647]]),\n",
       " tensor([[4.9829, 2.4553, 4.2269, 0.5553]]),\n",
       " tensor([[7.0080, 3.4908, 6.1187, 0.4364]]),\n",
       " tensor([[5.6403, 2.8935, 3.1966, 1.5032]]),\n",
       " tensor([[7.2597, 3.9731, 5.8506, 2.0731]]),\n",
       " tensor([[6.4791, 2.7451, 4.5713, 1.5527]]),\n",
       " ...]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shadow_dataset_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_10707/90580607.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshadow_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshadow_dataset_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadow_dataset_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadow_dataset_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadow_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shadow_datasetsV0.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shadow_dataset_0' is not defined"
     ]
    }
   ],
   "source": [
    "shadow_datasets = [shadow_dataset_0, shadow_dataset_1, shadow_dataset_2]\n",
    "torch.save(shadow_datasets, 'shadow_datasetsV0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_datasets = torch.load('shadow_datasetsV0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_datasets_train_class_k = []\n",
    "shadow_datasets_test_class_k = []\n",
    "shadow_train_labels_class_k = []\n",
    "shadow_test_labels_class_k = []\n",
    "for k in c_s:\n",
    "    temp_train_class_k, temp_test_class_k, temp_train_labels_class_k, temp_test_labels_class_k = train_test_split(shadow_datasets[k], np.full(len(shadow_datasets[k]),c_s[k]), test_size=0.5, shuffle=True)\n",
    "    shadow_datasets_train_class_k.append(temp_train_class_k)\n",
    "    shadow_datasets_test_class_k.append(temp_test_class_k)\n",
    "    shadow_train_labels_class_k.append(temp_train_labels_class_k)\n",
    "    shadow_test_labels_class_k.append(temp_test_labels_class_k)\n",
    "shadow_datasets_train_class_k = np.array(shadow_datasets_train_class_k)\n",
    "shadow_datasets_test_class_k = np.array(shadow_datasets_test_class_k)\n",
    "shadow_train_labels_class_k = np.array(shadow_train_labels_class_k)\n",
    "shadow_test_labels_class_k = np.array(shadow_test_labels_class_k)\n",
    "\n",
    "shadow_test_labels_class_k[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[4.458402  , 3.8980637 , 1.259603  , 1.9980637 ]],\n",
       " \n",
       "        [[7.8874593 , 4.459631  , 4.800767  , 0.32715416]],\n",
       " \n",
       "        [[7.7245164 , 2.8127816 , 2.9980881 , 0.2348094 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[4.3162737 , 3.2702246 , 1.0266708 , 0.11084914]],\n",
       " \n",
       "        [[4.517254  , 3.271134  , 1.3560548 , 0.4511175 ]],\n",
       " \n",
       "        [[5.8588357 , 3.0392237 , 3.5547583 , 0.9727907 ]]], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_dataset_train_k = []\n",
    "shadow_dataset_test_k = []\n",
    "shadow_train_labels_k= []\n",
    "shadow_test_labels_k= []\n",
    "range_indices_train = len(shadow_datasets_train_class_k[0])//mutliple_of_cs\n",
    "range_indices_test = len(shadow_datasets_test_class_k[0])//mutliple_of_cs\n",
    "for k in range(mutliple_of_cs):\n",
    "    shadow_dataset_train_k.append(np.concatenate([shadow_datasets_train_class_k[i][k*range_indices_train:(k+1)*range_indices_train] for i in range(len(c_s))]))\n",
    "    shadow_dataset_test_k.append(np.concatenate([shadow_datasets_test_class_k[i][k*range_indices_test:(k+1)*range_indices_test] for i in range(len(c_s))]))\n",
    "    shadow_train_labels_k.append(np.concatenate([shadow_train_labels_class_k[i][k*range_indices_train:(k+1)*range_indices_train] for i in range(len(c_s))]))\n",
    "    shadow_test_labels_k.append(np.concatenate([shadow_test_labels_class_k[i][k*range_indices_test:(k+1)*range_indices_test] for i in range(len(c_s))]))\n",
    "    shadow_dataset_train_k[k], shadow_train_labels_k[k] = shuffle(shadow_dataset_train_k[k], shadow_train_labels_k[k])\n",
    "\n",
    "shadow_dataset_train_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_list_to_np(shadow_dataset, shadow_labels):\n",
    "    \"Transofrm a list of tensors into a numpy array\"\n",
    "    shadow_dataset_np = np.zeros((len(shadow_dataset), len(shadow_dataset[0][0])))\n",
    "    shadow_labels_np = np.zeros(len(shadow_dataset))\n",
    "    for i in range(len(shadow_dataset)):\n",
    "        shadow_dataset_np[i] = shadow_dataset[i][0]\n",
    "        shadow_labels_np[i] = shadow_labels[i]\n",
    "    return shadow_dataset_np, shadow_labels_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(mutliple_of_cs):\n",
    "    shadow_dataset_train_k[k], shadow_train_labels_k[k] = from_list_to_np(shadow_dataset_train_k[k], shadow_train_labels_k[k])\n",
    "    shadow_dataset_test_k[k], shadow_test_labels_k[k] = from_list_to_np(shadow_dataset_test_k[k], shadow_test_labels_k[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrixes = []\n",
    "Edges = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_10707/1925229584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msimilarity_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadow_dataset_train_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshadow_dataset_train_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msimilarity_matrixes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0medges_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(mutliple_of_cs):\n",
    "    similarity_matrix = cosine_similarity(shadow_dataset_train_k[k],shadow_dataset_train_k[k])\n",
    "    similarity_matrixes.append(similarity_matrix)\n",
    "    edges_k = []\n",
    "    for i in tqdm(range(len(similarity_matrix))):\n",
    "        for j in range(i):\n",
    "            if similarity_matrix[i][j] >= minimum_similarity:\n",
    "                edges_k.append((i,j))\n",
    "    Edges.append(edges_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow model 0 training...\n",
      "Data done\n",
      "Mask done\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/101 [00:13<21:40, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 1.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/101 [02:16<18:23, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 1.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/101 [04:18<16:15, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train Loss: 0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/101 [06:20<14:12, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Train Loss: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/101 [08:21<12:08, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Train Loss: 0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 51/101 [10:23<10:08, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Train Loss: 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 61/101 [12:25<08:07, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 060, Train Loss: 0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 71/101 [14:27<06:05, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 070, Train Loss: 0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 81/101 [16:29<04:03, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 080, Train Loss: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 91/101 [18:30<02:01, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 090, Train Loss: 0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [20:32<00:00, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train Loss: 0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "shadow_model_s = []\n",
    "for k in range(mutliple_of_cs):\n",
    "    print(f'Shadow model {k} training...')\n",
    "    x = torch.tensor(shadow_dataset_train_k[k], dtype=torch.float)\n",
    "\n",
    "    edge_index = torch.tensor(Edges[k], dtype=torch.long).t().contiguous()\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    y_true_tensor = torch.tensor(shadow_train_labels_k[k], dtype=torch.long, requires_grad=False)\n",
    "    data.y = y_true_tensor\n",
    "    data.validate(raise_on_error=True)\n",
    "    print(\"Data done\")\n",
    "    # Manually split nodes into train, validation, and test sets using PyTorch\n",
    "    num_nodes = len(data.x)\n",
    "    train_ratio, test_ratio = 0.8, 0.2\n",
    "\n",
    "    num_train = int(train_ratio * num_nodes)\n",
    "    num_test = num_nodes - num_train\n",
    "\n",
    "    # Create masks for train, validation, and test nodes\n",
    "    perm = torch.randperm(num_nodes)\n",
    "    train_mask = perm[:num_train]\n",
    "    test_mask = perm[num_train:]\n",
    "\n",
    "    # Apply masks to the data\n",
    "    data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    data.train_mask[train_mask] = 1\n",
    "    data.test_mask[test_mask] = 1\n",
    "    print(\"Mask done\")\n",
    "\n",
    "    shadow_model_k = GraphSAGE(data.num_features, hidden_dim=16, out_dim=3)\n",
    "    optimizer = torch.optim.Adam(shadow_model_k.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Training loop\n",
    "    shadow_model_k.train()\n",
    "    print(\"Training...\")\n",
    "    for epoch in tqdm(range(101)):\n",
    "        optimizer.zero_grad()\n",
    "        out = shadow_model_k(data)\n",
    "        loss = criterion(out[data.train_mask], y_true_tensor[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}')\n",
    "\n",
    "    # Evaluation\n",
    "    shadow_model_k.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = shadow_model_k(data)\n",
    "        pred = logits.argmax(dim=1)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = (pred[data.test_mask] == y_true_tensor[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    shadow_model_s.append(shadow_model_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(shadow_model_s, 'shadow_modelsV0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_model_s = torch.load('shadow_modelsV0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_training_set_in(shadow_training_dataset, shadow_train_labels_k, target_shadow_model):\n",
    "    attack_dataset = []\n",
    "    attack_labels = []\n",
    "    print(f'Generating attack dataset in...')\n",
    "    for k in tqdm(range(len(shadow_training_dataset))):\n",
    "        if shadow_training_dataset[k] is not torch.tensor:\n",
    "            x = torch.tensor([shadow_training_dataset[k]], dtype=torch.float, requires_grad=False)\n",
    "        else :\n",
    "            x = torch.tensor([shadow_training_dataset[k].type(torch.FloatTensor).detach()])\n",
    "        edge_index = torch.tensor([(0,0)], dtype=torch.long).t().contiguous()\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        y = F.softmax(target_shadow_model.forward(data).detach())\n",
    "        attack_dataset.append([y[0].numpy(), shadow_train_labels_k[k]])\n",
    "        attack_labels.append(1)\n",
    "    return attack_dataset, attack_labels\n",
    "\n",
    "def attack_training_set_out(shadow_test_dataset, shadow_test_labels_k, target_shadow_model):\n",
    "    attack_dataset = []\n",
    "    attack_labels = []\n",
    "    print(f'Generating attack dataset out...')\n",
    "    for k in tqdm(range(len(shadow_test_dataset))):\n",
    "        if shadow_test_dataset[k] is not torch.tensor:\n",
    "            x = torch.tensor([shadow_test_dataset[k]], dtype=torch.float, requires_grad=False)\n",
    "        else :\n",
    "            x = torch.tensor([shadow_test_dataset[k].type(torch.FloatTensor).detach()])\n",
    "        edge_index = torch.tensor([(0,0)], dtype=torch.long).t().contiguous()\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "        y = F.softmax(target_shadow_model.forward(data).detach())\n",
    "        attack_dataset.append([y[0].numpy(), shadow_test_labels_k[k]])\n",
    "        attack_labels.append(0)\n",
    "    return attack_dataset, attack_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.35231924, 3.01741147, 1.08574498, 0.13487931],\n",
       "       [6.35557413, 4.28450727, 1.13643396, 0.15549856],\n",
       "       [4.36786222, 4.00718021, 1.11121798, 0.96438307],\n",
       "       ...,\n",
       "       [5.38039255, 3.56585312, 6.86368847, 1.00048339],\n",
       "       [4.61980343, 2.62902021, 4.11406517, 1.70622289],\n",
       "       [4.87551832, 2.20173454, 6.28643703, 1.79689825]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_dataset_test_k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating attack dataset in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15000 [00:00<?, ?it/s]/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/793026817.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686209/work/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  x = torch.tensor([shadow_training_dataset[k]], dtype=torch.float, requires_grad=False)\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/793026817.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y = F.softmax(target_shadow_model.forward(data).detach())\n",
      "100%|██████████| 15000/15000 [00:02<00:00, 5218.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating attack dataset out...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15000 [00:00<?, ?it/s]/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/793026817.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y = F.softmax(target_shadow_model.forward(data).detach())\n",
      "100%|██████████| 15000/15000 [00:02<00:00, 5510.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "attack_dataset = []\n",
    "attack_labels = []\n",
    "for k in range(mutliple_of_cs):\n",
    "    attack_dataset_in, attack_labels_in = attack_training_set_in(shadow_dataset_train_k[k], shadow_train_labels_k[k], shadow_model_s[k])\n",
    "    attack_dataset_out, attack_labels_out = attack_training_set_out(shadow_dataset_test_k[k], shadow_test_labels_k[k], shadow_model_s[k])\n",
    "    attack_dataset += attack_dataset_in\n",
    "    attack_dataset += attack_dataset_out\n",
    "    attack_labels += attack_labels_in\n",
    "    attack_labels += attack_labels_out\n",
    "attack_labels = np.array(attack_labels)\n",
    "print(len(attack_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.00990214, 0.79080725, 0.19929065]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.058757894, 0.9347302, 0.0065118284]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.010451914, 0.8305525, 0.15899555]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.009989712, 0.7973351, 0.19267517]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0101730665, 0.8107749, 0.17905195]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>[0.010370922, 0.82489705, 0.16473202]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>[0.01042097, 0.82840085, 0.16117817]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>[0.010425883, 0.82874286, 0.16083129]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>[0.01034083, 0.8227778, 0.1668813]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>[0.010118319, 0.8067966, 0.18308507]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            y  class\n",
       "1        [0.00990214, 0.79080725, 0.19929065]    1.0\n",
       "2      [0.058757894, 0.9347302, 0.0065118284]    1.0\n",
       "3        [0.010451914, 0.8305525, 0.15899555]    1.0\n",
       "5        [0.009989712, 0.7973351, 0.19267517]    1.0\n",
       "10      [0.0101730665, 0.8107749, 0.17905195]    1.0\n",
       "...                                       ...    ...\n",
       "24995   [0.010370922, 0.82489705, 0.16473202]    1.0\n",
       "24996    [0.01042097, 0.82840085, 0.16117817]    1.0\n",
       "24997   [0.010425883, 0.82874286, 0.16083129]    1.0\n",
       "24998      [0.01034083, 0.8227778, 0.1668813]    1.0\n",
       "24999    [0.010118319, 0.8067966, 0.18308507]    1.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=attack_dataset, columns=['y', 'class'])\n",
    "df[df['class'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4493\n",
      "Attack model 0 training...\n",
      "Attack model 0 accuracy: 0.512\n",
      "Attack model 0 recall: 0.5108481262327417\n",
      "Attack model 0 precision: 0.5190380761523046\n",
      "Attack model 0 f1: 0.5149105367793241\n",
      "\n",
      "4521\n",
      "Attack model 1 training...\n",
      "Attack model 1 accuracy: 0.504\n",
      "Attack model 1 recall: 0.48434237995824636\n",
      "Attack model 1 precision: 0.48232848232848236\n",
      "Attack model 1 f1: 0.4833333333333334\n",
      "\n",
      "4519\n",
      "Attack model 2 training...\n",
      "Attack model 2 accuracy: 0.515\n",
      "Attack model 2 recall: 0.5239085239085239\n",
      "Attack model 2 precision: 0.49606299212598426\n",
      "Attack model 2 f1: 0.5096056622851365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "attack_dataset = []\n",
    "attack_models = []\n",
    "for c in c_s:\n",
    "    dataset = df[df['class'] == c]['y']\n",
    "    labels = attack_labels[df['class'] == c]\n",
    "    dataset = np.array([x for x in dataset])\n",
    "    train_dataset, test_dataset, train_labels, test_labels = train_test_split(dataset, labels, test_size=0.1, shuffle=True)\n",
    "    print(sum(train_labels == 1))\n",
    "    print(f'Attack model {c} training...')\n",
    "    # attack_model = MLPClassifier(hidden_layer_sizes=(80, 70, 60, 50,40, 30, 20,10), max_iter=1000).fit(train_dataset, train_labels)\n",
    "    attack_model = RandomForestClassifier(n_estimators=1000).fit(train_dataset, train_labels)\n",
    "    y_pred = attack_model.predict(test_dataset)\n",
    "    print(f'Attack model {c} accuracy: {attack_model.score(test_dataset, test_labels)}')\n",
    "    print(f'Attack model {c} recall: {recall_score(test_labels, y_pred)}')\n",
    "    print(f'Attack model {c} precision: {precision_score(test_labels, y_pred)}')\n",
    "    print(f'Attack model {c} f1: {f1_score(test_labels, y_pred)}\\n')\n",
    "    attack_models.append(attack_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack model accuracy on class 0: 0.62\n",
      "Attack model recall on class 0: 0.6\n",
      "Attack model precision on class 0: 0.8888888888888888\n",
      "Attack model f1 on class 0: 0.7164179104477612\n",
      "\n",
      "Attack model accuracy on class 1: 0.5\n",
      "Attack model recall on class 1: 0.5641025641025641\n",
      "Attack model precision on class 1: 0.7333333333333333\n",
      "Attack model f1 on class 1: 0.6376811594202899\n",
      "\n",
      "Attack model accuracy on class 2: 0.28\n",
      "Attack model recall on class 2: 0.17073170731707318\n",
      "Attack model precision on class 2: 0.7777777777777778\n",
      "Attack model f1 on class 2: 0.27999999999999997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/1748551869.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  In_samples_y_0 = F.softmax(target_model.forward(data_in_sample_0).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/1748551869.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  In_samples_y_1 = F.softmax(target_model.forward(data_in_sample_1).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/1748551869.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  In_samples_y_2 = F.softmax(target_model.forward(data_in_sample_2).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/1748551869.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Out_samples_y_0 = F.softmax(target_model.forward(data_out_sample_0).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/1748551869.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Out_samples_y_1 = F.softmax(target_model.forward(data_out_sample_1).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/1748551869.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Out_samples_y_2 = F.softmax(target_model.forward(data_out_sample_2).detach())\n"
     ]
    }
   ],
   "source": [
    "data_target_model_train = data_target_model.x[data_target_model.train_mask]\n",
    "data_target_model_test = data_target_model.x[data_target_model.test_mask]\n",
    "y_train_target_model = data_target_model.y[data_target_model.train_mask]\n",
    "y_test_target_model = data_target_model.y[data_target_model.test_mask]\n",
    "\n",
    "data_target_model_train_class_0 = data_target_model_train[y_train_target_model == 0]\n",
    "data_target_model_train_class_1 = data_target_model_train[y_train_target_model == 1]\n",
    "data_target_model_train_class_2 = data_target_model_train[y_train_target_model == 2]\n",
    "\n",
    "data_target_model_test_class_0 = data_target_model_test[y_test_target_model == 0]\n",
    "data_target_model_test_class_1 = data_target_model_test[y_test_target_model == 1]\n",
    "data_target_model_test_class_2 = data_target_model_test[y_test_target_model == 2]\n",
    "\n",
    "data_in_sample_0 = Data(x=data_target_model_train_class_0, edge_index=torch.tensor([(0,0)]*len(data_target_model_train_class_0), dtype=torch.long).t().contiguous())\n",
    "data_in_sample_1 = Data(x=data_target_model_train_class_1, edge_index=torch.tensor([(0,0)]*len(data_target_model_train_class_1), dtype=torch.long).t().contiguous())\n",
    "data_in_sample_2 = Data(x=data_target_model_train_class_2, edge_index=torch.tensor([(0,0)]*len(data_target_model_train_class_2), dtype=torch.long).t().contiguous())\n",
    "\n",
    "data_out_sample_0 = Data(x=data_target_model_test_class_0, edge_index=torch.tensor([(0,0)]*len(data_target_model_test_class_0), dtype=torch.long).t().contiguous())\n",
    "data_out_sample_1 = Data(x=data_target_model_test_class_1, edge_index=torch.tensor([(0,0)]*len(data_target_model_test_class_1), dtype=torch.long).t().contiguous())\n",
    "data_out_sample_2 = Data(x=data_target_model_test_class_2, edge_index=torch.tensor([(0,0)]*len(data_target_model_test_class_2), dtype=torch.long).t().contiguous())\n",
    "\n",
    "In_samples_y_0 = F.softmax(target_model.forward(data_in_sample_0).detach())\n",
    "In_samples_y_1 = F.softmax(target_model.forward(data_in_sample_1).detach())\n",
    "In_samples_y_2 = F.softmax(target_model.forward(data_in_sample_2).detach())\n",
    "\n",
    "In_samples_y_0 = np.array([x for x in In_samples_y_0])\n",
    "In_samples_y_1 = np.array([x for x in In_samples_y_1])\n",
    "In_samples_y_2 = np.array([x for x in In_samples_y_2])\n",
    "\n",
    "Out_samples_y_0 = F.softmax(target_model.forward(data_out_sample_0).detach())\n",
    "Out_samples_y_1 = F.softmax(target_model.forward(data_out_sample_1).detach())\n",
    "Out_samples_y_2 = F.softmax(target_model.forward(data_out_sample_2).detach())\n",
    "\n",
    "Out_samples_y_0 = np.array([x for x in Out_samples_y_0])\n",
    "Out_samples_y_1 = np.array([x for x in Out_samples_y_1])\n",
    "Out_samples_y_2 = np.array([x for x in Out_samples_y_2])\n",
    "\n",
    "\n",
    "labels_in_0 = np.full(len(In_samples_y_0), 1)\n",
    "labels_in_1 = np.full(len(In_samples_y_1), 1)\n",
    "labels_in_2 = np.full(len(In_samples_y_2), 1)\n",
    "\n",
    "labels_out_0 = np.full(len(Out_samples_y_0), 0)\n",
    "labels_out_1 = np.full(len(Out_samples_y_1), 0)\n",
    "labels_out_2 = np.full(len(Out_samples_y_2), 0)\n",
    "\n",
    "evaluation_0 = np.concatenate((In_samples_y_0, Out_samples_y_0))\n",
    "evaluation_1 = np.concatenate((In_samples_y_1, Out_samples_y_1))\n",
    "evaluation_2 = np.concatenate((In_samples_y_2, Out_samples_y_2))\n",
    "\n",
    "labels_0 = np.concatenate((labels_in_0, labels_out_0))\n",
    "labels_1 = np.concatenate((labels_in_1, labels_out_1))\n",
    "labels_2 = np.concatenate((labels_in_2, labels_out_2))\n",
    "\n",
    "y_pred_0 = attack_models[0].predict(evaluation_0)\n",
    "y_pred_1 = attack_models[1].predict(evaluation_1)\n",
    "y_pred_2 = attack_models[2].predict(evaluation_2)\n",
    "\n",
    "print(f'Attack model accuracy on class 0: {accuracy_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model recall on class 0: {recall_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model precision on class 0: {precision_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model f1 on class 0: {f1_score(labels_0, y_pred_0)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 1: {accuracy_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model recall on class 1: {recall_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model precision on class 1: {precision_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model f1 on class 1: {f1_score(labels_1, y_pred_1)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 2: {accuracy_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model recall on class 2: {recall_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model precision on class 2: {precision_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model f1 on class 2: {f1_score(labels_2, y_pred_2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack model accuracy on class 0: 0.7\n",
      "Attack model recall on class 0: 0.85\n",
      "Attack model precision on class 0: 0.7906976744186046\n",
      "Attack model f1 on class 0: 0.8192771084337349\n",
      "\n",
      "Attack model accuracy on class 1: 0.76\n",
      "Attack model recall on class 1: 0.9743589743589743\n",
      "Attack model precision on class 1: 0.7755102040816326\n",
      "Attack model f1 on class 1: 0.8636363636363635\n",
      "\n",
      "Attack model accuracy on class 2: 0.56\n",
      "Attack model recall on class 2: 0.5853658536585366\n",
      "Attack model precision on class 2: 0.8275862068965517\n",
      "Attack model f1 on class 2: 0.6857142857142856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/57496897.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_predicted_train = F.softmax(y_predicted_train)\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/57496897.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_predicted_test = F.softmax(y_predicted_test)\n"
     ]
    }
   ],
   "source": [
    "y_predicted = target_model.forward(data_target_model).detach()\n",
    "y_predicted_train = y_predicted[data_target_model.train_mask]\n",
    "y_predicted_test = y_predicted[data_target_model.test_mask]\n",
    "class_train = data_target_model.y[data_target_model.train_mask]\n",
    "class_test = data_target_model.y[data_target_model.test_mask]\n",
    "\n",
    "y_predicted_train = F.softmax(y_predicted_train)\n",
    "y_predicted_test = F.softmax(y_predicted_test)\n",
    "\n",
    "y_predicted_train = np.array([x for x in y_predicted_train])\n",
    "y_predicted_test = np.array([x for x in y_predicted_test])\n",
    "class_train = np.array([x for x in class_train])\n",
    "class_test = np.array([x for x in class_test])\n",
    "\n",
    "index_train_0 = np.where(class_train == 0)\n",
    "index_train_1 = np.where(class_train == 1)\n",
    "index_train_2 = np.where(class_train == 2)\n",
    "\n",
    "index_test_0 = np.where(class_test == 0)\n",
    "index_test_1 = np.where(class_test == 1)\n",
    "index_test_2 = np.where(class_test == 2)\n",
    "\n",
    "In_samples_y_0 = y_predicted_train[index_train_0]\n",
    "In_samples_y_1 = y_predicted_train[index_train_1]\n",
    "In_samples_y_2 = y_predicted_train[index_train_2]\n",
    "\n",
    "Out_samples_y_0 = y_predicted_test[index_test_0]\n",
    "Out_samples_y_1 = y_predicted_test[index_test_1]\n",
    "Out_samples_y_2 = y_predicted_test[index_test_2]\n",
    "\n",
    "\n",
    "labels_in_0 = np.full(len(In_samples_y_0), 1)\n",
    "labels_in_1 = np.full(len(In_samples_y_1), 1)\n",
    "labels_in_2 = np.full(len(In_samples_y_2), 1)\n",
    "\n",
    "labels_out_0 = np.full(len(Out_samples_y_0), 0)\n",
    "labels_out_1 = np.full(len(Out_samples_y_1), 0)\n",
    "labels_out_2 = np.full(len(Out_samples_y_2), 0)\n",
    "\n",
    "evaluation_0 = np.concatenate((In_samples_y_0, Out_samples_y_0))\n",
    "evaluation_1 = np.concatenate((In_samples_y_1, Out_samples_y_1))\n",
    "evaluation_2 = np.concatenate((In_samples_y_2, Out_samples_y_2))\n",
    "\n",
    "labels_0 = np.concatenate((labels_in_0, labels_out_0))\n",
    "labels_1 = np.concatenate((labels_in_1, labels_out_1))\n",
    "labels_2 = np.concatenate((labels_in_2, labels_out_2))\n",
    "\n",
    "y_pred_0 = attack_models[0].predict(evaluation_0)\n",
    "y_pred_1 = attack_models[1].predict(evaluation_1)\n",
    "y_pred_2 = attack_models[2].predict(evaluation_2)\n",
    "\n",
    "print(f'Attack model accuracy on class 0: {accuracy_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model recall on class 0: {recall_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model precision on class 0: {precision_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model f1 on class 0: {f1_score(labels_0, y_pred_0)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 1: {accuracy_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model recall on class 1: {recall_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model precision on class 1: {precision_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model f1 on class 1: {f1_score(labels_1, y_pred_1)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 2: {accuracy_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model recall on class 2: {recall_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model precision on class 2: {precision_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model f1 on class 2: {f1_score(labels_2, y_pred_2)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target_model = GraphSAGE(data_target_model.num_features, hidden_dim=16, out_dim=3)\n",
    "optimizer = torch.optim.Adam(new_target_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 1.228\n",
      "Epoch: 010, Train Loss: 0.712\n",
      "Accuracy: 0.6333\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "new_target_model.train()\n",
    "for epoch in range(11):\n",
    "    optimizer.zero_grad()\n",
    "    out = new_target_model(data_target_model)\n",
    "    loss = F.cross_entropy(out[data_target_model.train_mask], y_true_tensor[data_target_model.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}')\n",
    "\n",
    "# Evaluation\n",
    "new_target_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = new_target_model(data_target_model)\n",
    "    pred = logits.argmax(dim=1)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = (pred[data_target_model.test_mask] == y_true_tensor[data_target_model.test_mask]).sum().item() / data_target_model.test_mask.sum().item()\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack model accuracy on class 0: 0.2\n",
      "Attack model recall on class 0: 0.0\n",
      "Attack model precision on class 0: 0.0\n",
      "Attack model f1 on class 0: 0.0\n",
      "\n",
      "Attack model accuracy on class 1: 0.78\n",
      "Attack model recall on class 1: 1.0\n",
      "Attack model precision on class 1: 0.78\n",
      "Attack model f1 on class 1: 0.8764044943820225\n",
      "\n",
      "Attack model accuracy on class 2: 0.54\n",
      "Attack model recall on class 2: 0.5609756097560976\n",
      "Attack model precision on class 2: 0.8214285714285714\n",
      "Attack model f1 on class 2: 0.6666666666666667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/2638329020.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_predicted_train = F.softmax(y_predicted_train)\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/2638329020.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_predicted_test = F.softmax(y_predicted_test)\n",
      "/Users/jskaf/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_predicted = new_target_model.forward(data_target_model).detach()\n",
    "y_predicted_train = y_predicted[data_target_model.train_mask]\n",
    "y_predicted_test = y_predicted[data_target_model.test_mask]\n",
    "class_train = data_target_model.y[data_target_model.train_mask]\n",
    "class_test = data_target_model.y[data_target_model.test_mask]\n",
    "\n",
    "y_predicted_train = F.softmax(y_predicted_train)\n",
    "y_predicted_test = F.softmax(y_predicted_test)\n",
    "\n",
    "y_predicted_train = np.array([x for x in y_predicted_train])\n",
    "y_predicted_test = np.array([x for x in y_predicted_test])\n",
    "class_train = np.array([x for x in class_train])\n",
    "class_test = np.array([x for x in class_test])\n",
    "\n",
    "index_train_0 = np.where(class_train == 0)\n",
    "index_train_1 = np.where(class_train == 1)\n",
    "index_train_2 = np.where(class_train == 2)\n",
    "\n",
    "index_test_0 = np.where(class_test == 0)\n",
    "index_test_1 = np.where(class_test == 1)\n",
    "index_test_2 = np.where(class_test == 2)\n",
    "\n",
    "In_samples_y_0 = y_predicted_train[index_train_0]\n",
    "In_samples_y_1 = y_predicted_train[index_train_1]\n",
    "In_samples_y_2 = y_predicted_train[index_train_2]\n",
    "\n",
    "Out_samples_y_0 = y_predicted_test[index_test_0]\n",
    "Out_samples_y_1 = y_predicted_test[index_test_1]\n",
    "Out_samples_y_2 = y_predicted_test[index_test_2]\n",
    "\n",
    "\n",
    "labels_in_0 = np.full(len(In_samples_y_0), 1)\n",
    "labels_in_1 = np.full(len(In_samples_y_1), 1)\n",
    "labels_in_2 = np.full(len(In_samples_y_2), 1)\n",
    "\n",
    "labels_out_0 = np.full(len(Out_samples_y_0), 0)\n",
    "labels_out_1 = np.full(len(Out_samples_y_1), 0)\n",
    "labels_out_2 = np.full(len(Out_samples_y_2), 0)\n",
    "\n",
    "evaluation_0 = np.concatenate((In_samples_y_0, Out_samples_y_0))\n",
    "evaluation_1 = np.concatenate((In_samples_y_1, Out_samples_y_1))\n",
    "evaluation_2 = np.concatenate((In_samples_y_2, Out_samples_y_2))\n",
    "\n",
    "labels_0 = np.concatenate((labels_in_0, labels_out_0))\n",
    "labels_1 = np.concatenate((labels_in_1, labels_out_1))\n",
    "labels_2 = np.concatenate((labels_in_2, labels_out_2))\n",
    "\n",
    "y_pred_0 = attack_models[0].predict(evaluation_0)\n",
    "y_pred_1 = attack_models[1].predict(evaluation_1)\n",
    "y_pred_2 = attack_models[2].predict(evaluation_2)\n",
    "\n",
    "print(f'Attack model accuracy on class 0: {accuracy_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model recall on class 0: {recall_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model precision on class 0: {precision_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model f1 on class 0: {f1_score(labels_0, y_pred_0)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 1: {accuracy_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model recall on class 1: {recall_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model precision on class 1: {precision_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model f1 on class 1: {f1_score(labels_1, y_pred_1)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 2: {accuracy_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model recall on class 2: {recall_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model precision on class 2: {precision_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model f1 on class 2: {f1_score(labels_2, y_pred_2)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack model accuracy on class 0: 0.2\n",
      "Attack model recall on class 0: 0.0\n",
      "Attack model precision on class 0: 0.0\n",
      "Attack model f1 on class 0: 0.0\n",
      "\n",
      "Attack model accuracy on class 1: 0.78\n",
      "Attack model recall on class 1: 1.0\n",
      "Attack model precision on class 1: 0.78\n",
      "Attack model f1 on class 1: 0.8764044943820225\n",
      "\n",
      "Attack model accuracy on class 2: 0.56\n",
      "Attack model recall on class 2: 0.5853658536585366\n",
      "Attack model precision on class 2: 0.8275862068965517\n",
      "Attack model f1 on class 2: 0.6857142857142856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/3036034558.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  In_samples_y_0 = F.softmax(new_target_model.forward(data_in_sample_0).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/3036034558.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  In_samples_y_1 = F.softmax(new_target_model.forward(data_in_sample_1).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/3036034558.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  In_samples_y_2 = F.softmax(new_target_model.forward(data_in_sample_2).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/3036034558.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Out_samples_y_0 = F.softmax(new_target_model.forward(data_out_sample_0).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/3036034558.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Out_samples_y_1 = F.softmax(new_target_model.forward(data_out_sample_1).detach())\n",
      "/var/folders/62/6pb5kjf139gccp8_mvcxrc7w0000gn/T/ipykernel_75829/3036034558.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Out_samples_y_2 = F.softmax(new_target_model.forward(data_out_sample_2).detach())\n",
      "/Users/jskaf/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "data_target_model_train = data_target_model.x[data_target_model.train_mask]\n",
    "data_target_model_test = data_target_model.x[data_target_model.test_mask]\n",
    "y_train_target_model = data_target_model.y[data_target_model.train_mask]\n",
    "y_test_target_model = data_target_model.y[data_target_model.test_mask]\n",
    "\n",
    "data_target_model_train_class_0 = data_target_model_train[y_train_target_model == 0]\n",
    "data_target_model_train_class_1 = data_target_model_train[y_train_target_model == 1]\n",
    "data_target_model_train_class_2 = data_target_model_train[y_train_target_model == 2]\n",
    "\n",
    "data_target_model_test_class_0 = data_target_model_test[y_test_target_model == 0]\n",
    "data_target_model_test_class_1 = data_target_model_test[y_test_target_model == 1]\n",
    "data_target_model_test_class_2 = data_target_model_test[y_test_target_model == 2]\n",
    "\n",
    "data_in_sample_0 = Data(x=data_target_model_train_class_0, edge_index=torch.tensor([(0,0)]*len(data_target_model_train_class_0), dtype=torch.long).t().contiguous())\n",
    "data_in_sample_1 = Data(x=data_target_model_train_class_1, edge_index=torch.tensor([(0,0)]*len(data_target_model_train_class_1), dtype=torch.long).t().contiguous())\n",
    "data_in_sample_2 = Data(x=data_target_model_train_class_2, edge_index=torch.tensor([(0,0)]*len(data_target_model_train_class_2), dtype=torch.long).t().contiguous())\n",
    "\n",
    "data_out_sample_0 = Data(x=data_target_model_test_class_0, edge_index=torch.tensor([(0,0)]*len(data_target_model_test_class_0), dtype=torch.long).t().contiguous())\n",
    "data_out_sample_1 = Data(x=data_target_model_test_class_1, edge_index=torch.tensor([(0,0)]*len(data_target_model_test_class_1), dtype=torch.long).t().contiguous())\n",
    "data_out_sample_2 = Data(x=data_target_model_test_class_2, edge_index=torch.tensor([(0,0)]*len(data_target_model_test_class_2), dtype=torch.long).t().contiguous())\n",
    "\n",
    "In_samples_y_0 = F.softmax(new_target_model.forward(data_in_sample_0).detach())\n",
    "In_samples_y_1 = F.softmax(new_target_model.forward(data_in_sample_1).detach())\n",
    "In_samples_y_2 = F.softmax(new_target_model.forward(data_in_sample_2).detach())\n",
    "\n",
    "In_samples_y_0 = np.array([x for x in In_samples_y_0])\n",
    "In_samples_y_1 = np.array([x for x in In_samples_y_1])\n",
    "In_samples_y_2 = np.array([x for x in In_samples_y_2])\n",
    "\n",
    "Out_samples_y_0 = F.softmax(new_target_model.forward(data_out_sample_0).detach())\n",
    "Out_samples_y_1 = F.softmax(new_target_model.forward(data_out_sample_1).detach())\n",
    "Out_samples_y_2 = F.softmax(new_target_model.forward(data_out_sample_2).detach())\n",
    "\n",
    "Out_samples_y_0 = np.array([x for x in Out_samples_y_0])\n",
    "Out_samples_y_1 = np.array([x for x in Out_samples_y_1])\n",
    "Out_samples_y_2 = np.array([x for x in Out_samples_y_2])\n",
    "\n",
    "\n",
    "labels_in_0 = np.full(len(In_samples_y_0), 1)\n",
    "labels_in_1 = np.full(len(In_samples_y_1), 1)\n",
    "labels_in_2 = np.full(len(In_samples_y_2), 1)\n",
    "\n",
    "labels_out_0 = np.full(len(Out_samples_y_0), 0)\n",
    "labels_out_1 = np.full(len(Out_samples_y_1), 0)\n",
    "labels_out_2 = np.full(len(Out_samples_y_2), 0)\n",
    "\n",
    "evaluation_0 = np.concatenate((In_samples_y_0, Out_samples_y_0))\n",
    "evaluation_1 = np.concatenate((In_samples_y_1, Out_samples_y_1))\n",
    "evaluation_2 = np.concatenate((In_samples_y_2, Out_samples_y_2))\n",
    "\n",
    "labels_0 = np.concatenate((labels_in_0, labels_out_0))\n",
    "labels_1 = np.concatenate((labels_in_1, labels_out_1))\n",
    "labels_2 = np.concatenate((labels_in_2, labels_out_2))\n",
    "\n",
    "y_pred_0 = attack_models[0].predict(evaluation_0)\n",
    "y_pred_1 = attack_models[1].predict(evaluation_1)\n",
    "y_pred_2 = attack_models[2].predict(evaluation_2)\n",
    "\n",
    "print(f'Attack model accuracy on class 0: {accuracy_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model recall on class 0: {recall_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model precision on class 0: {precision_score(labels_0, y_pred_0)}')\n",
    "print(f'Attack model f1 on class 0: {f1_score(labels_0, y_pred_0)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 1: {accuracy_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model recall on class 1: {recall_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model precision on class 1: {precision_score(labels_1, y_pred_1)}')\n",
    "print(f'Attack model f1 on class 1: {f1_score(labels_1, y_pred_1)}\\n')\n",
    "\n",
    "print(f'Attack model accuracy on class 2: {accuracy_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model recall on class 2: {recall_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model precision on class 2: {precision_score(labels_2, y_pred_2)}')\n",
    "print(f'Attack model f1 on class 2: {f1_score(labels_2, y_pred_2)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
